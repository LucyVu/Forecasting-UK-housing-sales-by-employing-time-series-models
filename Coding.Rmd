---
title: "R Notebook"
output:
  html_document:
    toc: yes
    toc_depth: 3
  word_document:
    toc: yes
    toc_depth: '3'
editor_options:
  chunk_output_type: console
---
---

This is to certify that the work I am submitting is my own. All external references and sources are clearly acknowledged and identified within the contents. I am aware of the University of Warwick regulation concerning plagiarism and collusion. 

No substantial part(s) of the work  submitted  here has also been submitted by me in other assessments for accredited courses of study, and I acknowledge that if this has been done an appropriate reduction in the mark I might otherwise have received will be made

---
---
```{r Install the packages}
# Install all necesssary package
# install.packages("tidyverse")
# install.packages("readr")
# install.packages("colorspace")
# install.packages("vctrs")
# install.packages("gtrendsR")
# install.packages("plotly")
# install.packages("DescTools")
# install.packages("latticeExtra")
# install.packages("gridExtra")
# install.packages("aTSA")
# install.packages("tidytext")
# install.packages("MLmetrics")
# install.packages("vars")
# install.packages("tsDyn")
# install.packages("dplyr")
# install.packages("tsibble")
# install.packages("fabletools")
# install.packages("fpp2")
# install.packages("fpp3")
# install.packages("readr")
# install.packages("lubridate")
# install.packages("fable")
# install.packages("GGally")
# install.packages("forecast")
# install.packages("urca")
# install.packages("tseries")
# install.packages("FinTS")
# install.packages("lmtest")
# install.packages("MuMIn")
# install.packages("carData")
# install.packages("ggcorrplot")
# install.packages("tableHTML")
# install.packages("caret")
# install.packages("broom")
```

# Loading library
```{r}
# Load necessary library
library(ggplot2)
library(xts)
library(plotly)
library(stats)
library(forecast)
library(DescTools)
library(tseries)
library(gtrendsR)
library(gridExtra)
library(latticeExtra)
library(scales)
library(aTSA) # For Coint
library(urca)
library(Hmisc)
library(tidytext)
library(MLmetrics)
library(vars)
library(tsDyn) # for VECM
library(dplyr)
library(tidyverse)
library(tsibble)
library(fabletools)
library(fpp2)
library(fpp3)
library(readr)
library(lubridate)
library(tidyr)
library(fable)
library(GGally)
library(pastecs)
library(lessR)
library(FinTS)
library(lmtest)
library(MuMIn)
library(grid)
library(car)
library(ggcorrplot) # For correlation matrix visualization
library(tableHTML)
library(caret)
library(broom)
library(reshape2)

```

```{r}
# Check current working directory
getwd()

```

# 1. Data loading and preparation

```{r}
# Read the CSV file
UK_data <- read.csv("UK_data.csv")
E_data <- read.csv ("England_data.csv")
NI_data <- read.csv ("Northern_Ireland_data.csv")
S_data <- read.csv ("Scotland_data.csv")
W_data <- read.csv ("Wales_data.csv")

search_terms <- read.csv ("search_terms.csv")

```

```{r}
# Check for missing values (NA) in the dataset
any(is.na(UK_data))
any(is.na(E_data))
any(is.na(NI_data))
any(is.na(S_data))
any(is.na(W_data))
any(is.na(search_terms))
```


# Date format
```{r}
 # Convert the 'Month' column to date type
UK_data <- UK_data %>%
   mutate(Month = as.Date(Month, format = "%m/%d/%Y"))

E_data <- E_data %>%
   mutate(Month = as.Date(Month, format = "%m/%d/%Y"))

NI_data <- NI_data %>%
   mutate(Month = as.Date(Month, format = "%m/%d/%Y"))

S_data <- S_data %>%
   mutate(Month = as.Date(Month, format = "%m/%d/%Y"))

W_data <- W_data %>%
   mutate(Month = as.Date(Month, format = "%m/%d/%Y"))

search_terms <- search_terms %>%
   mutate(Month = as.Date(Month, format = "%m/%d/%Y"))

```
 
```{r}
 # Check the structure of the data set 
 str(UK_data)
 
 # Summary of the dataset to understand data types and potential issues
 summary(UK_data)
 
 # Check the structure of the data set 
 str(search_terms)
 
 # Summary of the dataset to understand data types and potential issues
 summary(search_terms)
```

```{r}
# First, we check the missing data to ensure about the data integrity of our data set. We found that there is no NA values (missing values) in 'bike_data'
options(tibble.width = Inf)
summarise_all(UK_data, ~sum(is.na(.x)))
```

# Date
```{r}
# Defining different time period

housing_market_time <- UK_data %>%
   mutate(period = case_when(
     Month <= as.Date("2017-02-01") ~ "Pre-Brexit",
     Month >= as.Date("2017-03-01") & Month <= as.Date("2020-02-01") ~ "Brexit",
     Month >= as.Date("2020-02-01") & Month <= as.Date("2021-03-01") ~ "Covid & EU-UK transition",
     Month > as.Date("2021-03-01") ~ "Post-covid"
   ))

# Order the 'period' factor levels
housing_market_time$period <- factor(housing_market_time$period, levels = c("Pre-Brexit", "Brexit", "Covid & EU-UK transition", "Post-covid"))


# Plotting the data with ggplot2
ggplot(housing_market_time, aes(x = Month, y = UK_sale_vol, color = period)) +
  geom_line(size = 1) +
  scale_color_manual(values = c("Pre-Brexit" = "blue", 
                                "Brexit" = "red", 
                                "Covid & EU-UK transition" = "orange", 
                                "Post-covid" = "#008631")) +
  labs(title = "UK Housing Sales Volume Over Time for Different Periods",
       x = "Year",
       y = "Sales Volume",
       color = "Period") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "top")
```


```{r}

# Convert to tsibble
housing_tsibble <- as_tsibble(UK_data, index = Month)

# Timeplot using tsibble and autoplot
autoplot(housing_tsibble, UK_sale_vol) +
  ggtitle("UK Housing Sales Volume Over Time") +
  xlab("Monthly") + ylab("Sales Volume (units)") +
  theme_grey() +
  theme(plot.title = element_text(hjust = 0.5))


```

# Convert data into Time Series
```{r}

# Convert data into Time Series (frequency = 12 for monthly data)
UK_sales_ts <- ts(UK_data$UK_sale_vol, frequency = 12, start = c(2005, 1))
# Show the structure of the time series dataset
str(UK_sales_ts)

# Convert data into Time Series (frequency = 12 for monthly data)
E_sales_ts <- ts(E_data$E_sale_vol, frequency = 12, start = c(2005, 1))
# Show the structure of the time series dataset
str(UK_sales_ts)

# Convert data into Time Series (frequency = 12 for monthly data)
NI_sales_ts <- ts(NI_data$NI_sale_vol, frequency = 12, start = c(2005, 1))
# Show the structure of the time series dataset
str(NI_sales_ts)

# Convert data into Time Series (frequency = 12 for monthly data)
S_sales_ts <- ts(S_data$S_sale_vol, frequency = 12, start = c(2005, 1))
# Show the structure of the time series dataset
str(S_sales_ts)

# Convert data into Time Series (frequency = 12 for monthly data)
W_sales_ts <- ts(W_data$W_sale_vol, frequency = 12, start = c(2005, 1))
# Show the structure of the time series dataset
str(W_sales_ts)

```

```{r}
# Plot the time series data
plot(UK_sales_ts, main = "UK Housing Sales Volume", xlab = "Time", ylab = "Sales Volume")
grid()

```

```{r}
autoplot(UK_sales_ts, size = 0.7) +
  scale_x_continuous(expand = c(0.05, 0)) +
  scale_y_continuous(expand = c(0.05, 0)) +
  theme(plot.margin = margin(10, 10, 10, 10))

```

```{r}
grid.arrange(
  autoplot(UK_sales_ts) + theme(plot.margin = unit(c(0, 1, 0, 0), "lines")),
  autoplot(E_sales_ts) + theme(plot.margin = unit(c(0, 1, 0, 0), "lines")),
  autoplot(NI_sales_ts) + theme(plot.margin = unit(c(0, 1, 0, 0), "lines")),
  autoplot(S_sales_ts) + theme(plot.margin = unit(c(0, 1, 0, 0), "lines")),
  autoplot(W_sales_ts) + theme(plot.margin = unit(c(0, 1, 0, 0), "lines")),
  ncol = 2, nrow = 3
)
```


```{r}
# Convert data into Time Series (frequency = 12 for monthly data)
UK_house_sales <- ts(UK_data$UK_sale_vol, frequency = 12, start = c(2005, 1))
# Show the structure of the time series dataset


# Convert data into Time Series (frequency = 12 for monthly data)
E_house_sales <- ts(E_data$E_sale_vol, frequency = 12, start = c(2005, 1))
# Show the structure of the time series dataset


# Convert data into Time Series (frequency = 12 for monthly data)
NI_house_sales <- ts(NI_data$NI_sale_vol, frequency = 12, start = c(2005, 1))
# Show the structure of the time series dataset


# Convert data into Time Series (frequency = 12 for monthly data)
S_house_sales <- ts(S_data$S_sale_vol, frequency = 12, start = c(2005, 1))
# Show the structure of the time series dataset


# Convert data into Time Series (frequency = 12 for monthly data)
W_house_sales <- ts(W_data$W_sale_vol, frequency = 12, start = c(2005, 1))
# Show the structure of the time series dataset

```

# Exploratory Data Analysis (EDA)
```{r}
# Seasonal decomposition of UK housing sales
decomposed <- stl(UK_sales_ts, s.window = "periodic")
autoplot(decomposed) +
  ggtitle("Seasonal Decomposition of UK Housing Sales") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
# Check seasonality
seasonplot(UK_sales_ts, main = "Seasonal plot of UK Housing Sales", col = 1, lwd = 1.5)

```


```{r}
# Generate a seasonal subseries plot for the log-transformed UK sales training data

monthplot(UK_sales_ts,lwd = 1.5 )

```

# Plot for each region
```{r}
grid.arrange(
  autoplot(E_sales_ts) + 
    ggtitle("England Housing Sales") + 
    ylab("Sales Volume") + 
    xlab("Time") +
    theme(plot.margin = unit(c(0.5, 1, 0.5, 0.5), "lines"),  # Adjust margins
          plot.title = element_text(size = 9, hjust = 0.5),  # Center the title
          axis.title.x = element_text(size = 8),
          axis.title.y = element_text(size = 8)),
  
  autoplot(NI_sales_ts) + 
    ggtitle("Northern Ireland Housing Sales") + 
    ylab("Sales Volume") + 
    xlab("Time") +
    theme(plot.margin = unit(c(0.5, 1, 0.5, 0.5), "lines"),  # Adjust margins
          plot.title = element_text(size = 9, hjust = 0.5),
          axis.title.x = element_text(size = 8),
          axis.title.y = element_text(size = 8)),
  
  autoplot(S_sales_ts) + 
    ggtitle("Scotland Housing Sales") + 
    ylab("Sales Volume") + 
    xlab("Time") +
    theme(plot.margin = unit(c(0.5, 1, 0.5, 0.5), "lines"),  # Adjust margins
          plot.title = element_text(size = 9, hjust = 0.5),
          axis.title.x = element_text(size = 8),
          axis.title.y = element_text(size = 8)),
  
  autoplot(W_sales_ts) + 
    ggtitle("Wales Housing Sales") + 
    ylab("Sales Volume") + 
    xlab("Time") +
    theme(plot.margin = unit(c(0.5, 1, 0.5, 0.5), "lines"),  # Adjust margins
          plot.title = element_text(size = 9, hjust = 0.5),
          axis.title.x = element_text(size = 8),
          axis.title.y = element_text(size = 8)),
  
  ncol = 2, nrow = 2
)
```

# 3. Search Interest Index (SII)

### 3.1. Test correlation and determined lag

### 3.1.1. UK series

```{r}
# Extract only columns related to UK data
UK_search_terms <- grep("^UK_", colnames(search_terms), value = TRUE)

str(UK_search_terms)

# Select only UK related columns
UK_st_data <- search_terms %>% select(all_of(UK_search_terms ))

str(UK_st_data)

```

```{r}

# Initialize an empty dataframe with the same number of rows as UK_st_data
UK_ccf <- data.frame(matrix(ncol = 0, nrow = nrow(UK_st_data)))

# Loop through each UK search term column and calculate CCF with reference_column
for (term in UK_search_terms) {
    # Select the current term data
    x_variable <- UK_st_data %>% select(term)
    
    # Calculate the cross-correlation function
    ccf_result <- ccf(x_variable, UK_data$UK_sale_vol)
    
    # Find the maximum cross-correlation
    max_ccf <- data.frame(x_series = term, lag = ccf_result$lag, acf = ccf_result$acf) %>%
        arrange(desc(acf)) %>%
        slice(1)
    
    # Combine the results
    UK_ccf <- rbind(UK_ccf, max_ccf)
}

print(UK_ccf)
```

```{r}
UK_ccf <- UK_ccf %>% mutate(y_series = "UK")
```

### 3.1.2. England series

```{r}
# Extract only columns related to England data
E_search_terms <- grep("^E_", colnames(search_terms), value = TRUE)

str(E_search_terms)

# Select only England related columns
E_st_data <- search_terms %>% select(all_of(E_search_terms))

str(E_st_data)

print(E_st_data)

```

```{r}

# Initialize an empty dataframe with the same number of rows as E_st_data
E_ccf <- data.frame(matrix(ncol = 0, nrow = nrow(E_st_data)))

# Loop through each England search term column and calculate CCF with reference_column
for (term in E_search_terms) {
    # Select the current term data
    x_variable <- E_st_data %>% select(term)
    
    # Calculate the cross-correlation function
    ccf_result <- ccf(x_variable, E_data$E_sale_vol)
    
    # Find the maximum cross-correlation
    max_ccf <- data.frame(x_series = term, lag = ccf_result$lag, acf = ccf_result$acf) %>%
        arrange(desc(acf)) %>%
        slice(1)
    
    # Combine the results
    E_ccf <- rbind(E_ccf, max_ccf)
}

print(E_ccf)
```

```{r}
E_ccf <- E_ccf %>% mutate(y_series = "England")
```

### 3.1.3. Northern Ireland series

```{r}
# Extract only columns related to UK data
NI_search_terms <- grep("^NI_", colnames(search_terms), value = TRUE)

str(NI_search_terms)

# Select only UK related columns
NI_st_data <- search_terms %>% select(all_of(NI_search_terms ))

str(NI_st_data)

```

```{r}

# Initialize an empty dataframe with the same number of rows as S_st_data
NI_ccf <- data.frame(matrix(ncol = 0, nrow = nrow(NI_st_data)))

# Loop through each Scotland search term column and calculate CCF with reference_column
for (term in NI_search_terms) {
    # Select the current term data
    x_variable <- NI_st_data %>% select(term)
    
    # Calculate the cross-correlation function
    ccf_result <- ccf(x_variable, NI_data$NI_sale_vol)
    
    # Find the maximum cross-correlation
    max_ccf <- data.frame(x_series = term, lag = ccf_result$lag, acf = ccf_result$acf) %>%
        arrange(desc(acf)) %>%
        slice(1)
    
    # Combine the results
    NI_ccf <- rbind(NI_ccf, max_ccf)
}

print(NI_ccf)
```

```{r}
NI_ccf <- NI_ccf %>% mutate(y_series = "Northern Ireland")
```

### 3.1.4. Scotland series

```{r}
# Extract only columns related to UK data
S_search_terms <- grep("^S_", colnames(search_terms), value = TRUE)

str(S_search_terms)

# Select only UK related columns
S_st_data <- search_terms %>% select(all_of(S_search_terms ))

str(S_st_data)

```

```{r}
# Initialize an empty dataframe with the same number of rows as S_st_data
S_ccf <- data.frame(matrix(ncol = 0, nrow = nrow(S_st_data)))

# Loop through each Scotland search term column and calculate CCF with reference_column
for (term in S_search_terms) {
    # Select the current term data
    x_variable <- S_st_data %>% select(term)
    
    # Calculate the cross-correlation function
    ccf_result <- ccf(x_variable, S_data$S_sale_vol)
    
    # Find the maximum cross-correlation
    max_ccf <- data.frame(x_series = term, lag = ccf_result$lag, acf = ccf_result$acf) %>%
        arrange(desc(acf)) %>%
        slice(1)
    
    # Combine the results
    S_ccf <- rbind(S_ccf, max_ccf)
}

print(S_ccf)
```

```{r}
S_ccf <- S_ccf %>% mutate(y_series = "Scotland")
```


### 3.1.5. Wales series

```{r}
# Extract only columns related to UK data
W_search_terms <- grep("^W_", colnames(search_terms), value = TRUE)

str(W_search_terms)

# Select only UK related columns
W_st_data <- search_terms %>% select(all_of(W_search_terms ))

str(W_st_data)

```

```{r}
# Initialize an empty dataframe with the same number of rows as UK_st_data
W_ccf <- data.frame(matrix(ncol = 0, nrow = nrow(W_st_data)))

# Loop through each UK search term column and calculate CCF with reference_column
for (term in W_search_terms) {
    # Select the current term data
    x_variable <- W_st_data %>% select(term)
    
    # Calculate the cross-correlation function
    ccf_result <- ccf(x_variable, W_data$W_sale_vol)
    
    # Find the maximum cross-correlation
    max_ccf <- data.frame(x_series = term, lag = ccf_result$lag, acf = ccf_result$acf) %>%
        arrange(desc(acf)) %>%
        slice(1)
    
    # Combine the results
    W_ccf <- rbind(W_ccf, max_ccf)
}

print(W_ccf)
```

```{r}
W_ccf <- W_ccf %>% mutate(y_series = "Wales")
```

### 3.1.6. Bind all correlation result

```{r}
all_ccf <- rbind(UK_ccf,E_ccf,NI_ccf,S_ccf,W_ccf) 

(all_ccf <- all_ccf%>%mutate(lag = ifelse(lag > 0,0,lag)))

all_ccf %>% 
  select(y_series,x_series,lag,acf)%>% 
  mutate(lag = -lag, acf = round(acf,2))%>% 
  tableHTML::tableHTML(rownames = FALSE, 
                       widths = rep(150, 4))%>%
  tableHTML::add_theme('scientific')%>%tableHTML::write_tableHTML(file = 'ts_correlation.html')

```

## 3.2. Construct Search Interest Index

### 3.2.1. UK series

```{r}
# Shift and sum

# Extract the lag for each UK time series
UK_lags <- UK_ccf$lag

# Create an empty vector to store the summed values
UK_sii <- numeric(nrow(UK_st_data))

# Iterate over each lag and sum the time series columns
for (i in 1:length(UK_lags)) {
    lag <- UK_lags[i]
    term <- UK_ccf$x_series[i]
    
    # Select the current term data
    x_variable <- UK_st_data %>% pull(term)
    
    # Apply the lag and sum the values
    for (j in 1:nrow(UK_st_data)) {
        shifted_index <- j - lag
        if (shifted_index > 0 && shifted_index <= nrow(UK_st_data)) {
            UK_sii[j] <- UK_sii[j] + x_variable[shifted_index]
        }
    }
}

# Plot the result
plot(UK_sii, type = "o", main = "UK Search Interest Index (SII)", xlab = "Time", ylab = "UK_sii")

```

```{r}
print (ccf(UK_sii, UK_data$UK_sale_vol))

```

The CCF analysis shows that there are significant correlations between UK_sii and UK_sale_vol at various lags, with the most notable correlations occurring at negative lags. This suggests that the sale volume can be used to predict the search interest index with some lead time, and vice versa. The lack of significant correlation at lag zero indicates that the two time series do not move together instantaneously.

#### ADF test
```{r}
adf.test(UK_sii)

tseries::adf.test(UK_sii)

# Create ts object for sii 
ts_UK_sii <- ts(UK_sii, frequency = 12, start = c(2005, 1)) 

# Create time series tsdisplay(ts_UK_sii)
tsdisplay(ts_UK_sii)
ggtsdisplay(ts_UK_sii, main = "Time Series, ACF and PACF of ts_UK_sii")

```

The ADF test results across different configurations consistently suggest that the UK_sii time series is non-stationary:

- High p-values in all configurations indicate a failure to reject the null hypothesis of a unit root.

- ADF statistics are not sufficiently negative to indicate stationarity.

- Non-stationarity implies that the time series has some form of trend or seasonality that is not constant over time.

```{r}
seasonplot(ts_UK_sii)
```

#### Differencing 1
```{r}
d_UK_sii <- ts_UK_sii%>%diff(lag = 12, difference = 1) # Difference to remove seasonal 
tsdisplay(d_UK_sii)

```

```{r}
# ADF test
tseries::adf.test(d_UK_sii)

plot(d_UK_sii, type = "o")
```

Non-Stationarity: The high p-value (0.9771) and the relatively non-negative Dickey-Fuller statistic indicate that there is insufficient evidence to reject the null hypothesis of a unit root.

Implication: This means that even after differencing, the time series d_UK_sii is still considered non-stationary. The series likely still contains trends, seasonality, or other forms of non-stationarity

#### Differencing 2

```{r}

dd_UK_sii <- d_UK_sii%>%diff(lag = 1, difference = 1) # Difference to remove trend 

tsdisplay(dd_UK_sii)

```

```{r}
# ADF test
tseries::adf.test(dd_UK_sii)
plot(dd_UK_sii, type = "o")

```

Stationarity: The low p-value (0.01) and the highly negative Dickey-Fuller statistic (-5.6646) provide strong evidence to reject the null hypothesis. This means the twice differenced time series dd_UK_sii is stationary.

Implication: The time series dd_UK_sii does not contain a unit root and can be considered stable over time after being differenced twice.

#### Co-integration test
```{r}
UK_cojo_input <- data.frame(ts_UK_sii,UK_sales_ts) 

VARselect(UK_cojo_input, lag.max = 12, type = "both")

UK_cojo_result <- ca.jo(UK_cojo_input, type = "trace", ecdet = "trend", spec = "longrun", season = 12, K = 2)

# Rejecting r=0 but not r<=1, 2 series are co-integrate with 1 relationship
summary(UK_cojo_result)
```

### 3.2.2. England series

```{r}
# Shift and sum

# Extract the lag for each UK time series
E_lags <- E_ccf$lag
```

```{r}

# Create an empty vector to store the summed values
E_sii <- numeric(nrow(E_st_data))

# Iterate over each lag and sum the time series columns
for (i in 1:length(E_lags)) {
    lag <- E_lags[i]
    term <- E_ccf$x_series[i]
    
    # Select the current term data
    x_variable <- E_st_data %>% pull(term)
    
    # Apply the lag and sum the values
    for (j in 1:nrow(E_st_data)) {
        shifted_index <- j - lag
        if (shifted_index > 0 && shifted_index <= nrow(E_st_data)) {
            E_sii[j] <- E_sii[j] + x_variable[shifted_index]
        }
    }
}

# Plot the result
plot(E_sii, type = "o", main = "England Search Interest Index (SII)", xlab = "Time", ylab = "E_sii")

```

```{r}
print (ccf(E_sii, E_data$E_sale_vol))
```

The CCF analysis shows that there are significant correlations between UK_sii and UK_sale_vol at various lags, with the most notable correlations occurring at negative lags. This suggests that the sale volume can be used to predict the search interest index with some lead time, and vice versa. The lack of significant correlation at lag zero indicates that the two time series do not move together instantaneously.

#### ADF test
```{r}
adf.test(E_sii)

tseries::adf.test(E_sii)

# Create ts object for sii 
ts_E_sii <- ts(E_sii, frequency = 12, start = c(2005, 1)) 

# Create time series tsdisplay(ts_E_sii)
tsdisplay(ts_E_sii)
ggtsdisplay(ts_E_sii, main = "Time Series, ACF and PACF of ts_E_sii")

```

The ADF test results across different configurations consistently suggest that the UK_sii time series is non-stationary:

- High p-values in all configurations indicate a failure to reject the null hypothesis of a unit root.

- ADF statistics are not sufficiently negative to indicate stationarity.

- Non-stationarity implies that the time series has some form of trend or seasonality that is not constant over time.

```{r}
seasonplot(ts_E_sii)
```

#### Differencing 1
```{r}
d_E_sii <- ts_E_sii%>%diff(lag = 12, difference = 1) # Difference to remove seasonal 
tsdisplay(d_E_sii)

```

```{r}
# ADF test
tseries::adf.test(d_E_sii)

plot(d_E_sii, type = "o")
```

Non-Stationarity: The high p-value (0.9771) and the relatively non-negative Dickey-Fuller statistic indicate that there is insufficient evidence to reject the null hypothesis of a unit root.

Implication: This means that even after differencing, the time series d_UK_sii is still considered non-stationary. The series likely still contains trends, seasonality, or other forms of non-stationarity

#### Differencing 2

```{r}

dd_E_sii <- d_E_sii%>%diff(lag = 1, difference = 1) # Difference to remove trend 

tsdisplay(dd_E_sii)

```

```{r}
# ADF test
tseries::adf.test(dd_E_sii)
plot(dd_E_sii, type = "o")

```

Stationarity: The low p-value (0.01) and the highly negative Dickey-Fuller statistic (-5.6646) provide strong evidence to reject the null hypothesis. This means the twice differenced time series dd_UK_sii is stationary.

Implication: The time series dd_UK_sii does not contain a unit root and can be considered stable over time after being differenced twice.

#### Co-integration test
```{r}
E_cojo_input <- data.frame(ts_E_sii,E_sales_ts) 

VARselect(E_cojo_input, lag.max = 12, type = "both")

E_cojo_result <- ca.jo(E_cojo_input, type = "trace", ecdet = "trend", spec = "longrun", season = 12, K = 2)

# Rejecting r=0 but not r<=1, 2 series are co-integrate with 1 relationship
summary(E_cojo_result)
```

### 3.2.3. Northern Ireland series

```{r}
# Shift and sum

# Extract the lag for each UK time series
NI_lags <- NI_ccf$lag

# Create an empty vector to store the summed values
NI_sii <- numeric(nrow(NI_st_data))

# Iterate over each lag and sum the time series columns
for (i in 1:length(NI_lags)) {
    lag <- NI_lags[i]
    term <- NI_ccf$x_series[i]
    
    # Select the current term data
    x_variable <- NI_st_data %>% pull(term)
    
    # Apply the lag and sum the values
    for (j in 1:nrow(NI_st_data)) {
        shifted_index <- j - lag
        if (shifted_index > 0 && shifted_index <= nrow(NI_st_data)) {
            NI_sii[j] <- NI_sii[j] + x_variable[shifted_index]
        }
    }
}

# Plot the result
plot(NI_sii, type = "o", main = "Northern Ireland Search Interest Index (SII)", xlab = "Time", ylab = "NI_sii")

```

```{r}
print (ccf(NI_sii, NI_data$NI_sale_vol))

```

The CCF analysis shows that there are significant correlations between UK_sii and UK_sale_vol at various lags, with the most notable correlations occurring at negative lags. This suggests that the sale volume can be used to predict the search interest index with some lead time, and vice versa. The lack of significant correlation at lag zero indicates that the two time series do not move together instantaneously.

#### ADF test
```{r}
adf.test(NI_sii)

tseries::adf.test(NI_sii)

# Create ts object for sii 
ts_NI_sii <- ts(NI_sii, frequency = 12, start = c(2005, 1)) 

# Create time series tsdisplay(ts_NI_sii)
tsdisplay(ts_NI_sii)
ggtsdisplay(ts_NI_sii, main = "Time Series, ACF and PACF of ts_NI_sii")

```

The ADF test results across different configurations consistently suggest that the UK_sii time series is non-stationary:

- High p-values in all configurations indicate a failure to reject the null hypothesis of a unit root.

- ADF statistics are not sufficiently negative to indicate stationarity.

- Non-stationarity implies that the time series has some form of trend or seasonality that is not constant over time.

```{r}
seasonplot(ts_NI_sii)
```

#### Differencing 1
```{r}
d_NI_sii <- ts_NI_sii%>%diff(lag = 12, difference = 1) # Difference to remove seasonal 
tsdisplay(d_NI_sii)

```

```{r}
# ADF test
tseries::adf.test(d_NI_sii)

plot(d_NI_sii, type = "o")
```

Non-Stationarity: The high p-value (0.9771) and the relatively non-negative Dickey-Fuller statistic indicate that there is insufficient evidence to reject the null hypothesis of a unit root.

Implication: This means that even after differencing, the time series d_UK_sii is still considered non-stationary. The series likely still contains trends, seasonality, or other forms of non-stationarity

#### Differencing 2

```{r}

dd_NI_sii <- d_NI_sii%>%diff(lag = 1, difference = 1) # Difference to remove trend 

tsdisplay(dd_NI_sii)

```

```{r}
# ADF test
tseries::adf.test(dd_NI_sii)
plot(dd_NI_sii, type = "o")

```

Stationarity: The low p-value (0.01) and the highly negative Dickey-Fuller statistic (-5.6646) provide strong evidence to reject the null hypothesis. This means the twice differenced time series dd_UK_sii is stationary.

Implication: The time series dd_UK_sii does not contain a unit root and can be considered stable over time after being differenced twice.

#### Co-integration test
```{r}
NI_cojo_input <- data.frame(ts_NI_sii,NI_sales_ts) 

VARselect(NI_cojo_input, lag.max = 12, type = "both")

NI_cojo_result <- ca.jo(NI_cojo_input, type = "trace", ecdet = "trend", spec = "longrun", season = 12, K = 2)

# Rejecting r=0 but not r<=1, 2 series are co-integrate with 1 relationship
summary(NI_cojo_result)
```


### 3.2.2. Scotland series


```{r}
# Shift and sum

# Extract the lag for each UK time series
S_lags <- S_ccf$lag

# Create an empty vector to store the summed values
S_sii <- numeric(nrow(S_st_data))

# Iterate over each lag and sum the time series columns
for (i in 1:length(S_lags)) {
    lag <- S_lags[i]
    term <- S_ccf$x_series[i]
    
    # Select the current term data
    x_variable <- S_st_data %>% pull(term)
    
    # Apply the lag and sum the values
    for (j in 1:nrow(S_st_data)) {
        shifted_index <- j - lag
        if (shifted_index > 0 && shifted_index <= nrow(S_st_data)) {
            S_sii[j] <- S_sii[j] + x_variable[shifted_index]
        }
    }
}

# Plot the result
plot(S_sii, type = "o", main = "Scotland Search Interest Index (SII)", xlab = "Time", ylab = "S_sii")

```

```{r}
print (ccf(S_sii, S_data$S_sale_vol))

```

The CCF analysis shows that there are significant correlations between UK_sii and UK_sale_vol at various lags, with the most notable correlations occurring at negative lags. This suggests that the sale volume can be used to predict the search interest index with some lead time, and vice versa. The lack of significant correlation at lag zero indicates that the two time series do not move together instantaneously.

#### ADF test
```{r}
adf.test(S_sii)

tseries::adf.test(S_sii)

# Create ts object for sii 
ts_S_sii <- ts(S_sii, frequency = 12, start = c(2005, 1)) 

# Create time series tsdisplay(ts_S_sii)
tsdisplay(ts_S_sii)
ggtsdisplay(ts_S_sii, main = "Time Series, ACF and PACF of ts_S_sii")

```

The ADF test results across different configurations consistently suggest that the UK_sii time series is non-stationary:

- High p-values in all configurations indicate a failure to reject the null hypothesis of a unit root.

- ADF statistics are not sufficiently negative to indicate stationarity.

- Non-stationarity implies that the time series has some form of trend or seasonality that is not constant over time.

```{r}
seasonplot(ts_S_sii)
```

#### Differencing 1
```{r}
d_S_sii <- ts_S_sii%>%diff(lag = 12, difference = 1) # Difference to remove seasonal 
tsdisplay(d_S_sii)

```

```{r}
# ADF test
tseries::adf.test(d_S_sii)

plot(d_S_sii, type = "o")
```

Non-Stationarity: The high p-value (0.9771) and the relatively non-negative Dickey-Fuller statistic indicate that there is insufficient evidence to reject the null hypothesis of a unit root.

Implication: This means that even after differencing, the time series d_UK_sii is still considered non-stationary. The series likely still contains trends, seasonality, or other forms of non-stationarity

#### Differencing 2

```{r}
dd_S_sii <- d_S_sii%>%diff(lag = 1, difference = 1) # Difference to remove trend 

tsdisplay(dd_S_sii)
```

```{r}
# ADF test
tseries::adf.test(dd_S_sii)
plot(dd_S_sii, type = "o")
```

Stationarity: The low p-value (0.01) and the highly negative Dickey-Fuller statistic (-5.6646) provide strong evidence to reject the null hypothesis. This means the twice differenced time series dd_UK_sii is stationary.

Implication: The time series dd_UK_sii does not contain a unit root and can be considered stable over time after being differenced twice.

#### Co-integration test
```{r}
S_cojo_input <- data.frame(ts_S_sii,S_sales_ts) 

VARselect(S_cojo_input, lag.max = 12, type = "both")

S_cojo_result <- ca.jo(S_cojo_input, type = "trace", ecdet = "trend", spec = "longrun", season = 12, K = 2)

# Rejecting r=0 but not r<=1, 2 series are co-integrate with 1 relationship
summary(S_cojo_result)
```

### 3.2.2. Wales series

```{r}
# Shift and sum

# Extract the lag for each UK time series
W_lags <- W_ccf$lag

# Create an empty vector to store the summed values
W_sii <- numeric(nrow(W_st_data))

# Iterate over each lag and sum the time series columns
for (i in 1:length(W_lags)) {
    lag <- W_lags[i]
    term <- W_ccf$x_series[i]
    
    # Select the current term data
    x_variable <- W_st_data %>% pull(term)
    
    # Apply the lag and sum the values
    for (j in 1:nrow(W_st_data)) {
        shifted_index <- j - lag
        if (shifted_index > 0 && shifted_index <= nrow(W_st_data)) {
            W_sii[j] <- W_sii[j] + x_variable[shifted_index]
        }
    }
}

# Plot the result
plot(W_sii, type = "o", main = "Wales Search Interest Index (SII)", xlab = "Time", ylab = "W_sii")

```

```{r}
print (ccf(W_sii, W_data$W_sale_vol))

```

The CCF analysis shows that there are significant correlations between UK_sii and UK_sale_vol at various lags, with the most notable correlations occurring at negative lags. This suggests that the sale volume can be used to predict the search interest index with some lead time, and vice versa. The lack of significant correlation at lag zero indicates that the two time series do not move together instantaneously.

#### ADF test
```{r}
adf.test(W_sii)

tseries::adf.test(W_sii)

# Create ts object for sii 
ts_W_sii <- ts(W_sii, frequency = 12, start = c(2005, 1)) 

# Create time series tsdisplay(ts_W_sii)
tsdisplay(ts_W_sii)
ggtsdisplay(ts_W_sii, main = "Time Series, ACF and PACF of ts_W_sii")

```

The ADF test results across different configurations consistently suggest that the UK_sii time series is non-stationary:

- High p-values in all configurations indicate a failure to reject the null hypothesis of a unit root.

- ADF statistics are not sufficiently negative to indicate stationarity.

- Non-stationarity implies that the time series has some form of trend or seasonality that is not constant over time.

```{r}
seasonplot(ts_W_sii)
```

#### Differencing 1
```{r}
d_W_sii <- ts_W_sii%>%diff(lag = 12, difference = 1) # Difference to remove seasonal 
tsdisplay(d_W_sii)

```

```{r}
# ADF test
tseries::adf.test(d_W_sii)

plot(d_W_sii, type = "o")
```

Non-Stationarity: The high p-value (0.9771) and the relatively non-negative Dickey-Fuller statistic indicate that there is insufficient evidence to reject the null hypothesis of a unit root.

Implication: This means that even after differencing, the time series d_UK_sii is still considered non-stationary. The series likely still contains trends, seasonality, or other forms of non-stationarity

#### Differencing 2

```{r}

dd_W_sii <- d_W_sii%>%diff(lag = 1, difference = 1) # Difference to remove trend 

tsdisplay(dd_W_sii)
```

```{r}
# ADF test
tseries::adf.test(dd_W_sii)
plot(dd_W_sii, type = "o")
```

Stationarity: The low p-value (0.01) and the highly negative Dickey-Fuller statistic (-5.6646) provide strong evidence to reject the null hypothesis. This means the twice differenced time series dd_UK_sii is stationary.

Implication: The time series dd_UK_sii does not contain a unit root and can be considered stable over time after being differenced twice.

#### Co-integration test
```{r}
W_cojo_input <- data.frame(ts_W_sii,W_sales_ts) 

VARselect(W_cojo_input, lag.max = 12, type = "both")

W_cojo_result <- ca.jo(W_cojo_input, type = "trace", ecdet = "trend", spec = "longrun", season = 12, K = 2)

# Rejecting r=0 but not r<=1, 2 series are co-integrate with 1 relationship
summary(W_cojo_result)
```

## 3.3. Summary

```{r}
# Print all the composite search interest index
ts_UK_sii
ts_E_sii
ts_NI_sii
ts_S_sii
ts_W_sii
```

```{r}
autoplot(ts_NI_sii, size = 0.7) +
  scale_x_continuous(expand = c(0.05, 0)) +
  scale_y_continuous(expand = c(0.05, 0)) +
  theme(plot.margin = margin(10, 10, 10, 10))

```

```{r}
# Plot the composite search interest index
autoplot(ts_UK_sii)
autoplot(ts_E_sii)
autoplot(ts_NI_sii)
autoplot(ts_S_sii)
autoplot(ts_W_sii)
```

```{r}
grid.arrange(
  autoplot(ts_UK_sii) + theme(plot.margin = unit(c(0, 1, 0, 0), "lines")),
  autoplot(ts_E_sii) + theme(plot.margin = unit(c(0, 1, 0, 0), "lines")),
  autoplot(ts_NI_sii) + theme(plot.margin = unit(c(0, 1, 0, 0), "lines")),
  autoplot(ts_S_sii) + theme(plot.margin = unit(c(0, 1, 0, 0), "lines")),
  autoplot(ts_W_sii) + theme(plot.margin = unit(c(0, 1, 0, 0), "lines")),
  ncol = 2, nrow = 3
)
```

# 4. Model Development

## Define functions
```{r}
# Create function to test model 

# ADF test

adf_loop <- function(x,m) { 
  adf_list <- data.frame() 
  for (l in 1:m) { 
    adf_temp <- tseries::adf.test(x, k = l) 
    adf_list <- rbind(adf_list,cbind(as.numeric(adf_temp$parameter),round(adf_temp$p.value,2))) } 
  print(adf_list) }

# Add KPSS test function
kpss_test <- function(x) {
  kpss_result <- kpss.test(x)
  print(kpss_result)
}

# Function to perform the Ljung-Box test for a given model and lags
perform_ljung_box_test <- function(model, lags) {
  residuals <- residuals(model)
  for (lag in lags) {
    lb_test <- Box.test(residuals, lag = lag, type = "Ljung-Box")
    chi_square <- lb_test$statistic
    df <- lb_test$parameter
    p_value <- lb_test$p.value
    cat("Lag:", lag, "Chi-Square:", chi_square, "DF:", df, "P-Value:", p_value, "\n")
  }
}

# Box-Jenkins Model test 
bjm_test <- function(x){ 
  print(lmtest::coeftest(x)) 
  for (lag in c(12)){ 
    print(Box.test(x$residuals, lag = lag, type = "Ljung-Box")) 
    print(qchisq(0.05, lag, lower.tail = F)) } }

# Plotting

plot_res <- function(x){ 
  cat("Residuals of ",deparse(substitute(x))) 
  par(mfrow=c(2,2)) 
  plot(x, main = "Residuals") 
  acf(x, main = "Residuals ACF", lag.max = 60) 
  pacf(x, main = "Residuals PACF", lag.max = 60) 
  hist(x, main = "Histogram of Residuals") }


plot_fore <- function(y, fore) {
  plot(y, main = paste(fore$series, "forecast", fore$method, "with 95% CI"), 
       xlab = "Time", ylab = "Values", lwd = 2) 
  lines(fore$mean, col = "red", lty = "dashed", lwd = 2) 
  lines(fore$upper[, "95%"], col = "grey", lty = "dashed", lwd = 0.5) 
  lines(fore$lower[, "95%"], col = "grey", lty = "dashed", lwd = 0.5) 
  legend("bottomleft", legend = c("OS Visit", fore$method), 
         col = c("black", "red"), lty = 1:2, cex = 0.8)
}

plot_fore_exp <- function(y, fore) {
  plot(exp(y), main = paste(fore$series, "forecast", fore$method, "with 95% CI"), xlab = "Time", ylab = "Values", lwd = 2)
  lines(exp(fore$mean), col = "red", lty = "dashed", lwd = 2)
  lines(exp(fore$upper[, "95%"]), col = "grey", lty = "dashed", lwd = 0.5)
  lines(exp(fore$lower[, "95%"]), col = "grey", lty = "dashed", lwd = 0.5)
  legend("bottomleft", legend = c("OS Visit", fore$method), col = c("black", "red"), lty = 1:2, cex = 0.8)
}


# Function to calculate RSS, DF, MS, and AICc for a model
calculate_metrics <- function(model, n) {
  residuals <- residuals(model)
  rss <- sum(residuals^2)
  p <- length(model$coef) # number of estimated parameters
  df <- n - p # degrees of freedom
  ms <- rss / df
  aicc_value <- MuMIn::AICc(model)
  cat("RSS:", rss, "DF:", df, "MS:", ms, "AICc:", aicc_value, "\n")
}

# Shapiro-Wilk test function
shapiro_wilk_test <- function(model) {
  residuals <- residuals(model)
  shapiro_test <- shapiro.test(residuals)
  cat("Shapiro-Wilk normality test:\n")
  cat("W:", shapiro_test$statistic, "P-Value:", shapiro_test$p.value, "\n")
}

# Test Heteroscedasticity

# Function to perform Breusch-Pagan test
perform_breusch_pagan_test <- function(model) {
  bp_test <- bptest(model)
  cat("Breusch-Pagan test for heteroskedasticity:\n")
  cat("BP Statistic:", bp_test$statistic, "DF:", bp_test$parameter, "P-Value:", bp_test$p.value, "\n")
}

# Function to perform ARCH test
perform_arch_test <- function(model, lags) {
  residuals <- residuals(model)
  for (lag in lags) {
    arch_test <- ArchTest(residuals, lags = lag)
    cat("ARCH Test for lag", lag, ":\n")
    cat("Chi-Square:", arch_test$statistic, "DF:", arch_test$parameter, "P-Value:", arch_test$p.value, "\n")
  }
}

# Define a function to calculate AICc
calculate_aicc <- function(model) {
  n <- length(model$x)  # Number of observations
  k <- length(coef(model)) + 1  # Number of parameters (including variance)
  aic <- AIC(model)
  aicc <- aic + (2 * k * (k + 1)) / (n - k - 1)
  return(aicc)
}

# Check parameter estimation
# Custom function to capture parameter estimates at each iteration
capture_iterations <- function(data, order, seasonal_order, period) {
  # Initialize lists to store iteration results
  estimates <- list()
  sse <- list()
  
  # Initialize ARIMA model
  fit <- Arima(data, order = order, seasonal = list(order = seasonal_order, period = period))
  
  # Extract initial estimates and SSE
  estimates[[1]] <- coef(fit)
  sse[[1]] <- sum(residuals(fit)^2)
  
  # Manually iterate to refit the model and capture estimates
  for (i in 1:10) {  # Adjust the number of iterations as needed
    fit <- Arima(data, order = order, seasonal = list(order = seasonal_order, period = period),
                 model = fit)
    estimates[[i + 1]] <- coef(fit)
    sse[[i + 1]] <- sum(residuals(fit)^2)
  }
  
  # Combine estimates and SSE into a dataframe
  iterations_df <- data.frame(Iteration = 0:(length(estimates) - 1),
                              SSE = unlist(sse),
                              do.call(rbind, estimates))
  
  return(list(fit = fit, iterations = iterations_df))
}

# Calculate R-squared
r_squared <- function(actual, predicted) {
  ss_total <- sum((actual - mean(actual))^2)
  ss_res <- sum((actual - predicted)^2)
  1 - (ss_res / ss_total)
}

```

# SARIMA Model
## 4.1. SARIMA for UK series

### 4.1.1. Model building

```{r}
# Store data of Pre-Covid as time series
UK_sales_ts_pre <- UK_sales_ts %>% window (end=c(2020,02))

ggtsdisplay(UK_sales_ts_pre, lag.max=40, main ="Time series, ACF and PACF of UK_sales_ts_pre")

```

```{r}
# Seasonal decomposition
decomposed <- stl(UK_sales_ts_pre, s.window = "periodic")
autoplot(decomposed) +
  ggtitle("Seasonal Decomposition of UK Housing Sales Volume of Pre-Covid period") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
# Convert time series data to data frame
hist_data <- data.frame(UK_sales_ts = as.numeric(UK_sales_ts_pre))

# Histogram of Original Time Series Data
p1 <- ggplot(hist_data, aes(x=UK_sales_ts)) +
  geom_histogram(binwidth=5000, fill='blue', alpha=0.7, color='black') +
  ggtitle("Histogram of UK_sales_ts_pre") +
  theme(plot.title = element_text(hjust=0.5))

# Extract residuals from the decomposition and convert to data frame
residuals <- data.frame(residuals = as.numeric(decomposed$time.series[, "remainder"]))

# Histogram of Residuals
p2 <- ggplot(residuals, aes(x=residuals)) +
  geom_histogram(binwidth=1000, fill='red', alpha=0.7, color='black') +
  ggtitle("Histogram of Residuals") +
  theme(plot.title = element_text(hjust=0.5))

# Combine all plots
grid.arrange(p1, p2, ncol=2)
```

#### Guerrero test

```{r}

# Guerrero test 
guerrero_lambda <- BoxCox.lambda(UK_sales_ts_pre, method = "guerrero")
print(paste("Optimal lambda using Guerrero method:", guerrero_lambda))
```

--> The optimal lambda using the Guerrero method is approximately 0.433. This value suggests that the data would benefit from a transformation to stabilize variance and make the data more suitable for modeling.

Notes: Lambda = 1: No transformation (original data)
       Lambda = 0: Log transformation

#### Log transformation
```{r}
# Log transformation using the optimal lambda
UK_sales_ts_log <- log(UK_sales_ts_pre)

```

```{r}

# Plot the transformed data
autoplot(UK_sales_ts_log) +
  ggtitle("Log Transformed UK Housing Sales Volume\nof Pre-Covid period") +
  xlab("Time") + ylab("Log Transformed Sales Volume") +
  theme(plot.title = element_text(hjust = 0.5))

```

```{r}

# Seasonal decomposition of transformed data
decomposed_log <- stl(UK_sales_ts_log, s.window = "periodic")
autoplot(decomposed_log) +
  ggtitle("Seasonal Decomposition of Log Transformed UK Housing Sales Volume\nof Pre-Covid period") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}

# Display time series, ACF, and PACF of transformed data
ggtsdisplay(UK_sales_ts_log, lag.max = 40, main = 'Time series, ACF, and PACF of Log Transformed UK Housing\nSales of Pre-Covid period ')

```

#### Split the data into training and test sets

```{r}
# Create a training dataset from January 2005 to February 2019
UK_sales_ts_log_train <- window(UK_sales_ts_log, start = c(2005, 1), end = c(2019, 2))

# Create a test dataset from March 2019 to February 2020
UK_sales_ts_log_test <- window(UK_sales_ts_log, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the time series
str(UK_sales_ts_log_train)
str(UK_sales_ts_log_test)

# Print the time series data
print(UK_sales_ts_log_train)
print(UK_sales_ts_log_test)

```

#### Plot of Training and Test dataset
```{r}

# Plot the training and test sets
par(mfrow = c(2, 1), cex.main = 0.9, cex.lab = 0.8, cex.axis = 0.8) # Set up the plotting area for two plots
plot(UK_sales_ts_log_train, main = "Training Set of Log Transformed UK Housing Sales\nVolume", xlab = "Time", ylab = "Log Transformed Sales Volume")
grid()
plot(UK_sales_ts_log_test, main = "Test Set of Log Transformed UK Housing Sales Volume", xlab = "Time", ylab = "Log Transformed Sales Volume")
grid()

```

```{r}
# Reset plotting area to default to ensure subsequent plots are displayed one at a time
par(mfrow = c(1, 1))
```

#### Time series comparision 
```{r}

# Determine the range of the combined dataset for consistent y-axis limits
combined_range <- range(c(UK_sales_ts_log_train, UK_sales_ts_log_test))


# Overlay plot for comparison with thicker lines and adjusted axes
plot(UK_sales_ts_log_train, main = "Time Series Comparison", ylab = "Values", xlab = "Time", lwd = 2, ylim = combined_range, xlim = c(time(UK_sales_ts_log_train)[1], time(UK_sales_ts_log_test)[length(UK_sales_ts_log_test)]))
lines(UK_sales_ts_log_test, col = "red", lwd = 2)
legend("bottomright", legend = c("Train", "Test"), col = c("black", "red"), lty = 1, lwd = 2)

```

```{r}
# Check seasonality
seasonplot(UK_sales_ts_log_train, main = "Seasonal plot: UK_sales_ts_log_train", col = 1, lwd = 1.5)

```
There are observable seasonal fluctuations where certain months consistently exhibit higher sales values compared to others. For example, sales values tend to peak in certain months like May and July across multiple years, indicating potential seasonal effects. Additionally, the spread of the lines, especially in the middle of the year, suggests significant variability in sales from year to year. This variability implies that while seasonality is present, other factors might also be influencing sales, leading to fluctuations that are not solely driven by seasonal trends. The consistent pattern of peaks and troughs across different years reinforces the importance of considering seasonality in any predictive modeling of the sales data. However, the variability also underscores the need to incorporate methods that can handle this unpredictability and potential outliers in the data.

```{r}
# Generate a seasonal subseries plot for the log-transformed UK sales training data

monthplot(UK_sales_ts_log_train,lwd = 1.5 )

```

```{r}
# Generate a combined plot displaying the time series, ACF, and PACF of the log-transformed UK sales training data

ggtsdisplay(UK_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed UK\nHousing Sales training dataset")

```

#### Perform Augmented Dickey-Fuller (ADF) test
```{r}
tseries::adf.test(UK_sales_ts_log_train)

```
The test statistic of -2.8038 is compared against critical values to determine stationarity.

The p-value of 0.2407 is greater than the common significance levels (e.g., 0.01, 0.05, 0.10), indicating that we fail to reject the null hypothesis of non-stationarity.
Therefore, based on this test, the log-transformed UK sales training data is not stationary.


```{r}
# ADF test for three different model types
adf.test(UK_sales_ts_log_train)
```
- For the first type (no drift, no trend), the data is clearly non-stationary.

- For the second type (with drift, no trend), the data may be stationary at lag 0 but not at higher lags.

- For the third type (with drift and trend), the data may be stationary at lag 0 but not at higher lags.

--> Both tests suggest that the log-transformed UK sales training data is not stationary, especially when considering higher lag orders.

#### KPSS test
```{r}

# Perform KPSS test on the training dataset
UK_sales_ts_log_train%>% kpss.test()
```
The results of the KPSS test are mixed depending on the model assumptions:

- Without drift and trend: The data is stationary.
- With drift but no trend: The data is stationary.
- With drift and trend: The data is non-stationary.

Given these results, it is important to consider the nature of your time series data:

- If your time series data is better represented without a trend and drift, it can be considered stationary.

- However, if the data naturally includes a trend and drift, then it appears non-stationary and may require differencing or other transformations to achieve stationarity.

--> Apply differencing to remove the trend and achieve stationarity.

```{r}
#Calculate the number of observations (T)
T_UK_train <- length(UK_sales_ts_log_train)
print(T_UK_train)

# Apply Schwert's Criterion
use_lag_UK_train <- floor(12 * (T_UK_train / 100)^(1/4))
print(use_lag_UK_train)

# Perform KPSS Test with the Chosen Lag
UK_sales_ts_log_train%>% ur.kpss(use.lag = use_lag_UK_train) %>% summary()

```
Based on the KPSS test results with the chosen lag of 13:

The test statistic is lower than the critical values at all common significance levels (10%, 5%, 2.5%, and 1%).

Therefore, we do not have enough evidence to reject the null hypothesis of stationarity.

This means that, according to the KPSS test, your log-transformed UK sales training data is stationary around a constant mean when considering up to 13 lags.

```{r}

# Determine the Number of Seasonal Differencing (D):
D_UK_train <- nsdiffs(UK_sales_ts_log_train)
print(D_UK_train)

```

#### Seasonal Differencing

```{r}
d_UK_sales_ts_log_train <- diff (UK_sales_ts_log_train, lag =12, differences=1)

ggtsdisplay(d_UK_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed UK\nHousing Sales training dataset (D=1)")
```

#### Test again

##### Perform Augmented Dickey-Fuller (ADF) test - Unit root tests
```{r}
tseries::adf.test(d_UK_sales_ts_log_train)
```

ADF test indicates that the differenced log-transformed UK sales training data is stationary at the 5% significance level. This means the seasonal component has been effectively removed, and the series no longer has a unit root.

```{r}
adf.test(d_UK_sales_ts_log_train)
```
No Drift, No Trend: The data is stationary across all lags.
With Drift, No Trend: The data is stationary at lag 0, but not at higher lags.
With Drift and Trend: The data is stationary at lag 0, but not at higher lags.

--> Still need apply normal differencing to remove trend

##### KPSS test
```{r}

# Perform KPSS test on the housing sales volume
d_UK_sales_ts_log_train%>% kpss.test()
```

In all three cases, the p-value is equal to or greater than 0.1, which means we fail to reject the null hypothesis of stationarity. Therefore, based on the KPSS test results, the differenced log-transformed UK sales training data (d_UK_sales_ts_log_train) is considered stationary regardless of whether we account for drift and trend.

```{r}
#Calculate the number of observations (T)
d_T_UK_train <- length(d_UK_sales_ts_log_train)
print(d_T_UK_train)

# Apply Schwert's Criterion
d_use_lag_UK_train <- floor(12 * (d_T_UK_train / 100)^(1/4))
print(d_use_lag_UK_train)

# Perform KPSS Test with the Chosen Lag
d_UK_sales_ts_log_train%>% ur.kpss(use.lag = d_use_lag_UK_train ) %>% summary()

```
The test statistic is lower than the critical values at all common significance levels (10%, 5%, 2.5%, and 1%).

Therefore, we do not have enough evidence to reject the null hypothesis of stationarity.

Based on the KPSS test results with the chosen lag of 13, the differenced log-transformed UK sales training data (d_UK_sales_ts_log_train) is considered stationary around a constant mean

```{r}
#Determine the Number of Normal Differencing (d):
d_UK_train <- ndiffs(d_UK_sales_ts_log_train)
print(d_UK_train)
```

--> No need to do further differencing

### 4.1.2. SARIMA model Selection

```{r}
#SARIMA-1

# Fit a SARIMA model using auto.arima with specified parameters for Automatic Model Selection
UK_sarima_1 <- auto.arima(
  UK_sales_ts_log_train,  # The log-transformed training dataset for UK housing sales volume
  max.p = 4,              # Maximum order of the non-seasonal autoregressive part (AR)
  max.q = 4,              # Maximum order of the non-seasonal moving average part (MA)
  max.P = 4,              # Maximum order of the seasonal autoregressive part (SAR)
  max.Q = 4,              # Maximum order of the seasonal moving average part (SMA)
  max.d = 2,              # Maximum number of non-seasonal differences
  max.D = 2,              # Maximum number of seasonal differences
  start.p = 0,            # Starting value of p in the stepwise procedure
  start.q = 0,            # Starting value of q in the stepwise procedure
  start.P = 0,            # Starting value of P in the stepwise procedure
  start.Q = 0,            # Starting value of Q in the stepwise procedure
  stationary = FALSE,     # If TRUE, restricts search to stationary models
  seasonal = TRUE,        # If FALSE, restricts search to non-seasonal models
  ic = c("aicc", "aic", "bic"),  # Information criteria to be used in model selection (AICc, AIC, BIC)
  stepwise = FALSE,       # If TRUE, will do stepwise selection (faster); here set to FALSE for exhaustive search
  trace = TRUE,           # If TRUE, the list of ARIMA models considered will be reported
  approximation = FALSE,  # If TRUE, estimation is via conditional sums of squares and approximated information criteria; here set to FALSE for exact MLE
  test = c("kpss", "adf", "pp")  # Unit root tests to be used for non-seasonal differencing
)

```

--> Best model: ARIMA(2,0,2)(0,1,1)[12]  

```{r}
# Summary the SARIMA model
summary(UK_sarima_1)
```

#### Calculate Residual Sums of Squares and AICc value
```{r}
# Number of observations in the training set
n_train <- length(UK_sales_ts_log_train)

# Calculate metrics for each model

cat("SARIMA Model Metrics:\n")
calculate_metrics(UK_sarima_1, n_train)
```

### 4.1.3. Residuals Diagnostics
#### Draw Residual Plots

```{r}
# Extract residuals and fitted values
residuals <- as.numeric(residuals(UK_sarima_1))  # Convert to numeric
fitted_values <- as.numeric(fitted(UK_sarima_1)) # Convert to numeric
observations <- seq_along(residuals)

# Create a data frame for plotting
data <- data.frame(Residuals = residuals, Fitted = fitted_values, Observation = observations)

# 1. Normal Probability Plot
p1 <- ggplot(data, aes(sample = Residuals)) +
  stat_qq() +
  stat_qq_line() +
  ggtitle("Normal Probability Plot") +
  theme_minimal()

# 2. Residuals vs Fitted Values
p2 <- ggplot(data, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  ggtitle("Residuals vs Fitted Values") +
  theme_minimal()

# 3. Histogram of Residuals
p3 <- ggplot(data, aes(x = Residuals)) +
  geom_histogram(binwidth = 0.1, fill = "#008FC8", color = "black", alpha = 0.7) +
  ggtitle("Histogram of Residuals") +
  theme_minimal()

# 4. Residuals vs Observation Order
p4 <- ggplot(data, aes(x = Observation, y = Residuals)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  ggtitle("Residuals vs Observation Order") +
  theme_minimal()

# Arrange the plots in a grid with a main title
title <- grid::textGrob("Residual Plots for ARIMA(2,0,2)(0,1,1)[12]", gp = grid::gpar(fontsize = 16, fontface = "bold"))

# Combine the plots with the title
gridExtra::grid.arrange(
  gridExtra::arrangeGrob(p1, p2, p3, p4, ncol = 2, top = title)
)

```

#### Create ACF and PACF of residuals

```{r}

# Extract residuals
residuals <- as.numeric(residuals(UK_sarima_1))  # Convert to numeric

# ACF plot
acf_data <- acf(residuals, plot = FALSE)
acf_df <- data.frame(lag = acf_data$lag, acf = acf_data$acf)

p_acf <- ggplot(acf_df, aes(x = lag, y = acf)) +
  geom_bar(stat = "identity", position = "dodge", fill = "#008FC8", color = "black") +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  geom_hline(yintercept = -qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  ggtitle("ACF of Residuals for UK SARIMA modelmodel") +
  theme_minimal()

# PACF plot
pacf_data <- pacf(residuals, plot = FALSE)
pacf_df <- data.frame(lag = pacf_data$lag, pacf = pacf_data$acf)

p_pacf <- ggplot(pacf_df, aes(x = lag, y = pacf)) +
  geom_bar(stat = "identity", position = "dodge", fill = "#008FC8", color = "black") +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  geom_hline(yintercept = -qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  ggtitle("PACF of Residuals for ARIMA(2,0,2)(0,1,1)[12]") +
  theme_minimal()

# Combine the plots
gridExtra::grid.arrange(p_acf, p_pacf, ncol = 1)

```

#### Check residuals
```{r}
checkresiduals(UK_sarima_1, main = "Residuals of ARIMA(2,0,2)(0,1,1)[12]")
```

- p-value (0.06974) > 0.05: Since the p-value is greater than 0.05, we fail to reject the null hypothesis.
- This indicates that there is no significant autocorrelation in the residuals from the ARIMA(2,0,2)(0,1,1)[12] model.
- In other words, the residuals appear to be independently distributed, which suggests that the model fits the data well and there are no remaining patterns in the residuals that the model has not captured.
- Therefore, the model appears to be a good fit for the data based on this diagnostic test.

#### Ljung-Box test
```{r}
# Define the lags to test
lags <- c(12, 24, 36, 48)

# Perform Ljung-Box test for each model
cat("Ljung-Box Test Results of different lags:\n")
perform_ljung_box_test(UK_sarima_1, lags)

```
At all tested lags (12, 24, 36, and 48), the p-values are greater than 0.05.

This means that for all these lags, we fail to reject the null hypothesis that the residuals are independently distributed.

Therefore, there is no significant autocorrelation in the residuals of the ARIMA model UK_sarima_1 up to lag 48, suggesting that the model fits the data well.


#### ADF test and KPSS test for residuals 
```{r}
# ADF test
tseries::adf.test(UK_sarima_1$residuals)

# KPSS test
UK_sarima_1$residuals%>% ur.kpss(use.lag = (floor(12* (length(UK_sales_ts_log_train) /100)^(1/4)))) %>% summary()
```
ADF Test:
- p-value = 0.01: Reject the null hypothesis of non-stationarity.
- Conclusion: The residuals are stationary.

KPSS Test:
- Test Statistic (0.1546) < Critical Values (0.347, 0.463, 0.574, 0.739): Fail to reject the null hypothesis of stationarity.
- Conclusion: The residuals are stationary.

Both the ADF and KPSS tests suggest that the residuals from the ARIMA model UK_sarima_1 are stationary. This indicates that the model has effectively captured the underlying structure of the time series, and the remaining residuals do not exhibit significant patterns or trends, implying a good fit.

#### BJM test
```{r}
bjm_test(UK_sarima_1)
```
Z-Test for Coefficients:

- Significance: All coefficients are statistically significant at the 0.001 level (p-values are much smaller than 0.001), indicating that each of these parameters contributes significantly to the model.

- Signif. codes: The significance codes (*** for p < 0.001) confirm the high level of statistical significance for all coefficients.

- All AR, MA, and seasonal MA coefficients are highly significant, indicating that they are important for the model.

Box-Ljung Test:

- The high p-value (0.6083) indicates that there is no significant autocorrelation in the residuals.
- This suggests that the model fits the data well, as the residuals appear to be white noise.

#### Perform Shapiro-Wilk test for each model
```{r}
cat("Shapiro-Wilk Test Results:")
shapiro_wilk_test(UK_sarima_1)
```

The very low p-value (0.0000000004174758) indicates that the residuals of the ARIMA model UK_sarima_1 do not follow a normal distribution.
This deviation from normality could be due to various reasons, such as outliers, skewness, kurtosis, or other non-normal features in the residuals.

```{r}
# Plot the residuals
plot(UK_sarima_1$residuals, main = "Residuals of ARIMA Model")

# Q-Q plot
qqnorm(UK_sarima_1$residuals)
qqline(UK_sarima_1$residuals, col = "red")

```

#### Test for Heteroscedasticity

```{r}
# Perform ARCH test for each model
cat("Stepwise Model ARCH Test Results:")
perform_arch_test(UK_sarima_1, lags)

```

At lags 12 and 24, there are significant ARCH effects in the residuals, indicating the presence of autoregressive conditional heteroskedasticity.

At lags 36 and 48, there is no significant evidence of ARCH effects, suggesting the residuals are more likely homoscedastic at these longer lags.

#### Check parameter estimation
```{r}

# Define your SARIMA model parameters
order <- c(2, 0, 2)
seasonal_order <- c(0, 1, 1)
period <- 12

# Assuming `UK_sales_ts_log_train` is your time series data
# Fit the model with custom iteration capture
result <- capture_iterations(UK_sales_ts_log_train, order, seasonal_order, period)
fit <- result$fit
iterations_df <- result$iterations

print(iterations_df)
```

### 4.1.4. Forecast with SARIMA model

#### SARIMA-1
```{r}
# Forecast result

UK_sarima_result_1 <- forecast::forecast(UK_sarima_1, h = 12)

# Plot the forecast result 

plot(UK_sarima_result_1, main = paste("Fitted from",UK_sarima_result_1$method), xlab = "Time", ylab = "Values") 
lines(UK_sarima_result_1$fitted, col = "red",lty = "dashed", lwd = 1) 
legend("bottomright", legend = c("OS Visit", UK_sarima_result_1$method), col = c("black", "red"), lty = 1:2, cex = 0.8)

```

```{r}
plot_fore(UK_sales_ts_log_test,UK_sarima_result_1)

```

```{r}
plot_fore_exp(UK_sales_ts_log_test,UK_sarima_result_1)
```

```{r}
# Calculate Mean Absolute Percentage Error (MAPE)
mape_log <- round(MLmetrics::MAPE(UK_sarima_result_1$mean, UK_sales_ts_log_test) * 100, 2)
mape_exp <- round(MLmetrics::MAPE(exp(UK_sarima_result_1$mean), exp(UK_sales_ts_log_test)) * 100, 2)

# Calculate Mean Absolute Error (MAE)
mae_log <- round(MLmetrics::MAE(UK_sarima_result_1$mean, UK_sales_ts_log_test), 2)
mae_exp <- round(MLmetrics::MAE(exp(UK_sarima_result_1$mean), exp(UK_sales_ts_log_test)), 2)

# Convert MAE to percentage of the mean actual values
mae_log_percentage <- round((mae_log / mean(UK_sales_ts_log_test)) * 100, 2)
mae_exp_percentage <- round((mae_exp / mean(exp(UK_sales_ts_log_test))) * 100, 2)

# Manually calculate Mean Percentage Error (MPE)
mpe_log <- round(mean((UK_sarima_result_1$mean - UK_sales_ts_log_test) / UK_sales_ts_log_test) * 100, 2)
mpe_exp <- round(mean((exp(UK_sarima_result_1$mean) - exp(UK_sales_ts_log_test)) / exp(UK_sales_ts_log_test)) * 100, 2)

# Calculate Root Mean Squared Error (RMSE)
rmse_log <- round(MLmetrics::RMSE(UK_sarima_result_1$mean, UK_sales_ts_log_test), 2)
rmse_exp <- round(MLmetrics::RMSE(exp(UK_sarima_result_1$mean), exp(UK_sales_ts_log_test)), 2)

# Print the results
cat("Log-Transformed Data:\n")
cat("MAPE:", mape_log, "%\n")
cat("MAE:", mae_log, "\n")
cat("MAE (Percentage):", mae_log_percentage, "%\n")
cat("MPE:", mpe_log, "%\n")
cat("RMSE:", rmse_log, "\n")

cat("\nBack-Transformed Data (Exponential):\n")
cat("MAPE:", mape_exp, "%\n")
cat("MAE:", mae_exp, "\n")
cat("MAE (Percentage):", mae_exp_percentage, "%\n")
cat("MPE:", mpe_exp, "%\n")
cat("RMSE:", rmse_exp, "\n")
```

```{r}
accuracy(UK_sarima_result_1)
```

```{r}
# Save result
#sarima_UK_forecast <- cbind(UK_sarima_result_1$mean,UK_sarima_result_1$upper[, "95%"],UK_sarima_result_1$lower[, "95%"])

sarima_UK_forecast <- cbind(exp(UK_sarima_result_1$mean),exp(UK_sarima_result_1$upper[, "95%"]), exp(UK_sarima_result_1$lower[, "95%"]))

```

## 4.2. SARIMA for England series

### 4.2.1. Model building

```{r}
# Store data of Pre-Covid as time series
E_sales_ts_pre <- E_sales_ts %>% window (end=c(2020,02))

ggtsdisplay(E_sales_ts_pre, lag.max=40, main ="Time series, ACF and PACF of E_sales_ts_pre")

```

```{r}

# Seasonal decomposition
decomposed <- stl(E_sales_ts_pre, s.window = "periodic")
autoplot(decomposed) +
  ggtitle("Seasonal Decomposition of England\nHousing Sales Volume") +
  theme(plot.title = element_text(hjust = 0.5))
```

### Guerrero test

```{r}
# Guerrero test 
guerrero_lambda <- BoxCox.lambda(E_sales_ts_pre, method = "guerrero")
print(paste("Optimal lambda using Guerrero method:", guerrero_lambda))
```

--> The optimal lambda using the Guerrero method is approximately 0.433. This value suggests that the data would benefit from a transformation to stabilize variance and make the data more suitable for modeling.

Notes: Lambda = 1: No transformation (original data)
       Lambda = 0: Log transformation

#### Log transformation
```{r}
# Log transformation using the optimal lambda
E_sales_ts_log <- log(E_sales_ts_pre)
```

```{r}
# Plot the transformed data
autoplot(E_sales_ts_log) +
  ggtitle("Log Transformed England Housing Sales Volume\nof Pre-Covid period") +
  xlab("Time") + ylab("Log Transformed Sales Volume") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
# Seasonal decomposition of transformed data
decomposed_log <- stl(E_sales_ts_log, s.window = "periodic")
autoplot(decomposed_log) +
  ggtitle("Seasonal Decomposition of Log Transformed England\nHousing Sales Volume of Pre-Covid period") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
# Display time series, ACF, and PACF of transformed data
ggtsdisplay(E_sales_ts_log, lag.max = 40, main = 'Time series, ACF, and PACF of Log Transformed\nEngland Housing Sales of Pre-Covid period ')
```

#### Split the data into training and test sets

```{r}
# Create a training dataset from January 2005 to February 2019
E_sales_ts_log_train <- window(E_sales_ts_log, start = c(2005, 1), end = c(2019, 2))

# Create a test dataset from March 2019 to February 2020
E_sales_ts_log_test <- window(E_sales_ts_log, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the time series
str(E_sales_ts_log_train)
str(E_sales_ts_log_test)

# Print the time series data
print(E_sales_ts_log_train)
print(E_sales_ts_log_test)
```

#### Plot of Training and Test dataset
```{r}
# Set up the plotting area for two plots
par(mfrow = c(2, 1), cex.main = 0.9, cex.lab = 0.8, cex.axis = 0.8)

# Plot the training set with smaller text
plot(E_sales_ts_log_train, 
     main = "Training Set of Log Transformed England\nHousing Sales Volume", 
     xlab = "Time", 
     ylab = "Log Transformed Sales Volume")
grid()

# Plot the test set with smaller text
plot(E_sales_ts_log_test, 
     main = "Test Set of Log Transformed England\nHousing Sales Volume", 
     xlab = "Time", 
     ylab = "Log Transformed Sales Volume")
grid()

```

```{r}
# Reset plotting area to default to ensure subsequent plots are displayed one at a time
par(mfrow = c(1, 1))
```

#### Time series comparision 
```{r}

# Determine the range of the combined dataset for consistent y-axis limits
combined_range <- range(c(E_sales_ts_log_train, E_sales_ts_log_test))


# Overlay plot for comparison with thicker lines and adjusted axes
plot(E_sales_ts_log_train, main = "Time Series Comparison", ylab = "Values", xlab = "Time", lwd = 2, ylim = combined_range, xlim = c(time(E_sales_ts_log_train)[1], time(E_sales_ts_log_test)[length(E_sales_ts_log_test)]))
lines(E_sales_ts_log_test, col = "red", lwd = 2)
legend("bottomright", legend = c("Train", "Test"), col = c("black", "red"), lty = 1, lwd = 2)

```

```{r}
# Check seasonality
seasonplot(E_sales_ts_log_train, main = "Seasonal plot: E_sales_ts_log_train", col = 1, lwd = 1.5)

```
There are observable seasonal fluctuations where certain months consistently exhibit higher sales values compared to others. For example, sales values tend to peak in certain months like May and July across multiple years, indicating potential seasonal effects. Additionally, the spread of the lines, especially in the middle of the year, suggests significant variability in sales from year to year. This variability implies that while seasonality is present, other factors might also be influencing sales, leading to fluctuations that are not solely driven by seasonal trends. The consistent pattern of peaks and troughs across different years reinforces the importance of considering seasonality in any predictive modeling of the sales data. However, the variability also underscores the need to incorporate methods that can handle this unpredictability and potential outliers in the data.

```{r}
# Generate a seasonal subseries plot for the log-transformed UK sales training data

monthplot(E_sales_ts_log_train,lwd = 1.5 )

```
-> The highest is August and the lowest is January

```{r}
# Generate a combined plot displaying the time series, ACF, and PACF of the log-transformed England sales training data

ggtsdisplay(E_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed England\nHousing Sales training dataset")

```

#### Perform Augmented Dickey-Fuller (ADF) test
```{r}
tseries::adf.test(E_sales_ts_log_train)

```
The test statistic of -2.8751 is compared against critical values to determine stationarity.

The p-value of 0.2109 is greater than the common significance levels (e.g., 0.01, 0.05, 0.10), indicating that we fail to reject the null hypothesis of non-stationarity.
Therefore, based on this test, the log-transformed UK sales training data is not stationary.


```{r}
# ADF test for three different model types
adf.test(E_sales_ts_log_train)
```
- Type 1 (no drift, no trend): The series is non-stationary.
- Type 2 (with drift, no trend): The series shows signs of stationarity at lower lags, indicating that drift might play a role in making the series stationary.
- Type 3 (with drift and trend): The series appears stationary only at lag 0, suggesting that both drift and trend contribute to stationarity at this specific lag.

Overall, these results suggest that incorporating drift (Type 2) improves the likelihood of the series being stationary compared to the model without drift or trend (Type 1). The inclusion of both drift and trend (Type 3) shows stationarity only at lag 0. 

#### KPSS test
```{r}

# Perform KPSS test on the training dataset
E_sales_ts_log_train%>% kpss.test()
```
The results of the KPSS test are mixed depending on the model assumptions:

- Type 1 (no drift, no trend): The time series appears to be stationary.
- Type 2 (with drift, no trend): The time series appears to be stationary even with a drift component.
- Type 3 (with drift and trend): The time series is non-stationary when both drift and trend are included.

Given these results, it is important to consider the nature of your time series data:

- If your time series data is better represented without a trend and drift, it can be considered stationary.

- However, if the data naturally includes a trend and drift, then it appears non-stationary and may require differencing or other transformations to achieve stationarity.

--> Apply differencing to remove the trend and achieve stationarity.

```{r}
#Calculate the number of observations (T)
T_E_train <- length(E_sales_ts_log_train)
print(T_E_train)

# Apply Schwert's Criterion
use_lag_E_train <- floor(12 * (T_E_train / 100)^(1/4))
print(use_lag_E_train)

# Perform KPSS Test with the Chosen Lag
E_sales_ts_log_train%>% ur.kpss(use.lag = use_lag_E_train) %>% summary()

```
Based on the KPSS test results with the chosen lag of 13:

- Since the test statistic (0.1906) is less than the critical values at all significance levels (10%, 5%, 2.5%, and 1%), we fail to reject the null hypothesis.
- The time series is likely stationary around a constant (no trend).
- This result suggests that the time series does not have a unit root and is stationary when considering stationarity around a mean (without a trend).

```{r}

# Determine the Number of Seasonal Differencing (D):
D_E_train <- nsdiffs(E_sales_ts_log_train)
print(D_E_train)

```

#### Seasonal Differencing

```{r}
d_E_sales_ts_log_train <- diff (E_sales_ts_log_train, lag =12, differences=1)

ggtsdisplay(d_E_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed England\nHousing Sales training dataset (D=1)")
```

#### Test again

#### Perform Augmented Dickey-Fuller (ADF) test - Unit root tests
```{r}
tseries::adf.test(d_E_sales_ts_log_train)
```

ADF test indicates that the differenced log-transformed UK sales training data is stationary at the 5% significance level. This means the seasonal component has been effectively removed, and the series no longer has a unit root.

```{r}
adf.test(d_E_sales_ts_log_train)
```
- At lag 0, the p-value is 0.0348, indicating rejection of the null hypothesis of a unit root (stationary series).

- For lags 1 to 4, the p-values are greater than 0.05, indicating that we fail to reject the null hypothesis of a unit root (non-stationary series).

Conclusion: The differenced time series shows evidence of stationarity only at lag 0 when both drift and trend are considered.

#### KPSS test
```{r}

# Perform KPSS test on the housing sales volume
d_E_sales_ts_log_train%>% kpss.test()
```

Type 1 (no drift, no trend): The differenced time series is stationary.
Type 2 (with drift, no trend): The differenced time series is stationary.
Type 3 (with drift and trend): The differenced time series is stationary.

```{r}
#Calculate the number of observations (T)
d_T_E_train <- length(d_E_sales_ts_log_train)
print(d_T_E_train)

# Apply Schwert's Criterion
d_use_lag_E_train <- floor(12 * (d_T_E_train / 100)^(1/4))
print(d_use_lag_E_train)

# Perform KPSS Test with the Chosen Lag
d_E_sales_ts_log_train%>% ur.kpss(use.lag = d_use_lag_E_train ) %>% summary()

```
Since the test statistic (0.1107) is less than the critical values at all significance levels (10%, 5%, 2.5%, and 1%), we fail to reject the null hypothesis.

The time series is likely stationary around a constant (no trend).

This result suggests that the time series does not have a unit root and is stationary when considering stationarity around a mean (without a trend).

```{r}
#Determine the Number of Normal Differencing (d):
d_E_train <- ndiffs(d_E_sales_ts_log_train)
print(d_E_train)
```

--> No need to do further differencing

Conclusion:

- The differenced logged time series d_E_sales_ts_log_train is stationary based on both ADF and KPSS test results.

- This suggests that the differencing has successfully removed non-stationarity from the series.

### 4.2.2. SARIMA model selection

```{r}
# Fit a SARIMA model using auto.arima with specified parameters for Automatic Model Selection
E_sarima_1 <- auto.arima(
  E_sales_ts_log_train,  # The log-transformed training dataset for UK housing sales volume
  max.p = 4,              # Maximum order of the non-seasonal autoregressive part (AR)
  max.q = 4,              # Maximum order of the non-seasonal moving average part (MA)
  max.P = 4,              # Maximum order of the seasonal autoregressive part (SAR)
  max.Q = 4,              # Maximum order of the seasonal moving average part (SMA)
  max.d = 2,              # Maximum number of non-seasonal differences
  max.D = 2,              # Maximum number of seasonal differences
  start.p = 0,            # Starting value of p in the stepwise procedure
  start.q = 0,            # Starting value of q in the stepwise procedure
  start.P = 0,            # Starting value of P in the stepwise procedure
  start.Q = 0,            # Starting value of Q in the stepwise procedure
  stationary = FALSE,     # If TRUE, restricts search to stationary models
  seasonal = TRUE,        # If FALSE, restricts search to non-seasonal models
  ic = c("aicc", "aic", "bic"),  # Information criteria to be used in model selection (AICc, AIC, BIC)
  stepwise = FALSE,       # If TRUE, will do stepwise selection (faster); here set to FALSE for exhaustive search
  trace = TRUE,           # If TRUE, the list of ARIMA models considered will be reported
  approximation = FALSE,  # If TRUE, estimation is via conditional sums of squares and approximated information criteria; here set to FALSE for exact MLE
  test = c("kpss", "adf", "pp")  # Unit root tests to be used for non-seasonal differencing
)

```

--> Best model: ARIMA(2,0,2)(0,1,1)[12]    

```{r}
summary(E_sarima_1)
```

```{r}
# Number of observations in the training set
n_train <- length(E_sales_ts_log_train)

# Calculate metrics for each model

cat("SARIMA Model Metrics:\n")
calculate_metrics(E_sarima_1, n_train)
```

### 4.2.3. Residuals Diagnostics
#### Draw Residual plots

```{r}
# Extract residuals and fitted values
residuals <- as.numeric(residuals(E_sarima_1))  # Convert to numeric
fitted_values <- as.numeric(fitted(E_sarima_1)) # Convert to numeric
observations <- seq_along(residuals)

# Create a data frame for plotting
data <- data.frame(Residuals = residuals, Fitted = fitted_values, Observation = observations)

# 1. Normal Probability Plot
p1 <- ggplot(data, aes(sample = Residuals)) +
  stat_qq() +
  stat_qq_line() +
  ggtitle("Normal Probability Plot") +
  theme_minimal()

# 2. Residuals vs Fitted Values
p2 <- ggplot(data, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  ggtitle("Residuals vs Fitted Values") +
  theme_minimal()

# 3. Histogram of Residuals
p3 <- ggplot(data, aes(x = Residuals)) +
  geom_histogram(binwidth = 0.1, fill = "#008FC8", color = "black", alpha = 0.7) +
  ggtitle("Histogram of Residuals") +
  theme_minimal()

# 4. Residuals vs Observation Order
p4 <- ggplot(data, aes(x = Observation, y = Residuals)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  ggtitle("Residuals vs Observation Order") +
  theme_minimal()

# Arrange the plots in a grid with a main title
title <- grid::textGrob("Residual Plots for ARIMA(2,0,2)(0,1,1)[12]", gp = grid::gpar(fontsize = 16, fontface = "bold"))

# Combine the plots with the title
gridExtra::grid.arrange(
  gridExtra::arrangeGrob(p1, p2, p3, p4, ncol = 2, top = title)
)

```

- Normality: The residuals appear to be approximately normally distributed, as indicated by the Q-Q plot and the histogram.

- Independence: The residuals do not show any clear pattern when plotted against fitted values or observation order, suggesting they are independent.

- Homoscedasticity: The residuals exhibit constant variance, with no clear funnel-shaped patterns in the residuals vs fitted values plot.

- Outliers: There are some potential outliers visible in the Q-Q plot, residuals vs fitted values plot, and residuals vs observation order plot.


```{r}
# Plot the residuals
plot(E_sarima_1$residuals, main = "Residuals of SARIMA Model")
```

#### Q-Q plot
```{r}
qqnorm(E_sarima_1$residuals)
qqline(E_sarima_1$residuals, col = "red")

```

Normality: The residuals are approximately normally distributed in the central range, but there are deviations at the tails, suggesting potential outliers or non-normality in the extremes.

Impact: Non-normality in the tails may affect certain inferential statistics and predictive intervals. However, ARIMA models are generally robust to mild deviations from normality, especially if the primary goal is forecasting rather than hypothesis testing.

#### Create ACF and PACF

```{r}
# Extract residuals
residuals <- as.numeric(residuals(E_sarima_1))  # Convert to numeric

# ACF plot
acf_data <- acf(residuals, plot = FALSE)
acf_df <- data.frame(lag = acf_data$lag, acf = acf_data$acf)

p_acf <- ggplot(acf_df, aes(x = lag, y = acf)) +
  geom_bar(stat = "identity", position = "dodge", fill = "#008FC8", color = "black") +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  geom_hline(yintercept = -qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  ggtitle("ACF of Residuals for ARIMA(2,0,2)(0,1,1)[12]") +
  theme_minimal()

# PACF plot
pacf_data <- pacf(residuals, plot = FALSE)
pacf_df <- data.frame(lag = pacf_data$lag, pacf = pacf_data$acf)

p_pacf <- ggplot(pacf_df, aes(x = lag, y = pacf)) +
  geom_bar(stat = "identity", position = "dodge", fill = "#008FC8", color = "black") +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  geom_hline(yintercept = -qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  ggtitle("PACF of Residuals for ARIMA(2,0,2)(0,1,1)[12]") +
  theme_minimal()

# Combine the plots
gridExtra::grid.arrange(p_acf, p_pacf, ncol = 1)

```

#### Check residual
```{r}
checkresiduals(E_sarima_1, main = "Residuals of ARIMA(2,0,2)(0,1,1)[12]")
```

Good Model Fit: The Ljung-Box test results suggest that the residuals of your ARIMA(2,0,2)(0,1,1)[12] model are independently distributed, indicating a good model fit in terms of autocorrelation.

No Significant Autocorrelation: The residuals do not exhibit significant autocorrelation, meaning the model has adequately captured the underlying structure of the data.

Model Fit: The ARIMA(2,0,2)(0,1,1)[12] model appears to fit the data well, as indicated by the residuals fluctuating around zero with no significant autocorrelation.

Normality of Residuals: The histogram suggests that the residuals are approximately normally distributed, which supports the validity of the model assumptions.

Ljung-Box Test: The previously mentioned Ljung-Box test results (p-value = 0.117) also support the conclusion that the residuals do not exhibit significant autocorrelation, indicating that the model has captured the structure of the data well.

#### Ljung-Box test
```{r}
# Define the lags to test
lags <- c(12, 24, 36, 48)

# Perform Ljung-Box test for each model
cat("Ljung-Box Test Results:")
perform_ljung_box_test(E_sarima_1, lags)

```

For all lags (12, 24, 36, and 48), the p-values are greater than the common significance levels (e.g., 0.01, 0.05, 0.10).

Fail to Reject the Null Hypothesis: Since all the p-values are greater than 0.05, we fail to reject the null hypothesis at each lag.

No Significant Autocorrelation: The results indicate that there is no significant autocorrelation in the residuals at these lags. This suggests that the residuals from your ARIMA model are independently distributed.

#### ADF test and KPSS test for residuals 
```{r}
# ADF test
tseries::adf.test(E_sarima_1$residuals)

# KPSS test
E_sarima_1$residuals%>% ur.kpss(use.lag = (floor(12* (length(E_sales_ts_log_train) /100)^(1/4)))) %>% summary()
```

ADF test

This p-value is less than the common significance levels (0.01, 0.05, 0.10), which means we reject the null hypothesis at these levels.
The ADF test results indicate that the residuals of the ARIMA model are stationary. This is a good sign, as it suggests that the model has adequately captured the structure of the data and left behind white noise.

KPSS test
Since the test statistic (0.1494) is less than the critical values at all significance levels, we fail to reject the null hypothesis.
This indicates that the residuals of the ARIMA model are stationary.

#### BJM test
```{r}
bjm_test(E_sarima_1)

```

Z-Test of Coefficients: All coefficients in your ARIMA(2,0,2)(0,1,1)[12] model are highly significant, indicating that they are important components of the model.

Box-Ljung Test: The residuals do not show significant autocorrelation, confirming that the model is well-fitted.


#### Test for Heteroscedasticity

```{r}
# Perform ARCH test for each model
cat("ARCH Test Results:")
perform_arch_test(E_sarima_1, lags)

```

Significant ARCH Effects: At lags 12 and 24, the p-values are very low, indicating the presence of heteroskedasticity. This means that at these lags, the residuals show significant varying variance over time.

No Significant ARCH Effects: At lags 36 and 48, the p-values are higher than 0.05, indicating no significant heteroskedasticity at these lags. This suggests that at these longer lags, the variance of the residuals is relatively stable.

#### Check parameter estimation
```{r}

# Define your SARIMA model parameters
order <- c(2, 0, 2)
seasonal_order <- c(0, 1, 1)
period <- 12

# Assuming `E_sales_ts_log_train` is your time series data
# Fit the model with custom iteration capture
result <- capture_iterations(E_sales_ts_log_train, order, seasonal_order, period)
fit <- result$fit
iterations_df <- result$iterations

print(iterations_df)
```

Convergence Achieved: The constant SSE and parameter values across iterations indicate that the ARIMA model fitting process has successfully converged, and the model parameters are stable.

Model Fit: The SSE value of 1.779542 represents the model's fit to the data. While this value alone does not provide a complete picture of the model's performance, it is an indication of the residual sum of squares after fitting the model.

### 4.2.4. Forecast with SARIMA model

```{r}
# Forecast result

E_sarima_result_1 <- forecast::forecast(E_sarima_1, h = 12)

# Plot the forecast result 

plot(E_sarima_result_1, main = paste("Fitted from",E_sarima_result_1$method), xlab = "Time", ylab = "Values") 
lines(E_sarima_result_1$fitted, col = "red",lty = "dashed", lwd = 1) 
legend("bottomright", legend = c("OS Visit", E_sarima_result_1$method), col = c("black", "red"), lty = 1:2, cex = 0.8)

```

```{r}
plot_fore(E_sales_ts_log_test,E_sarima_result_1)

```

```{r}
plot_fore_exp(E_sales_ts_log_test,E_sarima_result_1)
```

```{r}
# Calculate Mean Absolute Percentage Error (MAPE)
mape_log <- round(MLmetrics::MAPE(E_sarima_result_1$mean, E_sales_ts_log_test) * 100, 2)
mape_exp <- round(MLmetrics::MAPE(exp(E_sarima_result_1$mean), exp(E_sales_ts_log_test)) * 100, 2)

# Calculate Mean Absolute Error (MAE)
mae_log <- round(MLmetrics::MAE(E_sarima_result_1$mean, E_sales_ts_log_test), 2)
mae_exp <- round(MLmetrics::MAE(exp(E_sarima_result_1$mean), exp(E_sales_ts_log_test)), 2)

# Convert MAE to percentage of the mean actual values
mae_log_percentage <- round((mae_log / mean(E_sales_ts_log_test)) * 100, 2)
mae_exp_percentage <- round((mae_exp / mean(exp(E_sales_ts_log_test))) * 100, 2)

# Manually calculate Mean Percentage Error (MPE)
mpe_log <- round(mean((E_sarima_result_1$mean - E_sales_ts_log_test) / E_sales_ts_log_test) * 100, 2)
mpe_exp <- round(mean((exp(E_sarima_result_1$mean) - exp(E_sales_ts_log_test)) / exp(E_sales_ts_log_test)) * 100, 2)

# Calculate Root Mean Squared Error (RMSE)
rmse_log <- round(MLmetrics::RMSE(E_sarima_result_1$mean, E_sales_ts_log_test), 2)
rmse_exp <- round(MLmetrics::RMSE(exp(E_sarima_result_1$mean), exp(E_sales_ts_log_test)), 2)

# Print the results
cat("Log-Transformed Data:\n")
cat("MAPE:", mape_log, "%\n")
cat("MAE:", mae_log, "\n")
cat("MAE (Percentage):", mae_log_percentage, "%\n")
cat("MPE:", mpe_log, "%\n")
cat("RMSE:", rmse_log, "\n")

cat("\nBack-Transformed Data (Exponential):\n")
cat("MAPE:", mape_exp, "%\n")
cat("MAE:", mae_exp, "\n")
cat("MAE (Percentage):", mae_exp_percentage, "%\n")
cat("MPE:", mpe_exp, "%\n")
cat("RMSE:", rmse_exp, "\n")
```

```{r}
# Save result
#sarima_E_forecast <- cbind(E_sarima_result_1$mean,E_sarima_result_1$upper[, "95%"],E_sarima_result_1$lower[, "95%"])

sarima_E_forecast <- cbind(exp(E_sarima_result_1$mean),exp(E_sarima_result_1$upper[, "95%"]), exp(E_sarima_result_1$lower[, "95%"]))
```

## 4.3. SARIMA for Northern Ireland series

### 4.3.1. Model building
```{r}
# Store data of Pre-Covid as time series
NI_sales_ts_pre <- NI_sales_ts %>% window (end=c(2020,02))
ggtsdisplay(NI_sales_ts_pre, lag.max=40, main ="Time series, ACF and PACF of NI_sales_ts_pre")

```

```{r}

# Seasonal decomposition
decomposed <- stl(NI_sales_ts_pre, s.window = "periodic")
autoplot(decomposed) +
  ggtitle("Seasonal Decomposition of NI Housing Sales Volume") +
  theme(plot.title = element_text(hjust = 0.5))
```

#### Guerrero test

```{r}

# Guerrero test 
guerrero_lambda <- BoxCox.lambda(NI_sales_ts_pre, method = "guerrero")
print(paste("Optimal lambda using Guerrero method:", guerrero_lambda))
```

--> The optimal lambda using the Guerrero method is approximately 0.433. This value suggests that the data would benefit from a transformation to stabilize variance and make the data more suitable for modeling.

Notes: Lambda = 1: No transformation (original data)
       Lambda = 0: Log transformation

#### Log transformation
```{r}
# Log transformation using the optimal lambda
NI_sales_ts_log <- log(NI_sales_ts_pre)

```

```{r}
# Plot the transformed data
autoplot(NI_sales_ts_log) +
  ggtitle("Log Transformed Northern Ireland Housing Sales\nVolume of Pre-Covid period") +
  xlab("Time") + ylab("Log Transformed Sales Volume") +
  theme(plot.title = element_text(hjust = 0.5))

```

```{r}
# Seasonal decomposition of transformed data
decomposed_log <- stl(NI_sales_ts_log, s.window = "periodic")
autoplot(decomposed_log) +
  ggtitle("Seasonal Decomposition of Log Transformed\nNorthern Ireland Housing Sales Volume of\nPre-Covid period") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
# Display time series, ACF, and PACF of transformed data
ggtsdisplay(NI_sales_ts_log, lag.max = 40, main = 'Time series, ACF, and PACF of Log Transformed\nNorthern Ireland Housing Sales of Pre-Covid period ')

```

#### Split the data into training and test sets

```{r}
# Create a training dataset from January 2005 to February 2019
NI_sales_ts_log_train <- window(NI_sales_ts_log, start = c(2005, 1), end = c(2019, 2))

# Create a test dataset from March 2019 to February 2020
NI_sales_ts_log_test <- window(NI_sales_ts_log, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the time series
str(NI_sales_ts_log_train)
str(NI_sales_ts_log_test)

# Print the time series data
print(NI_sales_ts_log_train)
print(NI_sales_ts_log_test)

```

#### Plot of Training and Test dataset
```{r}
# Set up the plotting area for two plots
par(mfrow = c(2, 1), cex.main = 0.9, cex.lab = 0.8, cex.axis = 0.8, lty=1, lwd = 1.8)

# Plot the training set with smaller text
plot(NI_sales_ts_log_train, 
     main = "Training Set of Log Transformed NI Housing Sales Volume", 
     xlab = "Time", 
     ylab = "Log Transformed Sales Volume")
grid()

# Plot the test set with smaller text
plot(NI_sales_ts_log_test, 
     main = "Test Set of Log Transformed NI Housing Sales Volume", 
     xlab = "Time", 
     ylab = "Log Transformed Sales Volume")
grid()

```

```{r}
# Reset plotting area to default to ensure subsequent plots are displayed one at a time
par(mfrow = c(1, 1))
```

#### Time series comparision 
```{r}

# Determine the range of the combined dataset for consistent y-axis limits
combined_range <- range(c(NI_sales_ts_log_train, NI_sales_ts_log_test))

# Overlay plot for comparison with thicker lines and adjusted axes
plot(NI_sales_ts_log_train, main = "Time Series Comparison", ylab = "Values", xlab = "Time", lwd = 2, ylim = combined_range, xlim = c(time(NI_sales_ts_log_train)[1], time(NI_sales_ts_log_test)[length(NI_sales_ts_log_test)]))
lines(NI_sales_ts_log_test, col = "red", lwd = 2)
legend("bottomright", legend = c("Train", "Test"), col = c("black", "red"), lty = 1, lwd = 2)

```


```{r}
# Check seasonality
seasonplot(NI_sales_ts_log_train, main = "Seasonal plot: NI_sales_ts_log_train", col = 1, lwd = 1.5)

```
The seasonal plot of the log-transformed sales data (NI_sales_ts_log_train) reveals distinct and consistent seasonal patterns over the years. Sales tend to increase from January to March, peak around May, dip in June, rise slightly towards September, and decrease again towards the end of the year with a slight uptick in December. This recurring monthly trend indicates a strong seasonal component in the sales data. The parallel lines across different years suggest that these seasonal effects are stable over time, though there is some variability in the exact sales volumes from year to year. This understanding of seasonal behavior is crucial for accurate forecasting and strategic planning.

```{r}
# Generate a seasonal subseries plot for the log-transformed UK sales training data
monthplot(NI_sales_ts_log_train,lwd = 1.5 )
```
The seasonal subseries plot of NI_sales_ts_log_train reveals consistent seasonal patterns in the sales data across different years, with regular peaks and troughs at specific times of the year. January to March generally shows an upward trend in sales, while significant peaks occur around April and May, followed by declines in the middle of the year. The variability in the sales volumes within each month across different years suggests that while the seasonal pattern is stable, the exact sales volumes can vary. This understanding of seasonal behavior is crucial for accurate forecasting and strategic planning.

```{r}
# Generate a combined plot displaying the time series, ACF, and PACF of the log-transformed NI sales training data

ggtsdisplay(NI_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed\nNorthern Ireland Housing Sales training dataset")

```

#### Perform Augmented Dickey-Fuller (ADF) test
```{r}
tseries::adf.test(NI_sales_ts_log_train)

```
The test statistic of -1.752 is compared against critical values to determine stationarity.

The p-value of 0.6798 is greater than the common significance levels (e.g., 0.01, 0.05, 0.10), indicating that we fail to reject the null hypothesis of non-stationarity.
Therefore, based on this test, the log-transformed UK sales training data is not stationary.


```{r}
# ADF test for three different model types
adf.test(NI_sales_ts_log_train)
```
Across all three model types and various lag orders, the p-values consistently exceed the threshold of 0.05, leading us to fail to reject the null hypothesis of non-stationarity.
The log-transformed Northern Ireland housing sales training dataset is non-stationary in its current form.

#### KPSS test
```{r}
# Perform KPSS test on the training dataset
NI_sales_ts_log_train%>% kpss.test()
```
The KPSS test indicates that the log-transformed Northern Ireland housing sales training dataset (NI_sales_ts_log_train) is stationary under the first two scenarios (no drift, no trend, and with drift but no trend).
However, when both drift and trend are considered, the series appears to be non-stationary.

--> Apply differencing to remove the trend and achieve stationarity.

```{r}
#Calculate the number of observations (T)
T_NI_train <- length(NI_sales_ts_log_train)
print(T_NI_train)

# Apply Schwert's Criterion
use_lag_NI_train <- floor(12 * (T_NI_train / 100)^(1/4))
print(use_lag_NI_train)

# Perform KPSS Test with the Chosen Lag
NI_sales_ts_log_train%>% ur.kpss(use.lag = use_lag_NI_train) %>% summary()

```
Fail to Reject the Null Hypothesis: Since the test statistic (0.232) is less than the critical values for all significance levels, we fail to reject the null hypothesis.

Stationary Series: The result suggests that the log-transformed Northern Ireland housing sales training dataset (NI_sales_ts_log_train) is stationary around a level when considering 13 lags.

```{r}
# Determine the Number of Seasonal Differencing (D):
D_NI_train <- nsdiffs(NI_sales_ts_log_train)
print(D_NI_train)

#Determine the Number of Normal Differencing (d):
d_NI_train <- ndiffs(NI_sales_ts_log_train)
print(d_NI_train)

```

--> Should do Normal Differencing

#### Normal differencing

```{r}
d_NI_sales_ts_log_train <- diff (NI_sales_ts_log_train, lag =1, differences=1)

ggtsdisplay(d_NI_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed\nNorthern Ireland Housing Sales training dataset\n(d=1)")

```

#### Test again

##### Perform Augmented Dickey-Fuller (ADF) test
```{r}
tseries::adf.test(na.omit(d_NI_sales_ts_log_train))
```

Stationarity Achieved: The differenced log-transformed Northern Ireland housing sales training dataset is stationary. This is indicated by the ADF test's p-value of 0.01, leading us to reject the null hypothesis of non-stationarity.

Model Readiness: Since the differenced series is now stationary, it is suitable for ARIMA modeling or other time series forecasting methods.

```{r}
adf.test(d_NI_sales_ts_log_train)
```
P-Values: For all three model types and all lags, the p-values are consistently 0.01 or less, indicating strong evidence against the null hypothesis.

ADF Statistics: The highly negative ADF statistics across all scenarios further support the rejection of the null hypothesis.

Stationarity Achieved: The differenced log-transformed Northern Ireland housing sales training dataset is confirmed to be stationary across all model types and lags tested. This strong evidence of stationarity suggests that the series is well-prepared for further time series modeling, such as ARIMA.


##### KPSS test
```{r}
# Perform KPSS test on the housing sales volume
d_NI_sales_ts_log_train%>% kpss.test()
```

For all three model types, the test statistics (0.163, 0.1, and 0.11) are less than the critical values at all significance levels (10%, 5%, 2.5%, and 1%).

Fail to Reject the Null Hypothesis: Since the test statistics are all less than the critical values for all significance levels, we fail to reject the null hypothesis for each model type.

Stationary Series: The results suggest that the differenced log-transformed Northern Ireland housing sales training dataset is stationary.

```{r}
#Calculate the number of observations (T)
d_T_NI_train <- length(d_NI_sales_ts_log_train)
print(d_T_NI_train)

# Apply Schwert's Criterion
d_use_lag_NI_train <- floor(12 * (d_T_NI_train / 100)^(1/4))
print(d_use_lag_NI_train)

# Perform KPSS Test with the Chosen Lag
d_NI_sales_ts_log_train%>% ur.kpss(use.lag = d_use_lag_NI_train ) %>% summary()

```

Test Statistic = 0.0832:
This value is significantly less than the critical values at all significance levels (10%, 5%, 2.5%, and 1%).

Fail to Reject the Null Hypothesis: Since the test statistic (0.0832) is less than the critical values for all significance levels, we fail to reject the null hypothesis.

Stationary Series: The result suggests that the differenced log-transformed Northern Ireland housing sales training dataset is stationary.

### 4.3.2. SARIMA model selection

```{r}
# Fit a SARIMA model using auto.arima with specified parameters for Automatic Model Selection
NI_sarima_1 <- auto.arima(
  NI_sales_ts_log_train,  # The log-transformed training dataset for UK housing sales volume
  max.p = 4,              # Maximum order of the non-seasonal autoregressive part (AR)
  max.q = 4,              # Maximum order of the non-seasonal moving average part (MA)
  max.P = 4,              # Maximum order of the seasonal autoregressive part (SAR)
  max.Q = 4,              # Maximum order of the seasonal moving average part (SMA)
  max.d = 2,              # Maximum number of non-seasonal differences
  max.D = 2,              # Maximum number of seasonal differences
  start.p = 0,            # Starting value of p in the stepwise procedure
  start.q = 0,            # Starting value of q in the stepwise procedure
  start.P = 0,            # Starting value of P in the stepwise procedure
  start.Q = 0,            # Starting value of Q in the stepwise procedure
  stationary = FALSE,     # If TRUE, restricts search to stationary models
  seasonal = TRUE,        # If FALSE, restricts search to non-seasonal models
  ic = c("aicc", "aic", "bic"),  # Information criteria to be used in model selection (AICc, AIC, BIC)
  stepwise = FALSE,       # If TRUE, will do stepwise selection (faster); here set to FALSE for exhaustive search
  trace = TRUE,           # If TRUE, the list of ARIMA models considered will be reported
  approximation = FALSE,  # If TRUE, estimation is via conditional sums of squares and approximated information criteria; here set to FALSE for exact MLE
  test = c("kpss", "adf", "pp")  # Unit root tests to be used for non-seasonal differencing
)

```

--> Best model: ARIMA(0,1,0)(1,0,4)[12]    

```{r}
# Summary the model
summary(NI_sarima_1)
```

#### Calculate Residual Sums of Squares and AICc value
```{r}
# Number of observations in the training set
n_train <- length(NI_sales_ts_log_train)

# Calculate metrics for each model

cat("Auto Model Metrics:")
calculate_metrics(NI_sarima_1, n_train)
```

### 4.3.3. Residuals Diagnostics
#### Residual PLots

```{r}
# Extract residuals and fitted values
residuals <- as.numeric(residuals(NI_sarima_1))  # Convert to numeric
fitted_values <- as.numeric(fitted(NI_sarima_1)) # Convert to numeric
observations <- seq_along(residuals)

# Create a data frame for plotting
data <- data.frame(Residuals = residuals, Fitted = fitted_values, Observation = observations)

# 1. Normal Probability Plot
p1 <- ggplot(data, aes(sample = Residuals)) +
  stat_qq() +
  stat_qq_line() +
  ggtitle("Normal Probability Plot") +
  theme_minimal()

# 2. Residuals vs Fitted Values
p2 <- ggplot(data, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  ggtitle("Residuals vs Fitted Values") +
  theme_minimal()

# 3. Histogram of Residuals
p3 <- ggplot(data, aes(x = Residuals)) +
  geom_histogram(binwidth = 0.1, fill = "#008FC8", color = "black", alpha = 0.7) +
  ggtitle("Histogram of Residuals") +
  theme_minimal()

# 4. Residuals vs Observation Order
p4 <- ggplot(data, aes(x = Observation, y = Residuals)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  ggtitle("Residuals vs Observation Order") +
  theme_minimal()

# Arrange the plots in a grid with a main title
title <- grid::textGrob("Residual Plots for ARIMA(0,1,0)(1,0,4)[12]", gp = grid::gpar(fontsize = 16, fontface = "bold"))

# Combine the plots with the title
gridExtra::grid.arrange(
  gridExtra::arrangeGrob(p1, p2, p3, p4, ncol = 2, top = title)
)

```

#### Create ACF and PACF

```{r}

# Extract residuals
residuals <- as.numeric(residuals(NI_sarima_1))  # Convert to numeric

# ACF plot
acf_data <- acf(residuals, plot = FALSE)
acf_df <- data.frame(lag = acf_data$lag, acf = acf_data$acf)

p_acf <- ggplot(acf_df, aes(x = lag, y = acf)) +
  geom_bar(stat = "identity", position = "dodge", fill = "#008FC8", color = "black") +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  geom_hline(yintercept = -qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  ggtitle("ACF of Residuals for ARIMA(0,1,0)(1,0,4)[12]") +
  theme_minimal()

# PACF plot
pacf_data <- pacf(residuals, plot = FALSE)
pacf_df <- data.frame(lag = pacf_data$lag, pacf = pacf_data$acf)

p_pacf <- ggplot(pacf_df, aes(x = lag, y = pacf)) +
  geom_bar(stat = "identity", position = "dodge", fill = "#008FC8", color = "black") +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  geom_hline(yintercept = -qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  ggtitle("PACF of Residuals for ARIMA(0,1,0)(1,0,4)[12]") +
  theme_minimal()

# Combine the plots
gridExtra::grid.arrange(p_acf, p_pacf, ncol = 1)

```
ACF Plot:

- Most residual autocorrelations are within the confidence intervals, indicating no significant autocorrelation at most lags.

- However, the significant spike at lag 1 suggests some remaining autocorrelation.

PACF Plot:

- Most residual partial autocorrelations are within the confidence intervals, indicating no significant partial autocorrelation at most lags.

- The significant spikes at lower lags, especially at lag 1 and lag 2, suggest some remaining structure in the residuals.

#### Check residual
```{r}
checkresiduals(NI_sarima_1, main = "Residuals of ARIMA(0,1,0)(1,0,4)[12]")
```

Conclusion
- Fail to Reject the Null Hypothesis: Since the p-value is 0.2948, which is greater than 0.05, we fail to reject the null hypothesis. This indicates that there is no significant autocorrelation in the residuals of the ARIMA(0,1,0)(1,0,4)[12] model.

- Independent Residuals: The residuals appear to be independently distributed, suggesting that the model has adequately captured the time series structure, and there are no remaining patterns in the residuals that need to be modeled.

Summary:
- Good Model Fit: The Ljung-Box test results indicate that the residuals from the ARIMA(0,1,0)(1,0,4)[12] model do not exhibit significant autocorrelation, supporting the adequacy of the model fit.

- Model Diagnostics: The residual diagnostics, including the Ljung-Box test, suggest that the model is well-specified and can be used for forecasting purposes.

#### Ljung-Box test
```{r}
# Define the lags to test
lags <- c(12, 24, 36, 48)

# Perform Ljung-Box test for each model
cat("Ljung-Box Test Results:")
perform_ljung_box_test(NI_sarima_1, lags)

```

- Overall Model Fit: The residuals from the ARIMA(0,1,0)(1,0,4)[12] model generally do not exhibit significant autocorrelation at the tested lags (12, 24, 36, 48).

- Lag 12 Caution: The p-value at lag 12 is slightly above 0.05, indicating potential autocorrelation, though it is not statistically significant. It may be worth investigating further or considering minor model adjustments.

The Ljung-Box test results suggest that the residuals are independently distributed, indicating that the ARIMA(0,1,0)(1,0,4)[12] model is well-specified.

#### BJM test
```{r}
bjm_test(NI_sarima_1)

```
Significant Coefficients: The sar1 and sma4 parameters are significant, indicating they are important components of the model.

Residual Independence: The Box-Ljung test suggests that the residuals are independently distributed, indicating no significant autocorrelation in the residuals, though the p-value at lag 12 is slightly above 0.05, suggesting close monitoring.

#### ADF test and KPSS test for residuals 
```{r}
# ADF test
tseries::adf.test(NI_sarima_1$residuals)

# KPSS test
NI_sarima_1$residuals%>% ur.kpss(use.lag = (floor(12* (length(NI_sales_ts_log_train) /100)^(1/4)))) %>% summary()
```
ADF test
Reject the Null Hypothesis: Since the p-value is 0.01, which is equal to the threshold of 0.01, we reject the null hypothesis.

Stationary Residuals: The result indicates that the residuals from the ARIMA(0,1,0)(1,0,4)[12] model are stationary.

#### Perform Shapiro-Wilk test for each model
```{r}
cat("Stepwise Model Shapiro-Wilk Test Results:")
shapiro_wilk_test(NI_sarima_1)

```
Non-Normal Residuals: The Shapiro-Wilk test strongly indicates that the residuals from the ARIMA(0,1,0)(1,0,4)[12] model are not normally distributed.

#### Q-Q plot
```{r}
# Plot the residuals
plot(NI_sarima_1$residuals, main = "Residuals of SARIMA Model")

# Q-Q plot
qqnorm(NI_sarima_1$residuals)
qqline(NI_sarima_1$residuals, col = "red")

```


#### Test for Heteroscedasticity

```{r}
# Perform ARCH test for each model
cat("ARCH Test Results:")
perform_arch_test(NI_sarima_1, lags)

```

- Significant heteroskedasticity is detected at lag 12 (p-value < 0.05).

- There is weak evidence of heteroskedasticity at lags 24 and 36 (p-value between 0.05 and 0.10).

- There is no significant evidence of heteroskedasticity at lag 48 (p-value > 0.10).

#### Check parameter estimation
```{r}
# Define your SARIMA model parameters
order <- c(0,1,0)
seasonal_order <- c(1,0,4)
period <- 12

# Assuming `NI_sales_ts_log_train` is your time series data
# Fit the model with custom iteration capture
result <- capture_iterations(NI_sales_ts_log_train, order, seasonal_order, period)
fit <- result$fit
iterations_df <- result$iterations

print(iterations_df)

```

Convergence:

- The SSE and parameter estimates remain constant across all iterations. This suggests that the model fitting process has converged, and the parameter estimates have stabilized.
- Convergence is a good sign as it indicates that the model has found a stable solution and that further iterations do not change the parameter estimates.

Parameter Significance:

- The estimated coefficients for the parameters (sar1, sma1, sma2, sma3, and sma4) are provided. In the earlier z-test results, only sar1 and sma4 were significant.
- The fact that the non-significant parameters (sma1, sma2, sma3) remain in the model without changing the SSE might suggest that they are not contributing much to the model.

Model Fit:

- The SSE value of 1.722517 indicates the sum of squared errors for the residuals of the fitted model. Lower SSE values indicate a better fit, but this must be interpreted in the context of the specific data and the scale of the time series.

### 4.3.4. Forecast with SARIMA model

```{r}
# Forecast result
NI_sarima_result_1 <- forecast::forecast(NI_sarima_1, h = 12)

# Plot the forecast result 

plot(NI_sarima_result_1, main = paste("Fitted from",NI_sarima_result_1$method), xlab = "Time", ylab = "Values") 
lines(NI_sarima_result_1$fitted, col = "red",lty = "dashed", lwd = 1) 
legend("bottomright", legend = c("OS Visit", NI_sarima_result_1$method), col = c("black", "red"), lty = 1:2, cex = 0.8)

```

```{r}
plot_fore(NI_sales_ts_log_test,NI_sarima_result_1)

```

```{r}
plot_fore_exp(NI_sales_ts_log_test,NI_sarima_result_1)
```

```{r}
# Calculate Mean Absolute Percentage Error (MAPE)
mape_log <- round(MLmetrics::MAPE(NI_sarima_result_1$mean, NI_sales_ts_log_test) * 100, 2)
mape_exp <- round(MLmetrics::MAPE(exp(NI_sarima_result_1$mean), exp(NI_sales_ts_log_test)) * 100, 2)

# Calculate Mean Absolute Error (MAE)
mae_log <- round(MLmetrics::MAE(NI_sarima_result_1$mean, NI_sales_ts_log_test), 2)
mae_exp <- round(MLmetrics::MAE(exp(NI_sarima_result_1$mean), exp(NI_sales_ts_log_test)), 2)

# Convert MAE to percentage of the mean actual values
mae_log_percentage <- round((mae_log / mean(NI_sales_ts_log_test)) * 100, 2)
mae_exp_percentage <- round((mae_exp / mean(exp(NI_sales_ts_log_test))) * 100, 2)

# Manually calculate Mean Percentage Error (MPE)
mpe_log <- round(mean((NI_sarima_result_1$mean - NI_sales_ts_log_test) / NI_sales_ts_log_test) * 100, 2)
mpe_exp <- round(mean((exp(NI_sarima_result_1$mean) - exp(NI_sales_ts_log_test)) / exp(NI_sales_ts_log_test)) * 100, 2)

# Calculate Root Mean Squared Error (RMSE)
rmse_log <- round(MLmetrics::RMSE(NI_sarima_result_1$mean, NI_sales_ts_log_test), 2)
rmse_exp <- round(MLmetrics::RMSE(exp(NI_sarima_result_1$mean), exp(NI_sales_ts_log_test)), 2)

# Print the results
cat("Log-Transformed Data:\n")
cat("MAPE:", mape_log, "%\n")
cat("MAE:", mae_log, "\n")
cat("MAE (Percentage):", mae_log_percentage, "%\n")
cat("MPE:", mpe_log, "%\n")
cat("RMSE:", rmse_log, "\n")

cat("\nBack-Transformed Data (Exponential):\n")
cat("MAPE:", mape_exp, "%\n")
cat("MAE:", mae_exp, "\n")
cat("MAE (Percentage):", mae_exp_percentage, "%\n")
cat("MPE:", mpe_exp, "%\n")
cat("RMSE:", rmse_exp, "\n")
```

```{r}
# Save result
#sarima_NI_forecast <- cbind(NI_sarima_result_1$mean,NI_sarima_result_1$upper[, "95%"],NI_sarima_result_1$lower[, "95%"])

sarima_NI_forecast <- cbind(exp(NI_sarima_result_1$mean),exp(NI_sarima_result_1$upper[, "95%"]), exp(NI_sarima_result_1$lower[, "95%"]))
```

## 4.4. SARIMA for Scotland series

### 4.4.1. Model building

```{r}
# Store data of Pre-Covid as time series
S_sales_ts_pre <- S_sales_ts %>% window (end=c(2020,02))

ggtsdisplay(S_sales_ts_pre, lag.max=40, main ="Time series, ACF and PACF of S_sales_ts_pre")

```

```{r}
# Seasonal decomposition
decomposed <- stl(S_sales_ts_pre, s.window = "periodic")
autoplot(decomposed) +
  ggtitle("Seasonal Decomposition of Scotland\nHousing Sales Volume") +
  theme(plot.title = element_text(hjust = 0.5))
```

#### Guerrero test

```{r}
# Guerrero test 
guerrero_lambda <- BoxCox.lambda(S_sales_ts_pre, method = "guerrero")
print(paste("Optimal lambda using Guerrero method:", guerrero_lambda))
```

--> The optimal lambda using the Guerrero method is approximately 0.433. This value suggests that the data would benefit from a transformation to stabilize variance and make the data more suitable for modeling.

Notes: Lambda = 1: No transformation (original data)
       Lambda = 0: Log transformation

#### Log transformation
```{r}
# Log transformation using the optimal lambda
S_sales_ts_log <- log(S_sales_ts_pre)

```

```{r}
# Plot the transformed data
autoplot(S_sales_ts_log) +
  ggtitle("Log Transformed Scotland Housing Sales\nVolume of Pre-Covid period") +
  xlab("Time") + ylab("Log Transformed Sales Volume") +
  theme(plot.title = element_text(hjust = 0.5))

```

```{r}
# Seasonal decomposition of transformed data
decomposed_log <- stl(S_sales_ts_log, s.window = "periodic")
autoplot(decomposed_log) +
  ggtitle("Seasonal Decomposition of Log Transformed\nScotland Housing Sales Volume of\nPre-Covid period") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
# Display time series, ACF, and PACF of transformed data
ggtsdisplay(S_sales_ts_log, lag.max = 40, main = 'Time series, ACF, and PACF of Log Transformed\nScotland Housing Sales of Pre-Covid period ')

```

#### Split the data into training and test sets

```{r}
# Create a training dataset from January 2005 to February 2019
S_sales_ts_log_train <- window(S_sales_ts_log, start = c(2005, 1), end = c(2019, 2))

# Create a test dataset from March 2019 to February 2020
S_sales_ts_log_test <- window(S_sales_ts_log, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the time series
str(S_sales_ts_log_train)
str(S_sales_ts_log_test)

# Print the time series data
print(S_sales_ts_log_train)
print(S_sales_ts_log_test)

```

#### Plot of Training and Test dataset
```{r}
# Set up the plotting area for two plots
par(mfrow = c(2, 1), cex.main = 0.9, cex.lab = 0.8, cex.axis = 0.8, lty=1, lwd = 1.8)

# Plot the training set with smaller text
plot(S_sales_ts_log_train, 
     main = "Training Set of Log Transformed Scotland\nHousing Sales Volume", 
     xlab = "Time", 
     ylab = "Log Transformed Sales Volume")
grid()

# Plot the test set with smaller text
plot(S_sales_ts_log_test, 
     main = "Test Set of Log Transformed Scotland\nHousing Sales Volume", 
     xlab = "Time", 
     ylab = "Log Transformed Sales Volume")
grid()

```

```{r}
# Reset plotting area to default to ensure subsequent plots are displayed one at a time
par(mfrow = c(1, 1))
```

#### Time series comparision 
```{r}

# Determine the range of the combined dataset for consistent y-axis limits
combined_range <- range(c(S_sales_ts_log_train, S_sales_ts_log_test))

# Overlay plot for comparison with thicker lines and adjusted axes
plot(S_sales_ts_log_train, main = "Time Series Comparison", ylab = "Values", xlab = "Time", lwd = 2, ylim = combined_range, xlim = c(time(S_sales_ts_log_train)[1], time(S_sales_ts_log_test)[length(S_sales_ts_log_test)]))
lines(S_sales_ts_log_test, col = "red", lwd = 2)
legend("bottomright", legend = c("Train", "Test"), col = c("black", "red"), lty = 1, lwd = 2)

```

```{r}
# Check seasonality
seasonplot(S_sales_ts_log_train, main = "Seasonal plot: S_sales_ts_log_train", col = 1, lwd = 1.5)
```
The seasonal plot of the log-transformed sales volume for the dataset "S_sales_ts_log_train" reveals a strong and consistent seasonal pattern. Sales volumes peak in January and February, drop in March, and rise again around June and July, followed by a decline towards year-end. Despite variability in sales from year to year, the overall seasonal trend remains stable. The log transformation stabilizes the variance, with values ranging from approximately 8.0 to 9.5, making it easier to observe these patterns. These seasonal fluctuations are critical for accurate forecasting, highlighting predictable changes in sales volume throughout the year.

```{r}
# Generate a seasonal subseries plot for the log-transformed UK sales training data
monthplot(S_sales_ts_log_train,lwd = 1.5 )
```

The time series plot of the log-transformed sales volume for the dataset "S_sales_ts_log_train" indicates pronounced seasonality and variability in sales throughout the year. The plot reveals distinct seasonal peaks, particularly noticeable in the middle and end of each year, with sharp increases in sales volume. Despite fluctuations, there is an overall upward trend in sales volume from January to December. The log transformation helps stabilize the variance, with values ranging from approximately 8.5 to 9.5. This seasonal pattern and variability highlight the importance of considering seasonal effects in forecasting models to accurately capture the trends in sales volume.

```{r}
# Generate a combined plot displaying the time series, ACF, and PACF of the log-transformed Scotland sales training data

ggtsdisplay(S_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed\nScotland Housing Sales training dataset")
```
- The time series exhibits strong seasonality and some level of periodicity.

- The ACF shows significant autocorrelations at seasonal lags, suggesting the presence of seasonal patterns.

- The PACF indicates that an autoregressive model of low order (such as AR(1) or AR(2)) might be appropriate for modeling this time series.


#### Perform Augmented Dickey-Fuller (ADF) test
```{r}
tseries::adf.test(S_sales_ts_log_train)

```
The test statistic of -2.8235 is compared against critical values to determine stationarity.

The p-value of 0.2325 is greater than the common significance levels (e.g., 0.01, 0.05, 0.10), indicating that we fail to reject the null hypothesis of non-stationarity.
Therefore, based on this test, the log-transformed UK sales training data is not stationary.


```{r}
# ADF test for three different model types
adf.test(S_sales_ts_log_train)
```
- The results indicate that the log-transformed Scotland housing sales training dataset is not stationary when no drift or trend is considered (Type 1).

- When a drift term is included (Type 2), there is stronger evidence to suggest stationarity, especially at lower lags.

- Including both drift and trend (Type 3) shows mixed results, with stationarity evident at the lowest lags but not at higher lags.

Given the significant p-values in Type 2, it appears that the time series may be best modeled with an inclusion of a drift term but without a trend. Further analysis might involve differencing the time series to achieve stationarity if necessary for modeling purposes.

#### KPSS test
```{r}
# Perform KPSS test on the training dataset
S_sales_ts_log_train%>% kpss.test()
```
- The ADF test (Type 2) indicated that the series could be stationary with drift.
- The KPSS test (Type 2) supports this by suggesting stationarity with drift.
However, the KPSS test (Type 3) indicates non-stationarity when both drift and trend are included.

Overall, the evidence points towards the time series being stationary with a drift component but without a trend. For modeling purposes, this suggests that including a drift term might be appropriate, but additional steps to account for trends or seasonal differencing may be necessary if modeling trends or seasonality explicitly.

```{r}
# Calculate the number of observations (T)
T_S_train <- length(S_sales_ts_log_train)
print(T_S_train)

# Apply Schwert's Criterion
use_lag_S_train <- floor(12 * (T_S_train / 100)^(1/4))
print(use_lag_S_train)

# Perform KPSS Test with the Chosen Lag
S_sales_ts_log_train%>% ur.kpss(use.lag = use_lag_S_train) %>% summary()

```
Since the test statistic is less than the critical value at the 10% significance level, we fail to reject the null hypothesis of stationarity. Therefore, the log-transformed Scotland housing sales training dataset can be considered stationary under the conditions tested (with a constant but no trend).

```{r}
# Determine the Number of Seasonal Differencing (D):
D_S_train <- nsdiffs(S_sales_ts_log_train)
print(D_S_train)

#Determine the Number of Normal Differencing (d):
d_S_train <- ndiffs(S_sales_ts_log_train)
print(d_S_train)

```

--> Should do differencing

#### Seasonal Differencing 

```{r}
d_S_sales_ts_log_train <- diff (S_sales_ts_log_train, lag =12, differences=1)

ggtsdisplay(d_S_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed\nScotland Housing Sales training dataset (D=1)")
```

- Stationarity: The time series appears to be stationary after first differencing, as indicated by the fluctuations around zero in the time series plot.

- Seasonality: The ACF plot shows significant autocorrelations at seasonal lags, indicating seasonality. The PACF plot shows significant partial correlations at specific lags, reinforcing this observation.

- ARIMA Model Identification: The patterns in the ACF and PACF plots suggest that an ARIMA model with seasonal components may be appropriate. Specifically, the ARIMA model may need terms to account for both the non-seasonal and seasonal autocorrelations.

#### Test again

##### Perform Augmented Dickey-Fuller (ADF) test - Unit root tests
```{r}
# ADF test
tseries::adf.test(d_S_sales_ts_log_train)
```

- p-value (0.05386): This p-value is slightly above the conventional 5% significance level (0.05). Therefore, at the 5% level, we fail to reject the null hypothesis of non-stationarity. However, the p-value is quite close to 0.05, suggesting weak evidence against the null hypothesis.

- Alternative Hypothesis (Stationary): The test is close to suggesting stationarity but does not do so definitively at the 5% significance level.

```{r}
# ADF test with three types
adf.test(d_S_sales_ts_log_train)
```
Type 1: The differenced series is mostly stationary without drift or trend, as evidenced by the significant p-values at most lags.
Type 2: The series is stationary at lag 0 with drift but shows weaker evidence of stationarity at higher lags.
Type 3: The series is stationary at lag 0 with drift and trend but not at higher lags.

--> Still need apply normal differencing to remove trend

##### KPSS test
```{r}
# Perform KPSS test on the housing sales volume
d_S_sales_ts_log_train%>% kpss.test()
```

- No Drift, No Trend (Type 1): The high p-value (>= 0.1) suggests that we fail to reject the null hypothesis, indicating that the differenced series is stationary without drift or trend.

- With Drift, No Trend (Type 2): The p-value is 0.0797, which is close to 0.1, suggesting that the series is nearly stationary with a drift term.

- With Drift and Trend (Type 3): The p-value is 0.0716, suggesting weak evidence against stationarity, but still indicating near stationarity when considering both drift and trend.

```{r}
#Calculate the number of observations (T)
d_T_S_train <- length(d_S_sales_ts_log_train)
print(d_T_S_train)

# Apply Schwert's Criterion
d_use_lag_S_train <- floor(12 * (d_T_S_train / 100)^(1/4))
print(d_use_lag_S_train)

# Perform KPSS Test with the Chosen Lag
d_S_sales_ts_log_train%>% ur.kpss(use.lag = d_use_lag_S_train ) %>% summary()

```
Since the test statistic (0.234) is less than the critical value at the 10% significance level (0.347), we fail to reject the null hypothesis of stationarity. Therefore, the differenced log-transformed Scotland housing sales training dataset can be considered stationary under the conditions tested (with a constant but no trend).

```{r}
#Determine the Number of Normal Differencing (d):
d_S_train <- ndiffs(d_S_sales_ts_log_train)
print(d_S_train)
```

--> Need to do Normal differencing

#### Normal differencing

```{r}
dd_S_sales_ts_log_train <- diff (d_S_sales_ts_log_train, lag =1, differences=1)

ggtsdisplay(dd_S_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed\nScotland Housing Sales training dataset\n(d=1, D=1)")

```

#### Test again

##### Perform Augmented Dickey-Fuller (ADF) test
```{r}
tseries::adf.test(na.omit(dd_S_sales_ts_log_train))
```

- p-value (0.03707): This p-value is less than the conventional 5% significance level (0.05). Therefore, we reject the null hypothesis of non-stationarity at the 5% significance level. This indicates that the twice-differenced log-transformed time series is stationary.

- Alternative Hypothesis (Stationary): The test provides evidence that the time series is stationary after the second differencing.

```{r}
# ADF test with three different types
adf.test(dd_S_sales_ts_log_train)
```
Rejecting Null Hypothesis: Given the p-values (<= 0.01) across all models and lags, we reject the null hypothesis of non-stationarity.

Stationarity: The results strongly indicate that the twice-differenced log-transformed time series is stationary.

##### KPSS test
```{r}
# Perform KPSS test on the housing sales volume
dd_S_sales_ts_log_train%>% kpss.test()
```

The KPSS test results show that the twice-differenced log-transformed Scotland housing sales training dataset (dd_S_sales_ts_log_train) is stationary across all model types (no drift, with drift, and with drift and trend). The low test statistics and high p-values provide strong evidence that the series is stationary.

```{r}
#Calculate the number of observations (T)
dd_T_S_train <- length(dd_S_sales_ts_log_train)
print(dd_T_S_train)

# Apply Schwert's Criterion
dd_use_lag_S_train <- floor(12 * (dd_T_S_train / 100)^(1/4))
print(dd_use_lag_S_train)

# Perform KPSS Test with the Chosen Lag
dd_S_sales_ts_log_train%>% ur.kpss(use.lag = dd_use_lag_S_train ) %>% summary()

```

Since the test statistic (0.0458) is much lower than the critical values, we fail to reject the null hypothesis of stationarity. Therefore, the twice-differenced log-transformed Scotland housing sales training dataset can be considered stationary under the conditions tested (with a constant but no trend).

--> The time series is stationary

### 4.4.2. SARIMA model selection

```{r}
# Fit a SARIMA model using auto.arima with specified parameters for Automatic Model Selection
S_sarima_1 <- auto.arima(
  S_sales_ts_log_train,  # The log-transformed training dataset for UK housing sales volume
  max.p = 4,              # Maximum order of the non-seasonal autoregressive part (AR)
  max.q = 4,              # Maximum order of the non-seasonal moving average part (MA)
  max.P = 4,              # Maximum order of the seasonal autoregressive part (SAR)
  max.Q = 4,              # Maximum order of the seasonal moving average part (SMA)
  max.d = 2,              # Maximum number of non-seasonal differences
  max.D = 2,              # Maximum number of seasonal differences
  start.p = 0,            # Starting value of p in the stepwise procedure
  start.q = 0,            # Starting value of q in the stepwise procedure
  start.P = 0,            # Starting value of P in the stepwise procedure
  start.Q = 0,            # Starting value of Q in the stepwise procedure
  stationary = FALSE,     # If TRUE, restricts search to stationary models
  seasonal = TRUE,        # If FALSE, restricts search to non-seasonal models
  ic = c("aicc", "aic", "bic"),  # Information criteria to be used in model selection (AICc, AIC, BIC)
  stepwise = FALSE,       # If TRUE, will do stepwise selection (faster); here set to FALSE for exhaustive search
  trace = TRUE,           # If TRUE, the list of ARIMA models considered will be reported
  approximation = FALSE,  # If TRUE, estimation is via conditional sums of squares and approximated information criteria; here set to FALSE for exact MLE
  test = c("kpss", "adf", "pp")  # Unit root tests to be used for non-seasonal differencing
)

```

--> Best model: ARIMA(3,1,1)(0,1,1)[12]   

```{r}
# Print summary of the model
summary(S_sarima_1)
```

#### Calculate Residual Sums of Squares and AICc value
```{r}
# Number of observations in the training set
n_train <- length(S_sales_ts_log_train)

# Calculate metrics for each model

cat("SARIMA Model Metrics:\n")
calculate_metrics(S_sarima_1, n_train)
```

### 4.4.3. Residuals Diagnostics
#### Draw Residual Plots

```{r}
# Extract residuals and fitted values
residuals <- as.numeric(residuals(S_sarima_1))  # Convert to numeric
fitted_values <- as.numeric(fitted(S_sarima_1)) # Convert to numeric
observations <- seq_along(residuals)

# Create a data frame for plotting
data <- data.frame(Residuals = residuals, Fitted = fitted_values, Observation = observations)

# 1. Normal Probability Plot
p1 <- ggplot(data, aes(sample = Residuals)) +
  stat_qq() +
  stat_qq_line() +
  ggtitle("Normal Probability Plot") +
  theme_minimal()

# 2. Residuals vs Fitted Values
p2 <- ggplot(data, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  ggtitle("Residuals vs Fitted Values") +
  theme_minimal()

# 3. Histogram of Residuals
p3 <- ggplot(data, aes(x = Residuals)) +
  geom_histogram(binwidth = 0.1, fill = "#008FC8", color = "black", alpha = 0.7) +
  ggtitle("Histogram of Residuals") +
  theme_minimal()

# 4. Residuals vs Observation Order
p4 <- ggplot(data, aes(x = Observation, y = Residuals)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  ggtitle("Residuals vs Observation Order") +
  theme_minimal()

# Arrange the plots in a grid with a main title
title <- grid::textGrob("Residual Plots for ARIMA(3,1,1)(0,1,1)[12]", gp = grid::gpar(fontsize = 16, fontface = "bold"))

# Combine the plots with the title
gridExtra::grid.arrange(
  gridExtra::arrangeGrob(p1, p2, p3, p4, ncol = 2, top = title)
)

```

- Normality: The normal probability plot and histogram indicate that the residuals are approximately normally distributed.

- Homoscedasticity: The residuals vs fitted values plot shows no clear pattern, indicating constant variance of the residuals.

- Independence: The residuals vs observation order plot shows no autocorrelation, suggesting the residuals are independent.

#### Create ACF and PACF

```{r}

# Extract residuals
residuals <- as.numeric(residuals(S_sarima_1))  # Convert to numeric

# ACF plot
acf_data <- acf(residuals, plot = FALSE)
acf_df <- data.frame(lag = acf_data$lag, acf = acf_data$acf)

p_acf <- ggplot(acf_df, aes(x = lag, y = acf)) +
  geom_bar(stat = "identity", position = "dodge", fill = "#008FC8", color = "black") +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  geom_hline(yintercept = -qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  ggtitle("ACF of Residuals for ARIMA(3,1,1)(0,1,1)[12]") +
  theme_minimal()

# PACF plot
pacf_data <- pacf(residuals, plot = FALSE)
pacf_df <- data.frame(lag = pacf_data$lag, pacf = pacf_data$acf)

p_pacf <- ggplot(pacf_df, aes(x = lag, y = pacf)) +
  geom_bar(stat = "identity", position = "dodge", fill = "#008FC8", color = "black") +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  geom_hline(yintercept = -qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  ggtitle("PACF of Residuals for ARIMA(3,1,1)(0,1,1)[12]") +
  theme_minimal()

# Combine the plots
gridExtra::grid.arrange(p_acf, p_pacf, ncol = 1)

```

- ACF and PACF Analysis: The residuals' ACF and PACF plots indicate that most autocorrelations and partial autocorrelations are close to zero and within the significance bounds, suggesting that the residuals do not exhibit significant autocorrelation at most lags. This implies that the ARIMA(3,1,1)(0,1,1)[12] model has adequately captured the time series' structure.

- Significant Lags: The slight spikes at lags 4, 5, and 13 in the PACF and at lag 12 in the ACF could suggest some minor seasonal or periodic components that might not be fully captured by the model. However, these are not severe and might be due to random noise.

#### Check residual
```{r}
checkresiduals(S_sarima_1, main = "Residuals of ARIMA(3,1,1)(0,1,1)[12]")
```

- Normality: The histogram suggests that the residuals are approximately normally distributed.

- Independence: The ACF plot indicates that the residuals are largely uncorrelated, with most autocorrelations within the significance bounds.

- Homoscedasticity: The residuals fluctuate randomly around zero in the time series plot, indicating constant variance.

The diagnostic plots collectively suggest that the ARIMA(3,1,1)(0,1,1)[12] model fits the data well. The residuals appear to behave like white noise, meaning they are normally distributed, have constant variance, and are largely independent. These characteristics indicate that the model is appropriate for the data and that the assumptions underlying the ARIMA model are reasonably satisfied.

Ljung-Box test

- Significance Level: If we use a typical significance level (e.g., 0.05), the p-value (0.02099) is less than 0.05.

- Rejecting the Null Hypothesis: Since the p-value is less than 0.05, we reject the null hypothesis of no autocorrelation in the residuals. This suggests that there is evidence of autocorrelation in the residuals up to lag 24.

#### Ljung-Box test
```{r}
# Define the lags to test
lags <- c(12, 24, 36, 48)

# Perform Ljung-Box test for each model
cat("Ljung-Box Test Results:")
perform_ljung_box_test(S_sarima_1, lags)

```

The Ljung-Box test results support the conclusion that the residuals from the ARIMA(3,1,1)(0,1,1)[12] model are approximately white noise, indicating that the model is appropriate for the data. The absence of significant autocorrelation in the residuals suggests that the model has successfully captured the dependencies in the time series data.

#### ADF test and KPSS test for residuals 
```{r}
# ADF test
tseries::adf.test(S_sarima_1$residuals)

# KPSS test
S_sarima_1$residuals%>% ur.kpss(use.lag = (floor(12* (length(S_sales_ts_log_train) /100)^(1/4)))) %>% summary()
```
ADF Test: The p-value (0.01) and highly negative test statistic (-4.3129) indicate strong evidence that the residuals are stationary.

KPSS Test: The test statistic (0.1311) is significantly below the critical values, further confirming the stationarity of the residuals.


#### BJM test
```{r}
bjm_test(S_sarima_1)

```

Model Coefficients: Most of the coefficients (ar3, ma1, and sma1) are highly significant, indicating that these terms are crucial for the model. The ar1 term is not significant, suggesting it may not be necessary.

Residuals: The Box-Ljung test indicates that the residuals are independently distributed, which is a good sign of model adequacy.


#### Q-Q plot
```{r}
# Plot the residuals
plot(S_sarima_1$residuals, main = "Residuals of SARIMA Model")

# Q-Q plot
qqnorm(S_sarima_1$residuals)
qqline(S_sarima_1$residuals, col = "red")

```


#### Test for Heteroscedasticity

```{r}
# Perform ARCH test for each model
cat("ARCH Test Results:")
perform_arch_test(S_sarima_1, lags)

```

- Presence of Heteroskedasticity: There is evidence of heteroskedasticity at lag 12, suggesting that the residuals exhibit changing variance at this lag.

- No Heteroskedasticity at Higher Lags: The absence of significant heteroskedasticity at lags 24, 36, and 48 indicates that the residuals' variance is stable at these higher lags.

#### Check parameter estimation
```{r}
# Define your SARIMA model parameters
order <- c(3, 1, 1)
seasonal_order <- c(0, 1, 1)
period <- 12

# Assuming `S_sales_ts_log_train` is your time series data
# Fit the model with custom iteration capture
result <- capture_iterations(S_sales_ts_log_train, order, seasonal_order, period)
fit <- result$fit
iterations_df <- result$iterations

print(iterations_df)

```
- Convergence: The fitting process converged quickly, as indicated by the constant values across iterations.

- Model Stability: The ARIMA(3,1,1)(0,1,1)[12] model appears stable with well-estimated parameters.

- Parameter Significance: The parameter estimates suggest that the AR(3), MA(1), and SMA(1) terms are significant components of the model.

### 4.4.4. Forecast with SARIMA model

```{r}
# Forecast result

S_sarima_result_1 <- forecast::forecast(S_sarima_1, h = 12)

# Plot the forecast result 

plot(S_sarima_result_1, main = paste("Fitted from",S_sarima_result_1$method), xlab = "Time", ylab = "Values") 
lines(S_sarima_result_1$fitted, col = "red",lty = "dashed", lwd = 1) 
legend("bottomright", legend = c("OS Visit", S_sarima_result_1$method), col = c("black", "red"), lty = 1:2, cex = 0.8)

```

```{r}
plot_fore(S_sales_ts_log_test,S_sarima_result_1)

```

```{r}
plot_fore_exp(S_sales_ts_log_test,S_sarima_result_1)
```

```{r}
# Calculate Mean Absolute Percentage Error (MAPE)
mape_log <- round(MLmetrics::MAPE(S_sarima_result_1$mean, S_sales_ts_log_test) * 100, 2)
mape_exp <- round(MLmetrics::MAPE(exp(S_sarima_result_1$mean), exp(S_sales_ts_log_test)) * 100, 2)

# Calculate Mean Absolute Error (MAE)
mae_log <- round(MLmetrics::MAE(S_sarima_result_1$mean, S_sales_ts_log_test), 2)
mae_exp <- round(MLmetrics::MAE(exp(S_sarima_result_1$mean), exp(S_sales_ts_log_test)), 2)

# Manually calculate Mean Percentage Error (MPE)
mpe_log <- round(mean((S_sarima_result_1$mean - S_sales_ts_log_test) /S_sales_ts_log_test) * 100, 2)
mpe_exp <- round(mean((exp(S_sarima_result_1$mean) - exp(S_sales_ts_log_test)) / exp(S_sales_ts_log_test)) * 100, 2)

# Convert MAE to percentage of the mean actual values
mae_log_percentage <- round((mae_log / mean(S_sales_ts_log_test)) * 100, 2)
mae_exp_percentage <- round((mae_exp / mean(exp(S_sales_ts_log_test))) * 100, 2)

# Calculate Root Mean Squared Error (RMSE)
rmse_log <- round(MLmetrics::RMSE(S_sarima_result_1$mean, S_sales_ts_log_test), 2)
rmse_exp <- round(MLmetrics::RMSE(exp(S_sarima_result_1$mean), exp(S_sales_ts_log_test)), 2)

# Print the results
cat("Log-Transformed Data:\n")
cat("MAPE:", mape_log, "%\n")
cat("MAE:", mae_log, "\n")
cat("MAE (Percentage):", mae_log_percentage, "%\n")
cat("MPE:", mpe_log, "%\n")
cat("RMSE:", rmse_log, "\n")

cat("\nBack-Transformed Data (Exponential):\n")
cat("MAPE:", mape_exp, "%\n")
cat("MAE:", mae_exp, "\n")
cat("MAE (Percentage):", mae_exp_percentage, "%\n")
cat("MPE:", mpe_exp, "%\n")
cat("RMSE:", rmse_exp, "\n")
```

```{r}
# Save result
#sarima_S_forecast <- cbind(S_sarima_result_1$mean,S_sarima_result_1$upper[, "95%"],S_sarima_result_1$lower[, "95%"])

sarima_S_forecast <- cbind(exp(S_sarima_result_1$mean),exp(S_sarima_result_1$upper[, "95%"]), exp(S_sarima_result_1$lower[, "95%"]))
```

## 4.5. SARIMA for Wales series

### 4.5.1. Model building
```{r}
# Store data of Pre-Covid as time series
W_sales_ts_pre <- W_sales_ts %>% window (end=c(2020,02))

ggtsdisplay(W_sales_ts_pre, lag.max=40, main ="Time series, ACF and PACF of W_sales_ts_pre")

```

- Time Series Plot: The time series exhibits significant fluctuations over time with noticeable peaks and troughs.There is an apparent trend with periods of increasing and decreasing sales, but no clear long-term trend is visible. Some seasonal patterns might be present, as indicated by the recurring spikes and dips at regular intervals.

- Autocorrelation Function (ACF) Plot: The ACF shows significant correlations at the initial lags, gradually decreasing as the lag increases.The significant spikes beyond the blue dashed lines indicate autocorrelations that are statistically significant.The ACF decays slowly and shows periodic spikes, suggesting seasonality in the data.

- Partial Autocorrelation Function (PACF) Plot: The PACF has a significant spike at the first lag, indicating a strong immediate past relationship.Other lags also show significant partial correlations, particularly around lags 12 and 24, suggesting possible seasonality.The PACF decreases quickly after the first few lags but exhibits periodic significant spikes, reinforcing the presence of seasonality.


```{r}
# Seasonal decomposition
decomposed <- stl(W_sales_ts_pre, s.window = "periodic")
autoplot(decomposed) +
  ggtitle("Seasonal Decomposition of Wales\nHousing Sales Volume") +
  theme(plot.title = element_text(hjust = 0.5))
```
- Trend: The housing sales volume shows periods of increase and decrease, reflecting underlying economic or market conditions over the years.

- Seasonality: The sales volume exhibits a strong, regular seasonal pattern, repeating each year.

- Residuals: The remainder component appears random and centered around zero, indicating that the decomposition has successfully separated the systematic variations from the noise.

#### Guerrero test

```{r}
# Guerrero test 
guerrero_lambda <- BoxCox.lambda(W_sales_ts_pre, method = "guerrero")
print(paste("Optimal lambda using Guerrero method:", guerrero_lambda))
```

--> The optimal lambda using the Guerrero method is approximately 0.435. This value suggests that the data would benefit from a transformation to stabilize variance and make the data more suitable for modeling.

Notes: Lambda = 1: No transformation (original data)
       Lambda = 0: Log transformation

#### Log transformation
```{r}
# Log transformation using the optimal lambda
W_sales_ts_log <- log(W_sales_ts_pre)

```

```{r}
# Plot the transformed data
autoplot(W_sales_ts_log) +
  ggtitle("Log Transformed Wales Housing Sales\nVolume of Pre-Covid period") +
  xlab("Time") + ylab("Log Transformed Sales Volume") +
  theme(plot.title = element_text(hjust = 0.5))

```

```{r}

# Seasonal decomposition of transformed data
decomposed_log <- stl(W_sales_ts_log, s.window = "periodic")
autoplot(decomposed_log) +
  ggtitle("Seasonal Decomposition of Log Transformed\nWales Housing Sales Volume of Pre-Covid period") +
  theme(plot.title = element_text(hjust = 0.5))
```

- Trend: The housing sales volume shows periods of increase and decrease, reflecting underlying economic or market conditions over the years.

- Seasonality: The sales volume exhibits a strong, regular seasonal pattern, repeating each year.

- Residuals: The remainder component appears random and centered around zero, indicating that the decomposition has successfully separated the systematic variations from the noise.

```{r}
# Display time series, ACF, and PACF of transformed data
ggtsdisplay(W_sales_ts_log, lag.max = 40, main = 'Time series, ACF, and PACF of Log Transformed\nWales Housing Sales of Pre-Covid period ')
```

- Stationarity: The time series appears to be non-stationary, as indicated by the significant autocorrelations in the ACF and the strong initial spikes in the PACF.

- Seasonality: Both the ACF and PACF plots suggest seasonal components, with significant spikes at seasonal lags (e.g., 12, 24).

- ARIMA Model Identification: The patterns in the ACF and PACF plots suggest that an ARIMA model with seasonal components might be appropriate. The presence of significant autocorrelations at multiple lags suggests including both AR and MA terms, along with seasonal differencing.

#### Split the data into training and test sets

```{r}
# Create a training dataset from January 2005 to February 2019
W_sales_ts_log_train <- window(W_sales_ts_log, start = c(2005, 1), end = c(2019, 2))

# Create a test dataset from March 2019 to February 2020
W_sales_ts_log_test <- window(W_sales_ts_log, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the time series
str(W_sales_ts_log_train)
str(W_sales_ts_log_test)

# Print the time series data
print(W_sales_ts_log_train)
print(W_sales_ts_log_test)

```

#### Plot of Training and Test dataset
```{r}
# Set up the plotting area for two plots
par(mfrow = c(2, 1), cex.main = 0.9, cex.lab = 0.8, cex.axis = 0.8, lty=1, lwd = 1.8)

# Plot the training set with smaller text
plot(W_sales_ts_log_train, 
     main = "Training Set of Log Transformed Wales\nHousing Sales Volume", 
     xlab = "Time", 
     ylab = "Log Transformed Sales Volume")
grid()

# Plot the test set with smaller text
plot(W_sales_ts_log_test, 
     main = "Test Set of Log Transformed Wales\nHousing Sales Volume", 
     xlab = "Time", 
     ylab = "Log Transformed Sales Volume")
grid()

```

```{r}
# Reset plotting area to default to ensure subsequent plots are displayed one at a time
par(mfrow = c(1, 1))
```

#### Time series comparision 
```{r}

# Determine the range of the combined dataset for consistent y-axis limits
combined_range <- range(c(W_sales_ts_log_train, W_sales_ts_log_test))


# Overlay plot for comparison with thicker lines and adjusted axes
plot(W_sales_ts_log_train, main = "Time Series Comparison", ylab = "Values", xlab = "Time", lwd = 2, ylim = combined_range, xlim = c(time(W_sales_ts_log_train)[1], time(W_sales_ts_log_test)[length(W_sales_ts_log_test)]))
lines(W_sales_ts_log_test, col = "red", lwd = 2)
legend("bottomright", legend = c("Train", "Test"), col = c("black", "red"), lty = 1, lwd = 2)

```

```{r}
# Check seasonality
seasonplot(W_sales_ts_log_train, main = "Seasonal plot: W_sales_ts_log_train", col = 1, lwd = 1.5)

```
- Consistent Seasonality: The housing sales volume exhibits a clear seasonal pattern, with sales generally increasing in the first half of the year, peaking around mid-year, and then decreasing in the latter half.

- Annual Variation: While the general pattern is consistent, the magnitude of sales can vary significantly between different years.

- Implications for Modeling: The strong seasonal pattern suggests that any time series model for forecasting should account for seasonality. A seasonal ARIMA (SARIMA) model or other models that include seasonal components would be appropriate.

```{r}
# Generate a seasonal subseries plot for the log-transformed UK sales training data
monthplot(W_sales_ts_log_train,lwd = 1.5 )
```
The seasonal plot of the log-transformed Wales housing sales volume clearly illustrates strong and consistent seasonal patterns, with predictable increases during the summer months and decreases during the winter. The log transformation stabilizes variance, making these patterns more evident. Despite the overall consistency, there is variability in sales volume for each month across different years. This strong seasonality suggests that any forecasting model should account for these seasonal effects. Therefore, employing a seasonal ARIMA (SARIMA) model or similar approaches will likely enhance forecasting accuracy by effectively capturing these regular seasonal fluctuations.

```{r}
# Generate a combined plot displaying the time series, ACF, and PACF of the log-transformed Scotland sales training data

ggtsdisplay(W_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed\nWales Housing Sales training dataset")

```

- Stationarity: The time series appears to be non-stationary, as indicated by the significant autocorrelations in the ACF and the strong initial spikes in the PACF.

- Seasonality: Both the ACF and PACF plots suggest seasonal components, with significant spikes at seasonal lags (e.g., 12, 24).

- ARIMA Model Identification: The patterns in the ACF and PACF plots suggest that an ARIMA model with seasonal components might be appropriate. The presence of significant autocorrelations at multiple lags suggests including both AR and MA terms, along with seasonal differencing.

#### Perform Augmented Dickey-Fuller (ADF) test
```{r}
tseries::adf.test(W_sales_ts_log_train)

```
The test statistic of -2.5923 is compared against critical values to determine stationarity.

The p-value of 0.329 is greater than the common significance levels (e.g., 0.01, 0.05, 0.10), indicating that we fail to reject the null hypothesis of non-stationarity.
Therefore, based on this test, the log-transformed UK sales training data is not stationary.

```{r}
# ADF test for three different model types
adf.test(W_sales_ts_log_train)
```

- No Drift, No Trend: The series is non-stationary without drift and trend.
- With Drift, No Trend: The series is stationary with drift for lag orders 0 and 1.
- With Drift and Trend: The series is stationary with drift and trend for lag orders 0 and 1.

#### KPSS test
```{r}

# Perform KPSS test on the training dataset
W_sales_ts_log_train%>% kpss.test()
```
- No Drift, No Trend: The test statistic (0.0662) and p-value (0.1) suggest that the series is stationary when no drift and trend are considered.

- With Drift, No Trend: The test statistic (0.301) and p-value (0.1) suggest that the series is stationary with drift but no trend.

- With Drift and Trend: The test statistic (0.294) and p-value (0.01) suggest that the series is non-stationary when both drift and trend are considered.

--> Apply differencing to remove the trend and achieve stationarity.

```{r}
#Calculate the number of observations (T)
T_W_train <- length(W_sales_ts_log_train)
print(T_W_train)

# Apply Schwert's Criterion
use_lag_W_train <- floor(12 * (T_W_train / 100)^(1/4))
print(use_lag_W_train)

# Perform KPSS Test with the Chosen Lag
W_sales_ts_log_train%>% ur.kpss(use.lag = use_lag_W_train) %>% summary()

```
Since the test statistic (0.2378) is much lower than the critical values, we fail to reject the null hypothesis of stationarity. Therefore, the log-transformed Wales housing sales training dataset can be considered stationary under the conditions tested (with a constant but no trend

```{r}

# Determine the Number of Seasonal Differencing (D):
D_W_train <- nsdiffs(W_sales_ts_log_train)
print(D_W_train)

#Determine the Number of Normal Differencing (d):
d_W_train <- ndiffs(W_sales_ts_log_train)
print(d_W_train)

```
--> Should do differencing

#### Seasonal Differencing 

```{r}
d_W_sales_ts_log_train <- diff (W_sales_ts_log_train, lag =12, differences=1)

ggtsdisplay(d_W_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed\nWales Housing Sales training dataset (D=1)")
```

#### Test again

##### Perform Augmented Dickey-Fuller (ADF) test - Unit root tests
```{r}
tseries::adf.test(d_W_sales_ts_log_train)
```

- p-value > 0.05: The p-value of 0.09223 is greater than the conventional significance level of 0.05, which means we fail to reject the null hypothesis of non-stationarity at the 5% level.

- Near-Threshold Significance: The p-value is relatively close to 0.05, suggesting that the series may be near the threshold of stationarity, but we do not have enough evidence to conclusively say it is stationary at the 5% significance level.

```{r}
# ADF test with different types
adf.test(d_W_sales_ts_log_train)
```
No Drift, No Trend: The differenced log-transformed series is stationary, as indicated by significant p-values across all lags.

With Drift, No Trend: The series is stationary only for lag 0, but non-stationary for lags 1 through 4.

With Drift and Trend: The series is stationary for lag 0 but non-stationary for lags 1 through 4.

--> Still need apply normal differencing to remove trend

##### KPSS test
```{r}

# Perform KPSS test on the housing sales volume
d_W_sales_ts_log_train%>% kpss.test()
```

- No Drift, No Trend: The test statistic (0.277) and p-value (0.1) suggest that the series is stationary when no drift and trend are considered.

- With Drift, No Trend: The test statistic (0.235) and p-value (0.1) suggest that the series is stationary with drift but no trend.

- With Drift and Trend: The test statistic (0.1) and p-value (0.1) suggest that the series is stationary with drift and trend.

--> Fail to Reject Null Hypothesis: For all test types (no drift, with drift, with drift and trend), the p-value of 0.1 suggests that we fail to reject the null hypothesis of stationarity. This implies that the differenced log-transformed series is stationary.


```{r}
#Calculate the number of observations (T)
d_T_W_train <- length(d_W_sales_ts_log_train)
print(d_T_W_train)

# Apply Schwert's Criterion
d_use_lag_W_train <- floor(12 * (d_T_W_train / 100)^(1/4))
print(d_use_lag_W_train)

# Perform KPSS Test with the Chosen Lag
d_W_sales_ts_log_train%>% ur.kpss(use.lag = d_use_lag_W_train ) %>% summary()

```

Since the test statistic (0.1508) is significantly lower than the critical values at all conventional significance levels, we fail to reject the null hypothesis of stationarity. Therefore, the differenced log-transformed Wales housing sales training dataset is considered stationary under the conditions tested (with a constant but no trend).

```{r}
#Determine the Number of Normal Differencing (d):
d_W_train <- ndiffs(d_W_sales_ts_log_train)
print(d_W_train)
```

--> Need to do 1 Normal differencing

#### Normal differencing

```{r}
dd_W_sales_ts_log_train <- diff (d_W_sales_ts_log_train, lag =1, differences=1)

ggtsdisplay(dd_W_sales_ts_log_train, lag.max = 40, main = "Time Series, ACF and PACF of Log Transformed\nWales Housing Sales training dataset\n(d=1, D=1)")

```
- Stationarity: The differenced series appears stationary, as indicated by the time series plot fluctuating around a mean close to zero.

- Seasonality: Both the ACF and PACF plots suggest the presence of seasonality, with significant spikes at seasonal lags (e.g., lag 12).

- ARIMA Model Identification: The patterns in the ACF and PACF plots suggest that an ARIMA model with seasonal components might be appropriate. The presence of significant autocorrelations at multiple lags suggests including both AR and MA terms, along with seasonal differencing.

#### Test again

##### Perform Augmented Dickey-Fuller (ADF) test
```{r}
tseries::adf.test(na.omit(dd_W_sales_ts_log_train))
```

Reject Null Hypothesis: The p-value of 0.04127 is less than the conventional significance level of 0.05, which means we reject the null hypothesis of non-stationarity. This suggests that the twice-differenced log-transformed series is stationary.

```{r}
# ADF test with different types
adf.test(dd_W_sales_ts_log_train)
```
Reject Null Hypothesis: The p-values being 0.01 or less for all lag orders and model types indicate that we reject the null hypothesis of non-stationarity. This suggests that the twice-differenced log-transformed series is stationary.


##### KPSS test
```{r}
# Perform KPSS test on the housing sales volume
dd_W_sales_ts_log_train%>% kpss.test()
```

- No Drift, No Trend: The test statistic (0.117) and p-value (0.1) suggest that the series is stationary when no drift and trend are considered.

- With Drift, No Trend: The test statistic (0.077) and p-value (0.1) suggest that the series is stationary with drift but no trend.

- With Drift and Trend: The test statistic (0.0668) and p-value (0.1) suggest that the series is stationary with drift and trend.

Fail to Reject Null Hypothesis: For all test types (no drift, with drift, and with drift and trend), the p-value of 0.1 suggests that we fail to reject the null hypothesis of stationarity. This implies that the twice-differenced log-transformed series is stationary.

```{r}
#Calculate the number of observations (T)
dd_T_W_train <- length(dd_W_sales_ts_log_train)
print(dd_T_W_train)

# Apply Schwert's Criterion
dd_use_lag_W_train <- floor(12 * (dd_T_W_train / 100)^(1/4))
print(dd_use_lag_W_train)

# Perform KPSS Test with the Chosen Lag
dd_W_sales_ts_log_train%>% ur.kpss(use.lag = dd_use_lag_W_train ) %>% summary()

```

Fail to Reject Null Hypothesis: Since the test statistic (0.0554) is significantly lower than the critical values at all conventional significance levels, we fail to reject the null hypothesis of stationarity. Therefore, the twice-differenced log-transformed Wales housing sales training dataset is considered stationary under the conditions tested (with a constant but no trend).

### 4.5.2. SARIMA model selection

```{r}
# Fit a SARIMA model using auto.arima with specified parameters for Automatic Model Selection
W_sarima_1 <- auto.arima(
  W_sales_ts_log_train,  # The log-transformed training dataset for UK housing sales volume
  max.p = 4,              # Maximum order of the non-seasonal autoregressive part (AR)
  max.q = 4,              # Maximum order of the non-seasonal moving average part (MA)
  max.P = 4,              # Maximum order of the seasonal autoregressive part (SAR)
  max.Q = 4,              # Maximum order of the seasonal moving average part (SMA)
  max.d = 2,              # Maximum number of non-seasonal differences
  max.D = 2,              # Maximum number of seasonal differences
  start.p = 0,            # Starting value of p in the stepwise procedure
  start.q = 0,            # Starting value of q in the stepwise procedure
  start.P = 0,            # Starting value of P in the stepwise procedure
  start.Q = 0,            # Starting value of Q in the stepwise procedure
  stationary = FALSE,     # If TRUE, restricts search to stationary models
  seasonal = TRUE,        # If FALSE, restricts search to non-seasonal models
  ic = c("aicc", "aic", "bic"),  # Information criteria to be used in model selection (AICc, AIC, BIC)
  stepwise = FALSE,       # If TRUE, will do stepwise selection (faster); here set to FALSE for exhaustive search
  trace = TRUE,           # If TRUE, the list of ARIMA models considered will be reported
  approximation = FALSE,  # If TRUE, estimation is via conditional sums of squares and approximated information criteria; here set to FALSE for exact MLE
  test = c("kpss", "adf", "pp")  # Unit root tests to be used for non-seasonal differencing
)

```

--> Best model: ARIMA(1,1,2)(0,1,1)[12]  

```{r}
# Print summary of the model
summary(W_sarima_1)
```

#### Calculate Residual Sums of Squares and AICc value
```{r}

# Number of observations in the training set
n_train <- length(W_sales_ts_log_train)

# Calculate metrics for each model

cat("SARIMA Model Metrics:\n")
calculate_metrics(W_sarima_1, n_train)
```

### 4.5.3. Residuals Diagnostics
##### Draw Residual Plots

```{r}
# Extract residuals and fitted values
residuals <- as.numeric(residuals(W_sarima_1))  # Convert to numeric
fitted_values <- as.numeric(fitted(W_sarima_1)) # Convert to numeric
observations <- seq_along(residuals)

# Create a data frame for plotting
data <- data.frame(Residuals = residuals, Fitted = fitted_values, Observation = observations)

# 1. Normal Probability Plot
p1 <- ggplot(data, aes(sample = Residuals)) +
  stat_qq() +
  stat_qq_line() +
  ggtitle("Normal Probability Plot") +
  theme_minimal()

# 2. Residuals vs Fitted Values
p2 <- ggplot(data, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  ggtitle("Residuals vs Fitted Values") +
  theme_minimal()

# 3. Histogram of Residuals
p3 <- ggplot(data, aes(x = Residuals)) +
  geom_histogram(binwidth = 0.1, fill = "#008FC8", color = "black", alpha = 0.7) +
  ggtitle("Histogram of Residuals") +
  theme_minimal()

# 4. Residuals vs Observation Order
p4 <- ggplot(data, aes(x = Observation, y = Residuals)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  ggtitle("Residuals vs Observation Order") +
  theme_minimal()

# Arrange the plots in a grid with a main title
title <- grid::textGrob("Residual Plots for ARIMA(1,1,2)(0,1,1)[12]", gp = grid::gpar(fontsize = 16, fontface = "bold"))

# Combine the plots with the title
gridExtra::grid.arrange(
  gridExtra::arrangeGrob(p1, p2, p3, p4, ncol = 2, top = title)
)

```

- Normality: The normal probability plot and the histogram of residuals suggest that the residuals are approximately normally distributed, with some minor deviations at the tails.

- Homoscedasticity: The residuals vs fitted values plot indicates that the residuals have constant variance, as they are randomly scattered around zero without any patterns.

- No Autocorrelation: The residuals vs observation order plot shows no evidence of autocorrelation, suggesting that the model has adequately captured the dependencies in the data.

#### Create ACF and PACF

```{r}

# Extract residuals
residuals <- as.numeric(residuals(W_sarima_1))  # Convert to numeric

# ACF plot
acf_data <- acf(residuals, plot = FALSE)
acf_df <- data.frame(lag = acf_data$lag, acf = acf_data$acf)

p_acf <- ggplot(acf_df, aes(x = lag, y = acf)) +
  geom_bar(stat = "identity", position = "dodge", fill = "#008FC8", color = "black") +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  geom_hline(yintercept = -qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  ggtitle("ACF of Residuals for ARIMA(1,1,2)(0,1,1)[12]") +
  theme_minimal()

# PACF plot
pacf_data <- pacf(residuals, plot = FALSE)
pacf_df <- data.frame(lag = pacf_data$lag, pacf = pacf_data$acf)

p_pacf <- ggplot(pacf_df, aes(x = lag, y = pacf)) +
  geom_bar(stat = "identity", position = "dodge", fill = "#008FC8", color = "black") +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept = qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  geom_hline(yintercept = -qnorm((1 + 0.95) / 2) / sqrt(length(residuals)), color = "red", linetype = "dashed") +
  ggtitle("PACF of Residuals for ARIMA(1,1,2)(0,1,1)[12]") +
  theme_minimal()

# Combine the plots
gridExtra::grid.arrange(p_acf, p_pacf, ncol = 1)

```

- High First Lag in ACF: The high autocorrelation at lag 1 in the ACF plot is concerning and indicates that the residuals are not behaving like white noise. This suggests that there might be some structure in the data that the model has not captured.

- General Pattern: Aside from the first lag, the residuals do not show significant autocorrelations or partial autocorrelations at other lags, which is a good sign.

#### Check residual
```{r}
checkresiduals(W_sarima_1, main = "Residuals of ARIMA(1,1,2)(0,1,1)[12]")
```

- Stationarity and Uncorrelated Residuals: The time series plot of residuals fluctuating around zero and the ACF plot showing no significant autocorrelations suggest that the residuals are stationary and uncorrelated.

- Normality of Residuals: The histogram of residuals indicates that the residuals are approximately normally distributed.

- Outliers: The noticeable spikes in the time series plot of residuals, particularly around 2015, suggest the presence of outliers or structural changes.

- Ljung-Box test: Reject Null Hypothesis: The p-value of 0.0276 is less than the conventional significance level of 0.05, which means we reject the null hypothesis of no autocorrelation. This suggests that there is significant autocorrelation in the residuals of the model at the 5% significance level.

#### Ljung-Box test
```{r}
# Define the lags to test
lags <- c(12, 24, 36, 48)

# Perform Ljung-Box test for each model
cat("Ljung-Box Test Results:")
perform_ljung_box_test(W_sarima_1, lags)

```

No Significant Autocorrelation: At the 5% significance level, we fail to reject the null hypothesis of no autocorrelation for all lags (12, 24, 36, and 48). This indicates that the residuals do not exhibit significant autocorrelation at these lags, suggesting that the ARIMA(1,1,2)(0,1,1)[12] model is adequately capturing the dependencies in the data.

Weak Evidence at 10% Level: There is some weak evidence of autocorrelation at lags 24 and 36 at the 10% significance level, which might warrant further investigation or slight model adjustments if higher precision is required.

#### BJM test
```{r}
bjm_test(W_sarima_1)
```

- Model Fit: The ARIMA(1,1,2)(0,1,1)[12] model seems to be well-specified, with significant coefficients and no significant autocorrelation in the residuals.

- Forecasting Validity: The lack of autocorrelation in the residuals and the significance of the model parameters suggest that the model is suitable for making reliable forecasts.

#### ADF test and KPSS test for residuals 
```{r}
# ADF test
tseries::adf.test(W_sarima_1$residuals)

# KPSS test
W_sarima_1$residuals%>% ur.kpss(use.lag = (floor(12* (length(W_sales_ts_log_train) /100)^(1/4)))) %>% summary()
```

ADF test
- Reject the Null Hypothesis: Since the p-value is 0.01, which is equal to the threshold of 0.01, we reject the null hypothesis.

- Stationary Residuals: The result indicates that the residuals from the ARIMA(0,1,0)(1,0,4)[12] model are stationary.

KPSS test:
- Fail to Reject the Null Hypothesis: Since the test statistic (0.1506) is less than the critical values for all significance levels, we fail to reject the null hypothesis.

- Stationary Residuals: The result suggests that the residuals are stationary.

Conclusion: 
Both the ADF and KPSS tests indicate that the residuals from the ARIMA(0,1,0)(1,0,4)[12] model are stationary. This is a good indication that the model is well-specified and that there are no remaining patterns in the residuals that need to be modeled.

#### Q-Q plot
```{r}
# Plot the residuals
plot(W_sarima_1$residuals, main = "Residuals of SARIMA Model")

# Q-Q plot
qqnorm(W_sarima_1$residuals)
qqline(W_sarima_1$residuals, col = "red")

```



#### Test for Heteroscedasticity

```{r}
# Perform ARCH test for each model
cat("ARCH Test Results:")
perform_arch_test(W_sarima_1, lags)

```

- Lag 12 and Lag 24: There is strong evidence of heteroscedasticity at these lags, indicating that the residual variance is not constant over time. This suggests the presence of ARCH effects.

- Lag 36: The p-value is slightly above 0.05, indicating no strong evidence of heteroscedasticity, but the proximity to the significance level suggests that there might still be some concerns.

- Lag 48: There is no significant evidence of heteroscedasticity at this lag


#### Check parameter estimation
```{r}
# Define your SARIMA model parameters
order <- c(1, 1, 2)
seasonal_order <- c(0, 1, 1)
period <- 12

# Assuming `S_sales_ts_log_train` is your time series data
# Fit the model with custom iteration capture
result <- capture_iterations(W_sales_ts_log_train, order, seasonal_order, period)
fit <- result$fit
iterations_df <- result$iterations

print(iterations_df)

```


### 4.5.4. Forecast with SARIMA model

```{r}
# Forecast result

W_sarima_result_1 <- forecast::forecast(W_sarima_1, h = 12)

# Plot the forecast result 
plot(W_sarima_result_1, main = paste("Fitted from",W_sarima_result_1$method), xlab = "Time", ylab = "Values") 
lines(W_sarima_result_1$fitted, col = "red",lty = "dashed", lwd = 1) 
legend("topleft", legend = c("OS Visit", W_sarima_result_1$method), col = c("black", "red"), lty = 1:2, cex = 0.8)

```

```{r}
plot_fore(W_sales_ts_log_test,W_sarima_result_1)

```

```{r}
plot_fore_exp(W_sales_ts_log_test,W_sarima_result_1)
```

```{r}
# Calculate Mean Absolute Percentage Error (MAPE)
mape_log <- round(MLmetrics::MAPE(W_sarima_result_1$mean, W_sales_ts_log_test) * 100, 2)
mape_exp <- round(MLmetrics::MAPE(exp(W_sarima_result_1$mean), exp(W_sales_ts_log_test)) * 100, 2)

# Calculate Mean Absolute Error (MAE)
mae_log <- round(MLmetrics::MAE(W_sarima_result_1$mean, W_sales_ts_log_test), 2)
mae_exp <- round(MLmetrics::MAE(exp(W_sarima_result_1$mean), exp(W_sales_ts_log_test)), 2)

# Convert MAE to percentage of the mean actual values
mae_log_percentage <- round((mae_log / mean(W_sales_ts_log_test)) * 100, 2)
mae_exp_percentage <- round((mae_exp / mean(exp(W_sales_ts_log_test))) * 100, 2)

# Manually calculate Mean Percentage Error (MPE)
mpe_log <- round(mean((W_sarima_result_1$mean - W_sales_ts_log_test) /W_sales_ts_log_test) * 100, 2)
mpe_exp <- round(mean((exp(W_sarima_result_1$mean) - exp(W_sales_ts_log_test)) / exp(W_sales_ts_log_test)) * 100, 2)

# Calculate Root Mean Squared Error (RMSE)
rmse_log <- round(MLmetrics::RMSE(W_sarima_result_1$mean, W_sales_ts_log_test), 2)
rmse_exp <- round(MLmetrics::RMSE(exp(W_sarima_result_1$mean), exp(W_sales_ts_log_test)), 2)

# Print the results
cat("Log-Transformed Data:\n")
cat("MAPE:", mape_log, "%\n")
cat("MAE:", mae_log, "\n")
cat("MAE (Percentage):", mae_log_percentage, "%\n")
cat("MPE:", mpe_log, "%\n")
cat("RMSE:", rmse_log, "\n")

cat("\nBack-Transformed Data (Exponential):\n")
cat("MAPE:", mape_exp, "%\n")
cat("MAE:", mae_exp, "\n")
cat("MAE (Percentage):", mae_exp_percentage, "%\n")
cat("MPE:", mpe_exp, "%\n")
cat("RMSE:", rmse_exp, "\n")
```

```{r}
# Save result
#sarima_W_forecast <- cbind(W_sarima_result_1$mean,W_sarima_result_1$upper[, "95%"],W_sarima_result_1$lower[, "95%"])

sarima_W_forecast <- cbind(exp(W_sarima_result_1$mean),exp(W_sarima_result_1$upper[, "95%"]), exp(W_sarima_result_1$lower[, "95%"]))
```

# VECM model
## 4.6. VECM for UK series
### Correlation matrix
```{r}
print(colnames(UK_data))

UK_independent_vars <- UK_data[, c("UK_sale_vol", "UK_REA", "UK_RPL", "UK_HF", "UK_HD")]

```


### 4.6.1. Data preparation for VECM model

```{r}
# Convert data into Time Series (frequency = 12 for monthly data)
UK_sales_ts <- ts(UK_data$UK_sale_vol, frequency = 12, start = c(2005, 1))

UK_REA_ts <- ts(UK_data$UK_REA, frequency = 12, start = c(2005, 1))

UK_RPL_ts <- ts(UK_data$UK_RPL, frequency = 12, start = c(2005, 1))

UK_HF_ts <- ts(UK_data$UK_HF, frequency = 12, start = c(2005, 1))

UK_HD_ts <- ts(UK_data$UK_HD, frequency = 12, start = c(2005, 1))

```

### Plot all the time series + ADF/KPSS test

### 1. UK_sales_ts
```{r}
ggtsdisplay(UK_sales_ts, lag.max = 40, main = "Time Series, ACF and PACF of UK_sales_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(UK_sales_ts) 

adf.test(UK_sales_ts)

# KPSS test

UK_sales_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_UK_sales_ts <- floor(12 * (length(UK_sales_ts) / 100)^(1/4))
print(use_lag_UK_sales_ts)

# Perform KPSS Test with the Chosen Lag
UK_sales_ts%>% ur.kpss(use.lag = use_lag_UK_sales_ts) %>% summary()

```
Conclusion: The UK_sales_ts series exhibits mixed stationarity properties:

- Non-stationary overall according to the ADF test.
- Stationary with drift according to the KPSS test with Type 2.
- Non-stationary in other configurations according to the KPSS test.
--> Non-stationary

### 2. UK_REA_ts
```{r}

ggtsdisplay(UK_REA_ts, lag.max = 40, main = "Time Series, ACF and PACF of UK_REA_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(UK_REA_ts) 

adf.test(UK_REA_ts)

# KPSS test

UK_REA_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_UK_REA_ts <- floor(12 * (length(UK_REA_ts) / 100)^(1/4))
print(use_lag_UK_REA_ts)

# Perform KPSS Test with the Chosen Lag
UK_REA_ts%>% ur.kpss(use.lag = use_lag_UK_REA_ts) %>% summary()

```

ADF Test: Indicates that the UK_REA_ts series is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
Type 1: The series is stationary.
Type 2: The series is borderline non-stationary with drift.
Type 3: The series is non-stationary with drift and trend.

KPSS Test (Schwert's Criterion): Indicates that the series is non-stationary.

--> Non-stationary


### 3. UK_RPL_ts
```{r}

ggtsdisplay(UK_RPL_ts, lag.max = 40, main = "Time Series, ACF and PACF of UK_RPL_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(UK_RPL_ts) 

adf.test(UK_RPL_ts)

# KPSS test

UK_RPL_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_UK_RPL_ts <- floor(12 * (length(UK_RPL_ts) / 100)^(1/4))
print(use_lag_UK_RPL_ts)

# Perform KPSS Test with the Chosen Lag
UK_RPL_ts%>% ur.kpss(use.lag = use_lag_UK_RPL_ts) %>% summary()

```

ADF Test: Indicates that the UK_RPL_ts series is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
- Type 1: The series is stationary.
- Type 2 and Type 3: The series is non-stationary with drift and trend.

KPSS Test (Schwert's Criterion): Indicates mixed results:

At the 10% and 5% significance levels, the series is non-stationary.

At the 2.5% and 1% significance levels, the series is stationary.

--> Non-stationary

### 4. UK_HF_ts
```{r}

ggtsdisplay(UK_HF_ts, lag.max = 40, main = "Time Series, ACF and PACF of UK_HF_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(UK_HF_ts) 

adf.test(UK_HF_ts)

# KPSS test

UK_HF_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_UK_HF_ts <- floor(12 * (length(UK_HF_ts) / 100)^(1/4))
print(use_lag_UK_HF_ts)

# Perform KPSS Test with the Chosen Lag
UK_HF_ts%>% ur.kpss(use.lag = use_lag_UK_HF_ts) %>% summary()

```
The ADF test suggests that the series UK_HF_ts is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
- Type 1: The series is stationary.
- Type 2 and Type 3: The series is non-stationary with drift and trend.
The initial KPSS test suggests stationarity in some configurations but non-stationarity with drift and trend.

KPSS Test (Schwert's Criterion): Indicates that the series is non-stationary.

--> non-stationary.

### Split train and test set for VECM model

### Training data from Jan 2005 to Feb 2020

#### 1. UK_sales_ts
```{r}

UK_sales_ts_train <- window(UK_sales_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2020 onwards
UK_sales_ts_test <- window(UK_sales_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(UK_sales_ts_train)
str(UK_sales_ts_test)

# Print the time series data
print(UK_sales_ts_train)
print(UK_sales_ts_test)

```

#### 2. UK_REA_ts
```{r}

UK_REA_ts_train <- window(UK_REA_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2020 onwards
UK_REA_ts_test <- window(UK_REA_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(UK_REA_ts_train)
str(UK_REA_ts_test)

# Print the time series data
print(UK_REA_ts_train)
print(UK_REA_ts_test)

```

#### 3. UK_RPL_ts
```{r}

UK_RPL_ts_train <- window(UK_RPL_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2020 onwards
UK_RPL_ts_test <- window(UK_RPL_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(UK_RPL_ts_train)
str(UK_RPL_ts_test)

# Print the time series data
print(UK_RPL_ts_train)
print(UK_RPL_ts_test)

```

#### 4. UK_HF_ts
```{r}

UK_HF_ts_train <- window(UK_HF_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2020 onwards
UK_HF_ts_test <- window(UK_HF_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(UK_HF_ts_train)
str(UK_HF_ts_test)

# Print the time series data
print(UK_HF_ts_train)
print(UK_HF_ts_test)

```


#### 5. ts_UK_sii

```{r}

ts_UK_sii_train <- window(ts_UK_sii, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2020 onwards
ts_UK_sii_test <- window(ts_UK_sii, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(ts_UK_sii_train)
str(ts_UK_sii_test)

# Print the time series data
print(ts_UK_sii_train)
print(ts_UK_sii_test)

```

### Define period

```{r}
UK_frequency <- frequency (UK_sales_ts_train)
UK_start <- start (UK_sales_ts_train)
UK_end <- end (UK_sales_ts_train)
UK_start_forecast <- c(UK_end[1],UK_end[2] + 1)

print (UK_frequency)
print (UK_start)
print (UK_end)
print (UK_start_forecast)
```


### 4.6.2. Model building
#### Create VECM input

```{r}
# Model 1: Use search subcategories
UK_vecm_in_1 <- cbind (UK_REA_ts_train, UK_RPL_ts_train, UK_HF_ts_train, UK_sales_ts_train)

# Model 2: Use composite search terms/queries
UK_vecm_in_2 <- cbind (ts_UK_sii_train, UK_sales_ts_train)

```

#### VECM

```{r}
# Select lags based in differenced data
(UK_vecm_lagselect_1 <- VARselect (UK_vecm_in_1, lag.max=12, type = "trend" ))
(UK_vecm_lagselect_2 <- VARselect (UK_vecm_in_2, lag.max=12, type = "trend" ))

```

#### Choose lags
```{r}
(UK_vecm_max_lag_1 <-UK_vecm_lagselect_1$selection[1])
(UK_vecm_max_lag_2 <-UK_vecm_lagselect_2$selection[1])
```

#### Apply Johansen's Cointegration Test

#### 1. Model 1
```{r}
# Co-integration test

UK_johansen_test_1 <- ca.jo(UK_vecm_in_1, type = "trace", ecdet = "trend", K = UK_vecm_max_lag_1, spec = "transitory", season = 12)

summary(UK_johansen_test_1)
```

From r=0 to r <=2: The test statistic (46.99) is greater than the 5% critical value (42.44), so we reject the null hypothesis of at most six co-integrating vectors (r  6).

Test r <=3:The test statistic (15.80) is less than the 5% critical value (25.32), so we do not reject the null hypothesis of at most seven co-integrating vectors (r  3).

Therefore, there are two cointegration relationships among the time series at the 5% significance level. This indicates that the series are cointegrated and share long-term equilibrium relationships.

#### 2. Model 2
```{r}
# Co-integration test

UK_johansen_test_2 <- ca.jo(UK_vecm_in_2, type = "trace", ecdet = "trend", K = UK_vecm_max_lag_2, spec = "transitory", season = 12)

summary(UK_johansen_test_2)
```
Based on the Johansen cointegration test results, we can conclude the following:

- We reject the null hypothesis of no cointegration relationships, indicating there is at least one cointegration relationship.

- We fail to reject the null hypothesis of at most one cointegration relationship, indicating that there is likely only one cointegration relationship among the variables.

--> This suggests there is 1 cointegrating vector.

#### Fit VECM

##### Model 1
```{r}
# Fit the VECM model
UK_vecm_1 <- VECM (UK_vecm_in_1, r=2, lag= UK_vecm_max_lag_1-1, estim= "ML", include ="trend")
options(max.print = 10000) # Increase this number as needed

summary (UK_vecm_1)
```

##### Model 2

```{r}

UK_vecm_2 <- VECM (UK_vecm_in_2, r=1, lag= UK_vecm_max_lag_2, estim= "ML", include ="trend")
options(max.print = 10000) # Increase this number as needed
summary (UK_vecm_2)

```
### 4.6.3. Residuals Diagnostics

#### Model 1: Search sub-categories

##### a. UK_REA_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(UK_vecm_1)[,1], main = "Residuals of UK_REA_ts_train")
```

- Good Model Fit: The residuals are centered around zero and appear to be randomly distributed, indicating a good fit.

- No Significant Autocorrelation: Both the ACF and PACF plots show that most autocorrelations are within the confidence bounds, indicating that the residuals are approximately white noise. This suggests that the model has successfully captured the time series' dependencies.

- Further Checks: Despite the overall positive signs, it's important to check for any remaining patterns or outliers in the residuals, as well as to consider additional diagnostic tests (e.g., Ljung-Box test) to confirm that the residuals are indeed white noise.

```{r}
checkresiduals(residuals(UK_vecm_1)[,1])
```
Ljung-Box test: The p-value is 0.7571, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis.This means there is no significant autocorrelation in the residuals at the 5% significance level.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(UK_vecm_1)[,1])
```

In your case, the p-value is 0.7831, which is much greater than 0.05. Therefore, you fail to reject the null hypothesis. This result indicates that there is no significant evidence to suggest that the residuals of UK_vecm_1 are not normally distributed.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(UK_vecm_1)[,1], main="Q-Q Plot of Residuals")
qqline(residuals(UK_vecm_1)[,1], col = "red")
grid()
```
The Q-Q plot for UK_REA_ts_train residuals shows that the residuals are approximately normally distributed with some minor deviations at the tails. 

###### ADF test
```{r}

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(UK_vecm_1)[,1]) 

adf.test(residuals(UK_vecm_1)[,1])

```
In all three types (no drift no trend, with drift no trend, and with drift and trend), the p-values for the ADF test are less than or equal to 0.01. This indicates that we reject the null hypothesis of a unit root at the 1% significance level for all lags considered.
The negative values of the ADF statistics (which are all significantly lower than the critical values typically used in ADF tests) also support the rejection of the null hypothesis.

###### KPSS test
```{r}
# KPSS test

residuals(UK_vecm_1)[,1]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(UK_vecm_1)[,1]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(UK_vecm_1)[,1]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

Initial KPSS Test: For all types (no drift no trend, with drift no trend, with drift and trend), the p-values are 0.1, which is greater than the typical significance levels (0.01, 0.05). This means we fail to reject the null hypothesis of stationarity. In other words, the residuals do not show significant evidence of non-stationarity based on these tests.

KPSS Test with Schwert's Criterion:

The test statistic is 0.1226.
The critical value at the 10% significance level is 0.347. Since 0.1226 < 0.347, we fail to reject the null hypothesis of stationarity.

--> The KPSS test results, including the one performed using Schwert's criterion, consistently indicate that the residuals of UK_vecm_1 are stationary. 
###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(UK_vecm_1)[, 1]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- UK_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(UK_vecm_1)[,1], lags = 12)
print(arch_test)


```

ARCH test
The result of the ARCH LM test indicates that the p-value is 0.579, which is much greater than 0.05. Therefore, you fail to reject the null hypothesis that there are no ARCH effects in the residuals of UK_vecm_1. This suggests that the residuals do not exhibit time-varying volatility, and they are homoscedastic.

Breusch-Pagan test 
The result of the Breusch-Pagan test indicates that the p-value is 0.2048, which is greater than 0.05. Therefore, you fail to reject the null hypothesis that the variance of the residuals is constant. This suggests that the residuals of your VECM model do not exhibit heteroscedasticity, supporting the assumption of homoscedasticity in your model.

##### b. UK_RPL_ts_train 

```{r}
# Residual of SII
ggtsdisplay(residuals(UK_vecm_1)[,2], main = "Residuals of UK_RPL_ts_train")
```
Residuals Time Series Plot: The residuals are centered around zero with no visible patterns, indicating that the model has captured the main features of the data.

ACF and PACF Plots: Both plots show that most lags are within the confidence bands, suggesting that the residuals are mostly uncorrelated and can be considered white noise.

```{r}

checkresiduals(residuals(UK_vecm_1)[,2])
```
- The p-value is 0.1997, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.

- Residuals Time Series Plot: The residuals are centered around zero with no visible patterns, indicating that the model has captured the main features of the data.

- ACF Plot: The residuals are mostly uncorrelated, with only a few lags showing significant autocorrelation, suggesting that the residuals are largely white noise.

- Histogram with Density Plot: The residuals appear to be approximately normally distributed, with some minor deviations.


###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(UK_vecm_1)[,2])
```

In your case, the p-value is 0.009069, which is less than 0.05. Therefore, you reject the null hypothesis that the residuals of UK_vecm_1[,2] are normally distributed. This result indicates that there is significant evidence to suggest that the residuals do not follow a normal distribution.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(UK_vecm_1)[,2], main="Q-Q Plot of Residuals")
qqline(residuals(UK_vecm_1)[,2], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(UK_vecm_1)[,2]) 

adf.test(residuals(UK_vecm_1)[,2])

```

###### KPSS test
```{r}
# KPSS test

residuals(UK_vecm_1)[,2]%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(UK_vecm_1)[,2]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(UK_vecm_1)[,2]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```
The result of the KPSS test indicates that the test statistic is 0.0705, which is much lower than the critical values for all significance levels. Therefore, you fail to reject the null hypothesis that the residuals of UK_vecm_1[,2] are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis


###### Test of Heteroscedasticity check

```{r}

### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(UK_vecm_1)[, 2]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- UK_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(UK_vecm_1)[,2], lags = 12)
print(arch_test)

```
- Breusch-Pagan Test: Since the p-value is greater than 0.05, we fail to reject the null hypothesis.This means there is not enough evidence to suggest that the residuals exhibit heteroscedasticity.Therefore, the residuals can be considered to have constant variance (homoscedastic).

- ARCH Test: Since the p-value is greater than 0.05, we fail to reject the null hypothesis. This means there is not enough evidence to suggest the presence of ARCH effects in the residuals. Therefore, the residuals do not exhibit time-varying volatility and can be considered homoscedastic.


##### c. UK_HF_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(UK_vecm_1)[,3], main = "Residuals of UK_HF_ts_train")
```

The diagnostic plots suggest that the residuals from your VECM model are mostly well-behaved. There is no strong evidence of autocorrelation, and the residuals are approximately normally distributed. However, it is important to investigate the significant lags in the ACF and PACF plots to see if there might be minor improvements to the model that could further reduce any remaining autocorrelation

```{r}

checkresiduals(residuals(UK_vecm_1)[,3])
```
- Residuals Time Series Plot: The residuals are centered around zero with no visible patterns, indicating that the model has captured the main features of the data. The presence of some larger spikes indicates occasional higher volatility.

- ACF Plot: The residuals are mostly uncorrelated, with only a few significant lags showing autocorrelation, suggesting that the residuals are largely white noise. However, the significant lag at 1 indicates some remaining autocorrelation.

- Histogram with Density Plot: The residuals appear to be approximately normally distributed, with some minor deviations.

Ljung-Box test: Since the p-value (0.2519) is greater than 0.05, we fail to reject the null hypothesis that the residuals are independently distributed.This indicates that there is no significant evidence of autocorrelation in the residuals of the third component of your VECM model, suggesting that the residuals are adequately modeled as white noise.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(UK_vecm_1)[,3])
```

--> Normally distributed (p-value >0.05)

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(UK_vecm_1)[,3], main="Q-Q Plot of Residuals")
qqline(residuals(UK_vecm_1)[,3], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(UK_vecm_1)[,3]) 

adf.test(residuals(UK_vecm_1)[,3])
```
p-value  0.05: The p-value in all cases is 0.01, which is less than the typical significance level of 0.05. This means we reject the null hypothesis that the residuals have a unit root.

Negative ADF statistics: The ADF statistics are significantly negative, which further supports the rejection of the null hypothesis.

The results of the Augmented Dickey-Fuller test indicate that the residuals of the third component of your VECM model are stationary. This is supported across all types of the ADF test (no drift no trend, with drift no trend, and with drift and trend) and various lag orders. The consistent rejection of the null hypothesis with significant p-values ( 0.01) confirms that the residuals do not exhibit a unit root and are therefore stationary.

###### KPSS test
```{r}
# KPSS test
residuals(UK_vecm_1)[,3]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(UK_vecm_1)[,3]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(UK_vecm_1)[,3]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

Test statistic < Critical values: The test statistic (0.1426) is less than the critical values at all commonly used significance levels (10%, 5%, 2.5%, 1%). Therefore, we fail to reject the null hypothesis. This means there is not enough evidence to suggest that the residuals are non-stationary.

The results of the KPSS test indicate that the test statistic is 0.1426, which is much lower than the critical values for all significance levels. Thus, we fail to reject the null hypothesis that the residuals of the third component of your VECM model are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis.

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(UK_vecm_1)[, 3]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- UK_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(UK_vecm_1)[,3], lags = 12)
print(arch_test)


```
Breusch-Pagan Test: p-value > 0.05: Since the p-value is greater than 0.05, we fail to reject the null hypothesis. This means there is not enough evidence to suggest that the residuals exhibit heteroscedasticity. Therefore, the residuals can be considered to have constant variance (homoscedastic).

ARCH Test: p-value > 0.05: Since the p-value is greater than 0.05, we fail to reject the null hypothesis.This means there is not enough evidence to suggest the presence of ARCH effects in the residuals. Therefore, the residuals do not exhibit time-varying volatility and can be considered homoscedastic.

##### d. UK_sales_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(UK_vecm_1)[,4], main = "Residuals of UK_sales_ts_train")
```


```{r}
checkresiduals(residuals(UK_vecm_1)[,4])
```
- Ljung-Box test: The p-value is 0.8608, which is greater than the typical significance level of 0.05.Therefore, you do not reject the null hypothesis.This means there is no significant autocorrelation in the residuals at the 5% significance level.

- Residuals Time Series Plots: The residuals are centered around zero with no visible patterns, indicating that the model has captured the main features of the data. Occasional spikes indicate periods of higher volatility.

- ACF and PACF Plots: The residuals are mostly uncorrelated, with a few significant lags indicating some remaining structure. The overall randomness suggests that the residuals are largely white noise.

- Histogram with Density Plot (Second Set): The residuals appear approximately normally distributed, with minor deviations suggesting the presence of outliers or heavy tails.


###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(UK_vecm_1)[,4])
```

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(UK_vecm_1)[,4], main="Q-Q Plot of Residuals")
qqline(residuals(UK_vecm_1)[,4], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(UK_vecm_1)[,4]) 

adf.test(residuals(UK_vecm_1)[,4])

```

###### KPSS test
```{r}
# KPSS test
residuals(UK_vecm_1)[,4]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(UK_vecm_1)[,4]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(UK_vecm_1)[,4]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

###### Test of Heteroscedasticity check

```{r}

### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(UK_vecm_1)[, 4]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- UK_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(UK_vecm_1)[,4], lags = 12)
print(arch_test)


```

#### Model 2: Composite search terms/queries

##### a. ts_UK_sii_train

```{r}
# Residual of SII
ggtsdisplay(residuals(UK_vecm_2)[,1], main = "Residuals of ts_UK_sii_train")
```

```{r}
checkresiduals(residuals(UK_vecm_2)[,1])
```
- Ljung-Box test: The p-value is 0.7277, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis.This means there is no significant autocorrelation in the residuals at the 5% significance level.

- Residuals Time Series Plots: The residuals are centered around zero with no visible patterns, indicating that the model has captured the main features of the data. The presence of significant spikes at certain points indicates occasional higher volatility.

- ACF and PACF Plots: The residuals are mostly uncorrelated, with a few significant lags indicating some remaining structure. The overall randomness suggests that the residuals are largely white noise.

- Histogram with Density Plot (Second Set): The residuals appear approximately normally distributed, with minor deviations suggesting the presence of outliers or heavy tails.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(UK_vecm_2)[,1])
```

In your case, the p-value is 0.8523, which is much greater than 0.05. Therefore, you fail to reject the null hypothesis. This result indicates that there is no significant evidence to suggest that the residuals of UK_vecm_1 are not normally distributed.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(UK_vecm_2)[,1], main="Q-Q Plot of Residuals")
qqline(residuals(UK_vecm_2)[,1], col = "red")
grid()
```
 

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(UK_vecm_2)[,1]) 

adf.test(residuals(UK_vecm_2)[,1])
```
In all three types (no drift no trend, with drift no trend, and with drift and trend), the p-values for the ADF test are less than or equal to 0.01. This indicates that we reject the null hypothesis of a unit root at the 1% significance level for all lags considered.
The negative values of the ADF statistics (which are all significantly lower than the critical values typically used in ADF tests) also support the rejection of the null hypothesis.

###### KPSS test
```{r}
# KPSS test

residuals(UK_vecm_2)[,1]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(UK_vecm_2)[,1]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(UK_vecm_2)[,1]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

Initial KPSS Test: For all types (no drift no trend, with drift no trend, with drift and trend), the p-values are 0.1, which is greater than the typical significance levels (0.01, 0.05). This means we fail to reject the null hypothesis of stationarity. In other words, the residuals do not show significant evidence of non-stationarity based on these tests.

KPSS Test with Schwert's Criterion:

The test statistic is 0.1121.
The critical value at the 10% significance level is 0.347. Since 0.1121 < 0.347, we fail to reject the null hypothesis of stationarity.

--> The KPSS test results, including the one performed using Schwert's criterion, consistently indicate that the residuals of UK_vecm_1 are stationary. 

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(UK_vecm_2)[, 1]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- UK_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(UK_vecm_2)[,1], lags = 12)
print(arch_test)


```

ARCH test
The result of the ARCH LM test indicates that the p-value is 0.579, which is much greater than 0.05. Therefore, you fail to reject the null hypothesis that there are no ARCH effects in the residuals of UK_vecm_1. This suggests that the residuals do not exhibit time-varying volatility, and they are homoscedastic.

Breusch-Pagan test 
The result of the Breusch-Pagan test indicates that the p-value is 0.2048, which is greater than 0.05. Therefore, you fail to reject the null hypothesis that the variance of the residuals is constant. This suggests that the residuals of your VECM model do not exhibit heteroscedasticity, supporting the assumption of homoscedasticity in your model.

##### b. UK_sales_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(UK_vecm_2)[,2], main = "Residuals of UK_sales_ts_train")
```


```{r}

checkresiduals(residuals(UK_vecm_2)[,2])
```
- The p-value is 0.9981, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(UK_vecm_2)[,2])
```

In your case, the p-value is 0.000000007942, which is less than 0.05. Therefore, you reject the null hypothesis that the residuals of UK_vecm_1[,2] are normally distributed. This result indicates that there is significant evidence to suggest that the residuals do not follow a normal distribution.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(UK_vecm_2)[,2], main="Q-Q Plot of Residuals")
qqline(residuals(UK_vecm_2)[,2], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(UK_vecm_2)[,2]) 

adf.test(residuals(UK_vecm_2)[,2])

```

###### KPSS test
```{r}
# KPSS test
residuals(UK_vecm_2)[,2]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(UK_vecm_2)[,2]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(UK_vecm_2)[,2]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```
The result of the KPSS test indicates that the test statistic is 0.0387, which is much lower than the critical values for all significance levels. Therefore, you fail to reject the null hypothesis that the residuals of UK_vecm_1[,2] are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis


###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(UK_vecm_2)[, 2]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- UK_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(UK_vecm_2)[,2], lags = 12)
print(arch_test)

```


### 4.6.4. Forecast with VECM model

#### Model 1 

```{r}

UK_forecast.vecm_1 <- predict(UK_vecm_1, n.ahead = 12) # Forecast 12 months ahead

UK_ts_forecast.vecm_1 <- ts(UK_forecast.vecm_1[,"UK_sales_ts_train"], frequency = UK_frequency, start = UK_start_forecast)

print (UK_ts_forecast.vecm_1)

#Plot 

plot(UK_sales_ts_test, main = "VECM", xlab = "Time", ylab = "Values", lwd=2) 
lines(UK_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)

print(UK_sales_ts_test)
```

```{r}

plot(UK_sales_ts_pre, main = "VECM", xlab = "Time", ylab = "Values", lwd=2)
lines(UK_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)
```

#### Evaluation metrics
```{r}

# Calculate MAPE 
round(MLmetrics::MAPE(UK_ts_forecast.vecm_1,UK_sales_ts_test)*100,2)

# Calculate MAE
mae <- mean(abs(UK_ts_forecast.vecm_1 - UK_sales_ts_test))
print(paste("MAE:", round(mae, 2)))

# Calculate MPE
mpe <- mean((UK_ts_forecast.vecm_1 - UK_sales_ts_test) / UK_sales_ts_test) * 100
print(round(mpe, 2))

# Calculate MAE in percentage
mae_percentage <- (mae / mean(UK_sales_ts_test)) * 100
print(paste("MAE as a percentage:", round(mae_percentage, 2), "%"))

# Calculate RMSE
rmse <- sqrt(mean((UK_ts_forecast.vecm_1 - UK_sales_ts_test)^2))
print(paste("RMSE:", round(rmse, 2)))

```

```{r}
# Save result 
vecm_UK_forecast_model_1 <- UK_ts_forecast.vecm_1
```

#### Model 2 

```{r}

UK_forecast.vecm_2 <- predict(UK_vecm_2, n.ahead = 12) # Forecast 12 months ahead

UK_ts_forecast.vecm_2 <- ts(UK_forecast.vecm_2[,"UK_sales_ts_train"], frequency = UK_frequency, start = UK_start_forecast)

print (UK_ts_forecast.vecm_2)

#Plot 

plot(UK_sales_ts_test, main = "VECM", xlab = "Time", ylab = "Values", lwd=2) 
lines(UK_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)

print(UK_sales_ts_test)
```

```{r}

plot(UK_sales_ts_pre, main = "VECM", xlab = "Time", ylab = "Values", lwd=2)
lines(UK_ts_forecast.vecm_2, col = "red",lty = "dashed", lwd = 2)
```

#### Evaluation metrics
```{r}

# Calculate MAPE 
round(MLmetrics::MAPE(UK_ts_forecast.vecm_2,UK_sales_ts_test)*100,2)

# Calculate MAE
mae <- mean(abs(UK_ts_forecast.vecm_2 - UK_sales_ts_test))
print(paste("MAE:", round(mae, 2)))

# Calculate MAE in percentage
mae_percentage <- (mae / mean(UK_sales_ts_test)) * 100
print(paste("MAE as a percentage:", round(mae_percentage, 2), "%"))

# Calculate MPE
mpe <- mean((UK_ts_forecast.vecm_2 - UK_sales_ts_test) / UK_sales_ts_test) * 100
print(round(mpe, 2))

# Calculate RMSE
rmse <- sqrt(mean((UK_ts_forecast.vecm_2 - UK_sales_ts_test)^2))
print(paste("RMSE:", round(rmse, 2)))

```

```{r}
# Save result 
vecm_UK_forecast_model_2 <- UK_ts_forecast.vecm_2
```

## 4.7. VECM for England series
### Correlation matrix
```{r}
print(colnames(E_data))

E_independent_vars <- E_data[, c("E_sale_vol", "E_REA", "E_RPL", "E_HF", "E_HD")]

# Select only numeric columns for correlation analysis
E_data_cor <- E_independent_vars %>%
  select_if(is.numeric)

# Compute the correlation matrix
E_cor_matrix <- cor(E_data_cor, use = "complete.obs")

# Print the correlation matrix
print("Correlation Matrix:")
print(E_cor_matrix )

```

```{r}

# Visualize the correlation matrix using ggcorrplot
ggcorrplot(E_cor_matrix , 
           method = "circle", 
           type = "lower", 
           lab = TRUE, 
           title = "Correlation Matrix")

```


### VIF

```{r}

missing_summary <- sapply(E_data, function(x) sum(is.na(x)))
print("Summary of Missing Values:")
print(missing_summary)

```


```{r}

# Conduct multiple regression

E_reg_model <- lm(E_sale_vol~E_REA+E_RPL+ E_HF +E_HD , data=E_data)

# Print the result of multiple regression 
summary(E_reg_model)

# Calculate VIF for the independent variables
vif(E_reg_model)

```


### 4.7.1. Data preparation for VECM model

```{r}

# Convert data into Time Series (frequency = 12 for monthly data)
E_sales_ts <- ts(E_data$E_sale_vol, frequency = 12, start = c(2005, 1))

E_REA_ts <- ts(E_data$E_REA, frequency = 12, start = c(2005, 1))

E_RPL_ts <- ts(E_data$E_RPL, frequency = 12, start = c(2005, 1))

E_HF_ts <- ts(E_data$E_HF, frequency = 12, start = c(2005, 1))

E_HD_ts <- ts(E_data$E_HD, frequency = 12, start = c(2005, 1))

```

### Plot all the time series + ADF/KPSS test

### a. E_sales_ts
```{r}

ggtsdisplay(E_sales_ts, lag.max = 40, main = "Time Series, ACF and PACF of E_sales_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(E_sales_ts) 

adf.test(E_sales_ts)

# KPSS test

E_sales_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_E_sales_ts <- floor(12 * (length(E_sales_ts) / 100)^(1/4))
print(use_lag_E_sales_ts)

# Perform KPSS Test with the Chosen Lag
E_sales_ts%>% ur.kpss(use.lag = use_lag_E_sales_ts) %>% summary()

```
Conclusion: The UK_sales_ts series exhibits mixed stationarity properties:

- Non-stationary overall according to the ADF test.
- Stationary with drift according to the KPSS test with Type 2.
- Non-stationary in other configurations according to the KPSS test.
--> Non-stationary


### b. E_REA_ts
```{r}

ggtsdisplay(E_REA_ts, lag.max = 40, main = "Time Series, ACF and PACF of E_REA_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(E_REA_ts) 

adf.test(E_REA_ts)

# KPSS test

E_REA_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_E_REA_ts <- floor(12 * (length(E_REA_ts) / 100)^(1/4))
print(use_lag_E_REA_ts)

# Perform KPSS Test with the Chosen Lag
E_REA_ts%>% ur.kpss(use.lag = use_lag_E_REA_ts) %>% summary()

```

ADF Test: Indicates that the UK_REA_ts series is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
Type 1: The series is stationary.
Type 2: The series is borderline non-stationary with drift.
Type 3: The series is non-stationary with drift and trend.

KPSS Test (Schwert's Criterion): Indicates that the series is non-stationary.

--> Non-stationary


### c. E_RPL_ts
```{r}

ggtsdisplay(E_RPL_ts, lag.max = 40, main = "Time Series, ACF and PACF of E_RPL_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(E_RPL_ts) 

adf.test(E_RPL_ts)

# KPSS test

E_RPL_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_E_RPL_ts <- floor(12 * (length(E_RPL_ts) / 100)^(1/4))
print(use_lag_E_RPL_ts)

# Perform KPSS Test with the Chosen Lag
E_RPL_ts%>% ur.kpss(use.lag = use_lag_E_RPL_ts) %>% summary()

```

ADF Test: Indicates that the UK_RPL_ts series is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
- Type 1: The series is stationary.
- Type 2 and Type 3: The series is non-stationary with drift and trend.

KPSS Test (Schwert's Criterion): Indicates mixed results:

At the 10% and 5% significance levels, the series is non-stationary.

At the 2.5% and 1% significance levels, the series is stationary.

--> Non-stationary

### d. E_HF_ts
```{r}

ggtsdisplay(E_HF_ts, lag.max = 40, main = "Time Series, ACF and PACF of E_HF_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(E_HF_ts) 

adf.test(E_HF_ts)

# KPSS test

E_HF_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_E_HF_ts <- floor(12 * (length(E_HF_ts) / 100)^(1/4))
print(use_lag_E_HF_ts)

# Perform KPSS Test with the Chosen Lag
E_HF_ts%>% ur.kpss(use.lag = use_lag_E_HF_ts) %>% summary()

```
The ADF test suggests that the series UK_HF_ts is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
- Type 1: The series is stationary.
- Type 2 and Type 3: The series is non-stationary with drift and trend.
The initial KPSS test suggests stationarity in some configurations but non-stationarity with drift and trend.

KPSS Test (Schwert's Criterion): Indicates that the series is non-stationary.

--> non-stationary.

### e. ts_E_sii

```{r}

ggtsdisplay(E_HD_ts, lag.max = 40, main = "Time Series, ACF and PACF of E_HD_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(E_HD_ts) 

adf.test(E_HD_ts)

# KPSS test

E_HD_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_E_HD_ts <- floor(12 * (length(E_HD_ts) / 100)^(1/4))
print(use_lag_E_HD_ts)

# Perform KPSS Test with the Chosen Lag
E_HD_ts%>% ur.kpss(use.lag = use_lag_E_HD_ts) %>% summary()

```


### Split train and test set for VECM model

### Training data from Jan 2005 to Feb 2020

#### a. E_sales_ts
```{r}

# Split the E_sales_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
E_sales_ts_train <- window(E_sales_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
E_sales_ts_test <- window(E_sales_ts, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the training time series
str(E_sales_ts_train)

# Check the structure of the testing time series
str(E_sales_ts_test)

# Print the training time series data to verify the split
print(E_sales_ts_train)

# Print the testing time series data to verify the split
print(E_sales_ts_test)

```

#### b. E_REA_ts
```{r}
# Split the E_REA_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
E_REA_ts_train <- window(E_REA_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
E_REA_ts_test <- window(E_REA_ts, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the training time series
str(E_REA_ts_train)

# Check the structure of the testing time series
str(E_REA_ts_test)

# Print the training time series data to verify the split
print(E_REA_ts_train)

# Print the testing time series data to verify the split
print(E_REA_ts_test)
```

#### c. E_RPL_ts
```{r}
# Split the E_RPL_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
E_RPL_ts_train <- window(E_RPL_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
E_RPL_ts_test <- window(E_RPL_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(E_RPL_ts_train)
str(E_RPL_ts_test)

# Print the time series data
print(E_RPL_ts_train)
print(E_RPL_ts_test)

```

#### d. E_HF_ts
```{r}

# Split the E_HF_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019

E_HF_ts_train <- window(E_HF_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
E_HF_ts_test <- window(E_HF_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(E_HF_ts_train)
str(E_HF_ts_test)

# Print the time series data
print(E_HF_ts_train)
print(E_HF_ts_test)

```

#### e. ts_E_sii

```{r}
# Split the ts_E_sii time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
ts_E_sii_train <- window(ts_E_sii, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
ts_E_sii_test <- window(ts_E_sii, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(ts_E_sii_train)
str(ts_E_sii_test)

# Print the time series data
print(ts_E_sii_train)
print(ts_E_sii_test)

```

### Define period

```{r}
E_frequency <- frequency (E_sales_ts_train)
E_start <- start (E_sales_ts_train)
E_end <- end (E_sales_ts_train)
E_start_forecast <- c(E_end[1],E_end[2] + 1)

print (E_frequency)
print (E_start)
print (E_end)
print (E_start_forecast)
```

### Create VECM input

```{r}
# Model 1: Use search subcategories
E_vecm_in_1 <- cbind (E_REA_ts_train, E_RPL_ts_train, E_HF_ts_train, E_sales_ts_train)

# Model 2: Use composite search terms/queries
E_vecm_in_2 <- cbind (ts_E_sii_train,E_sales_ts_train)

```

### 4.7.2. VECM Model building

```{r}
# Select lags based in differenced data
(E_vecm_lagselect_1 <- VARselect (E_vecm_in_1, lag.max=12, type = "trend" ))
(E_vecm_lagselect_2 <- VARselect (E_vecm_in_2, lag.max=12, type = "trend" ))

```

### Choose lags
```{r}
(E_vecm_max_lag_1 <-E_vecm_lagselect_1$selection[1])

(E_vecm_max_lag_2 <-E_vecm_lagselect_2$selection[1])

```

### Apply Johansen's Cointegration Test

#### 1. Model 1
```{r}
# Co-integration test

E_johansen_test_1 <- ca.jo(E_vecm_in_1, type = "trace", ecdet = "trend", K = E_vecm_max_lag_1, spec = "transitory", season = 12)

summary(E_johansen_test_1)
```

From r=0 to r <=6: The test statistic (51.27) is greater than the 5% critical value (42.44), so we reject the null hypothesis of at most six co-integrating vectors (r  6).

Test r <=7:The test statistic (24.29) is less than the 5% critical value (25.32), so we do not reject the null hypothesis of at most seven co-integrating vectors (r  7).

--> Based on the test statistics and critical values, we can conclude that there are 7 co-integrating relationships (since r7 is not rejected) among the variables in the system.

--> there are 2 co-integrating relationships

#### 2. Model 2
```{r}
# Co-integration test

E_johansen_test_2 <- ca.jo(E_vecm_in_2, type = "trace", ecdet = "trend", K = E_vecm_max_lag_2, spec = "transitory", season = 12)

summary(E_johansen_test_2)
```

--> This suggests there is 1 cointegrating vector.

### Fit VECM

#### Model 1
```{r}

E_vecm_1 <- VECM (E_vecm_in_1, r=1, lag= E_vecm_max_lag_1-1, estim= "ML", include ="trend")
options(max.print = 10000) # Increase this number as needed

summary (E_vecm_1)
```

#### Model 2

```{r}

E_vecm_2 <- VECM (E_vecm_in_2, r=1, lag= E_vecm_max_lag_2, estim= "ML", include ="trend")
options(max.print = 10000) # Increase this number as needed
summary (E_vecm_2)

```

### 4.7.3. Residuals Diagnostics

#### Model 1: Search sub-categories

##### a. E_REA_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(E_vecm_1)[,1], main = "Residuals of E_REA_ts_train")
```

- Residuals Time Series Plot: The residuals are centered around zero with no visible patterns, indicating that the model has captured the main features of the data. Occasional larger spikes suggest periods of higher volatility but no systematic pattern.

- ACF Plot: The residuals are mostly uncorrelated, with significant autocorrelations at lags 1 and 14 indicating some remaining structure. The overall randomness suggests that the residuals are largely white noise, with minor issues.


```{r}
checkresiduals(residuals(E_vecm_1)[,1])
```
- Ljung-Box test: Rejection of Null Hypothesis: The p-value of 0.03109 indicates that there is significant autocorrelation in the residuals. This is not a desirable outcome because it suggests that the residuals are not behaving as white noise, and there is some structure left in the residuals that the model has not captured.

- Histogram with Density Plot: The residuals appear approximately normally distributed, with some minor deviations suggesting the presence of outliers or heavy tails. The overall symmetry around zero is a positive sign.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(E_vecm_1)[,1])
```

In your case, the p-value is 0.3861, which is much greater than 0.05. Therefore, you fail to reject the null hypothesis. This result indicates that there is no significant evidence to suggest that the residuals of UK_vecm_1 are not normally distributed.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(E_vecm_1)[,1], main="Q-Q Plot of Residuals")
qqline(residuals(E_vecm_1)[,1], col = "red")
grid()
```
The Q-Q plot for UK_REA_ts_train residuals shows that the residuals are approximately normally distributed with some minor deviations at the tails. 

###### ADF test
```{r}

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(E_vecm_1)[,1]) 

adf.test(residuals(E_vecm_1)[,1])

```
In all three types (no drift no trend, with drift no trend, and with drift and trend), the p-values for the ADF test are less than or equal to 0.01. This indicates that we reject the null hypothesis of a unit root at the 1% significance level for all lags considered.
The negative values of the ADF statistics (which are all significantly lower than the critical values typically used in ADF tests) also support the rejection of the null hypothesis.

###### KPSS test
```{r}
# KPSS test

residuals(E_vecm_1)[,1]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(E_vecm_1)[,1]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(E_vecm_1)[,1]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

Initial KPSS Test: For all types (no drift no trend, with drift no trend, with drift and trend), the p-values are 0.1, which is greater than the typical significance levels (0.01, 0.05). This means we fail to reject the null hypothesis of stationarity. In other words, the residuals do not show significant evidence of non-stationarity based on these tests.

KPSS Test with Schwert's Criterion:

The test statistic is 0.0478.
The critical value at the 10% significance level is 0.347. Since 0.0478 < 0.347, we fail to reject the null hypothesis of stationarity.

--> The KPSS test results, including the one performed using Schwert's criterion, consistently indicate that the residuals of UK_vecm_1 are stationary. 

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(E_vecm_1)[, 1]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- E_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(E_vecm_1)[,1], lags = 12)
print(arch_test)


```

ARCH test
The result of the ARCH LM test indicates that the p-value is 0.374, which is much greater than 0.05. Therefore, you fail to reject the null hypothesis that there are no ARCH effects in the residuals of UK_vecm_1. This suggests that the residuals do not exhibit time-varying volatility, and they are homoscedastic.

Breusch-Pagan test 
The result of the Breusch-Pagan test indicates that the p-value is 0.07592, which is greater than 0.05. Therefore, you fail to reject the null hypothesis that the variance of the residuals is constant. This suggests that the residuals of your VECM model do not exhibit heteroscedasticity, supporting the assumption of homoscedasticity in your model.

##### b. E_RPL_ts_train 

```{r}
# Residual of SII
ggtsdisplay(residuals(E_vecm_1)[,2], main = "Residuals of E_RPL_ts_train")
```
- Residuals Time Series Plots: The residuals are centered around zero with no visible patterns, indicating that the model has captured the main features of the data. Occasional spikes suggest periods of higher volatility.

- ACF and PACF Plots: The residuals are mostly uncorrelated, with a few significant lags indicating some remaining structure. The overall randomness suggests that the residuals are largely white noise.

```{r}

checkresiduals(residuals(E_vecm_1)[,2])
```
-Ljung-Box test: The p-value is 0.0749, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.

- Residuals Time Series Plot: The residuals are centered around zero with no visible patterns, indicating that the model has captured the main features of the data.

- ACF Plot: The residuals are mostly uncorrelated, with only a few lags showing significant autocorrelation, suggesting that the residuals are largely white noise.

- Histogram with Density Plot: The residuals appear to be approximately normally distributed, with some minor deviations.


###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(E_vecm_1)[,2])
```

In your case, the p-value is 0.00764, which is less than 0.05. Therefore, you reject the null hypothesis that the residuals of UK_vecm_1[,2] are normally distributed. This result indicates that there is significant evidence to suggest that the residuals do not follow a normal distribution.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(UK_vecm_1)[,2], main="Q-Q Plot of Residuals")
qqline(residuals(UK_vecm_1)[,2], col = "red")
grid()
```
- The Q-Q plot indicates that the residuals are approximately normally distributed for the most part, with some deviations at the tails.

- These deviations suggest the presence of outliers or heavy tails, which means that while the bulk of the residuals follow a normal distribution, the extreme values do not fit the normal distribution as well.

- This might be acceptable depending on the context and the robustness of the methods used. However, if strict normality is required for subsequent analysis, you might need to investigate the causes of these deviations or consider transformations to address them.

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(E_vecm_1)[,2]) 

adf.test(residuals(E_vecm_1)[,2])

```

###### KPSS test
```{r}
# KPSS test

residuals(E_vecm_1)[,2]%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(E_vecm_1)[,2]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(E_vecm_1)[,2]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```
The result of the KPSS test indicates that the test statistic is 0.0705, which is much lower than the critical values for all significance levels. Therefore, you fail to reject the null hypothesis that the residuals of UK_vecm_1[,2] are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis


###### Test of Heteroscedasticity check

```{r}

### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(E_vecm_1)[, 2]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- UK_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(E_vecm_1)[,2], lags = 12)
print(arch_test)

```
- Breusch-Pagan Test: Since the p-value is greater than 0.05, we fail to reject the null hypothesis.This means there is not enough evidence to suggest that the residuals exhibit heteroscedasticity.Therefore, the residuals can be considered to have constant variance (homoscedastic).

- ARCH Test: Since the p-value is greater than 0.05, we fail to reject the null hypothesis. This means there is not enough evidence to suggest the presence of ARCH effects in the residuals. Therefore, the residuals do not exhibit time-varying volatility and can be considered homoscedastic.


##### c. E_HF_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(E_vecm_1)[,3], main = "Residuals of E_HF_ts_train")
```

- Residuals Time Series Plots: The residuals are centered around zero with no visible patterns, indicating that the model has captured the main features of the data. Occasional spikes suggest periods of higher volatility.

- ACF and PACF Plots: The residuals are mostly uncorrelated, with a few significant lags indicating some remaining structure. The overall randomness suggests that the residuals are largely white noise

```{r}

checkresiduals(residuals(E_vecm_1)[,3])
```
- Histogram with Density Plot (Second Set): The residuals appear approximately normally distributed, with minor deviations suggesting the presence of outliers or heavy tails. The overall symmetry around zero is a positive sign.

- Ljung-Box test: Since the p-value (0.2165) is greater than 0.05, we fail to reject the null hypothesis that the residuals are independently distributed.This indicates that there is no significant evidence of autocorrelation in the residuals of the third component of your VECM model, suggesting that the residuals are adequately modeled as white noise.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(E_vecm_1)[,3])
```
In your case, the p-value is 0.003841, which is less than 0.05. Therefore, you reject the null hypothesis that the residuals of UK_vecm_1[,2] are normally distributed. This result indicates that there is significant evidence to suggest that the residuals do not follow a normal distribution.

--> Not Normally distributed (p-value <0.05)

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(E_vecm_1)[,3], main="Q-Q Plot of Residuals")
qqline(residuals(E_vecm_1)[,3], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(E_vecm_1)[,3]) 

adf.test(residuals(E_vecm_1)[,3])
```
p-value  0.05: The p-value in all cases is 0.01, which is less than the typical significance level of 0.05. This means we reject the null hypothesis that the residuals have a unit root.

Negative ADF statistics: The ADF statistics are significantly negative, which further supports the rejection of the null hypothesis.

The results of the Augmented Dickey-Fuller test indicate that the residuals of the third component of your VECM model are stationary. This is supported across all types of the ADF test (no drift no trend, with drift no trend, and with drift and trend) and various lag orders. The consistent rejection of the null hypothesis with significant p-values ( 0.01) confirms that the residuals do not exhibit a unit root and are therefore stationary.

###### KPSS test
```{r}
# KPSS test
residuals(E_vecm_1)[,3]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(E_vecm_1)[,3]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(E_vecm_1)[,3]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

Test statistic < Critical values: The test statistic (0.1593) is less than the critical values at all commonly used significance levels (10%, 5%, 2.5%, 1%). Therefore, we fail to reject the null hypothesis. This means there is not enough evidence to suggest that the residuals are non-stationary.

The results of the KPSS test indicate that the test statistic is 0.1593, which is much lower than the critical values for all significance levels. Thus, we fail to reject the null hypothesis that the residuals of the third component of your VECM model are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis.

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(E_vecm_1)[, 3]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- E_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(E_vecm_1)[,3], lags = 12)
print(arch_test)


```
Breusch-Pagan Test: p-value > 0.05: Since the p-value is greater than 0.05, we fail to reject the null hypothesis. This means there is not enough evidence to suggest that the residuals exhibit heteroscedasticity. Therefore, the residuals can be considered to have constant variance (homoscedastic).

ARCH Test: p-value > 0.05: Since the p-value is greater than 0.05, we fail to reject the null hypothesis.This means there is not enough evidence to suggest the presence of ARCH effects in the residuals. Therefore, the residuals do not exhibit time-varying volatility and can be considered homoscedastic.

##### d. E_sales_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(E_vecm_1)[,4], main = "Residuals of E_sales_ts_train")
```
- Residuals Time Series Plots: The residuals are centered around zero with no visible patterns, indicating that the model has captured the main features of the data. Occasional spikes suggest periods of higher volatility.

- ACF and PACF Plots: The residuals are mostly uncorrelated, with a few significant lags indicating some remaining structure. The overall randomness suggests that the residuals are largely white noise

```{r}
checkresiduals(residuals(E_vecm_1)[,4])
```
- Ljung-Box test: The p-value is 0.4073, which is greater than the typical significance level of 0.05.Therefore, you do not reject the null hypothesis.This means there is no significant autocorrelation in the residuals at the 5% significance level.

- Histogram with Density Plot (Second Set): The residuals appear approximately normally distributed, with minor deviations suggesting the presence of outliers or heavy tails. The overall symmetry around zero is a positive sign.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(E_vecm_1)[,4])
```

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(E_vecm_1)[,4], main="Q-Q Plot of Residuals")
qqline(residuals(E_vecm_1)[,4], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(E_vecm_1)[,4]) 

adf.test(residuals(E_vecm_1)[,4])

```

###### KPSS test
```{r}
# KPSS test
residuals(E_vecm_1)[,4]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(E_vecm_1)[,4]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(E_vecm_1)[,4]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

###### Test of Heteroscedasticity check

```{r}

### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(E_vecm_1)[, 4]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- E_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(E_vecm_1)[,4], lags = 12)
print(arch_test)


```

#### Model 2: Composite search terms/queries

```{r}
# Plot Residuals vs. Fitted Values for Model 2
residuals_vecm_2 <- residuals(E_vecm_2)
fitted_values_vecm_2 <- E_sales_ts_train[1:length(residuals_vecm_2)] - residuals_vecm_2

# Create the Residuals vs. Fitted plot
plot(fitted_values_vecm_2, residuals_vecm_2, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Residuals vs. Fitted Values for E_VECM Model 2",
     pch = 20, 
     col = "blue")

# Add a horizontal line at 0
abline(h = 0, col = "red", lty = 2)

# Add a grid for better visualization
grid()

```

##### a. ts_E_sii_train

```{r}
# Residual of SII
ggtsdisplay(residuals(E_vecm_2)[,1], main = "Residuals of ts_E_sii_train")
```

```{r}
checkresiduals(residuals(E_vecm_2)[,1])
```
- Ljung-Box test: The p-value is 0.993, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis.This means there is no significant autocorrelation in the residuals at the 5% significance level.

- Normality: The residuals appear to be approximately normally distributed, with some deviations at the tails.

- Autocorrelation: There are some signs of autocorrelation in the residuals, particularly at specific lags.

- Model Fit: The model captures the underlying data well, but there might be some areas where improvements could be made to address the observed autocorrelations and deviations from normality at the tails.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(E_vecm_2)[,1])
```

In your case, the p-value is 0.000000001531, which is much greater than 0.05. Therefore, you fail to reject the null hypothesis. This result indicates that there is evidence to suggest that the residuals of UK_vecm_1 are not normally distributed.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(E_vecm_2)[,1], main="Q-Q Plot of Residuals")
qqline(residuals(E_vecm_2)[,1], col = "red")
grid()
```
- The Q-Q plot compares the quantiles of the residuals to the quantiles of a normal distribution.

- Points should lie approximately on the red diagonal line if the residuals are normally distributed.

- In your Q-Q plot, most points lie on the line, but there are deviations at the tails, indicating potential issues with normality, particularly at the extremes.

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(E_vecm_2)[,1]) 

adf.test(residuals(E_vecm_2)[,1])
```
In all three types (no drift no trend, with drift no trend, and with drift and trend), the p-values for the ADF test are less than or equal to 0.01. This indicates that we reject the null hypothesis of a unit root at the 1% significance level for all lags considered.
The negative values of the ADF statistics (which are all significantly lower than the critical values typically used in ADF tests) also support the rejection of the null hypothesis.

###### KPSS test
```{r}
# KPSS test

residuals(E_vecm_2)[,1]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(E_vecm_2)[,1]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(E_vecm_2)[,1]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

Initial KPSS Test: For all types (no drift no trend, with drift no trend, with drift and trend), the p-values are 0.1, which is greater than the typical significance levels (0.01, 0.05). This means we fail to reject the null hypothesis of stationarity. In other words, the residuals do not show significant evidence of non-stationarity based on these tests.

KPSS Test with Schwert's Criterion:

The test statistic is 0.1121.
The critical value at the 10% significance level is 0.347. Since 0.1121 < 0.347, we fail to reject the null hypothesis of stationarity.

--> The KPSS test results, including the one performed using Schwert's criterion, consistently indicate that the residuals of UK_vecm_1 are stationary. 

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(E_vecm_2)[, 1]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- E_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(E_vecm_2)[,1], lags = 12)
print(arch_test)


```

The Breusch-Pagan test results suggest that there is no strong evidence of heteroscedasticity in the residuals, but the result is close to the significance level, indicating a potential slight heteroscedasticity.

The ARCH test results indicate significant ARCH effects in the residuals, meaning the residuals exhibit time-varying volatility.

##### b. E_sales_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(E_vecm_2)[,2], main = "Residuals of E_sales_ts_train")
```

```{r}
checkresiduals(residuals(E_vecm_2)[,2])
```
- The p-value is 0.9982, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(E_vecm_2)[,2])
```

In your case, the p-value is 0.00000001586, which is less than 0.05. Therefore, you reject the null hypothesis that the residuals of UK_vecm_1[,2] are normally distributed. This result indicates that there is significant evidence to suggest that the residuals do not follow a normal distribution.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(E_vecm_2)[,2], main="Q-Q Plot of Residuals")
qqline(residuals(E_vecm_2)[,2], col = "red")
grid()
```
- Normality: The Q-Q plot suggests that the residuals are approximately normally distributed in the central region but exhibit deviations in the tails, indicating that the residuals have heavier tails than a normal distribution. This deviation from normality could impact the performance and reliability of any inference made from the model.

- Outliers: The significant deviations at the ends of the plot indicate the presence of outliers. These outliers may need to be investigated and addressed, as they can influence the model's results.

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(E_vecm_2)[,2]) 

adf.test(residuals(E_vecm_2)[,2])

```

###### KPSS test
```{r}
# KPSS test
residuals(E_vecm_2)[,2]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(E_vecm_2)[,2]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(E_vecm_2)[,2]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```
The result of the KPSS test indicates that the test statistic is 0.0589, which is much lower than the critical values for all significance levels. Therefore, you fail to reject the null hypothesis that the residuals of UK_vecm_1[,2] are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis


###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(E_vecm_2)[, 2]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- E_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(E_vecm_2)[,2], lags = 12)
print(arch_test)

```

### 4.7.4. Forecast with VECM model

#### Model 1 

```{r}

E_forecast.vecm_1 <- predict(E_vecm_1, n.ahead = 12) # Forecast 12 months ahead

E_ts_forecast.vecm_1 <- ts(E_forecast.vecm_1[,"E_sales_ts_train"], frequency = E_frequency, start = E_start_forecast)

print (E_ts_forecast.vecm_1)

#Plot 

plot(E_sales_ts_test, main = "VECM", xlab = "Time", ylab = "Values", lwd=2) 
lines(E_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)

print(E_sales_ts_test)
```

```{r}

plot(E_sales_ts_pre, main = "VECM", xlab = "Time", ylab = "Values", lwd=2)
lines(E_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)
```

#### Evaluation metrics
```{r}

# Calculate MAPE 
round(MLmetrics::MAPE(E_ts_forecast.vecm_1,E_sales_ts_test)*100,2)

# Calculate MAE
mae <- mean(abs(E_ts_forecast.vecm_1 - E_sales_ts_test))
print(paste("MAE:", round(mae, 2)))

# Calculate MAE in percentage
mae_percentage <- (mae / mean(E_sales_ts_test)) * 100
print(paste("MAE as a percentage:", round(mae_percentage, 2), "%"))

# Calculate MPE
mpe <- mean((E_ts_forecast.vecm_1 - E_sales_ts_test) / E_sales_ts_test) * 100
print(round(mpe, 2))

# Calculate RMSE
rmse <- sqrt(mean((E_ts_forecast.vecm_1 - E_sales_ts_test)^2))
print(paste("RMSE:", round(rmse, 2)))

```

```{r}
# Save result
vecm_E_forecast_model_1 <- E_ts_forecast.vecm_1
```

#### Model 2 

```{r}

E_forecast.vecm_2 <- predict(E_vecm_2, n.ahead = 12) # Forecast 12 months ahead

E_ts_forecast.vecm_2 <- ts(E_forecast.vecm_2[,"E_sales_ts_train"], frequency = E_frequency, start = E_start_forecast)

print (E_ts_forecast.vecm_2)

#Plot 

plot(E_sales_ts_test, main = "VECM", xlab = "Time", ylab = "Values", lwd=2) 
lines(E_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)

print(E_sales_ts_test)
```

```{r}

plot(E_sales_ts_pre, main = "VECM", xlab = "Time", ylab = "Values", lwd=2)
lines(E_ts_forecast.vecm_2, col = "red",lty = "dashed", lwd = 2)
```

#### Evaluation metrics
```{r}

# Calculate MAPE 
round(MLmetrics::MAPE(E_ts_forecast.vecm_2,E_sales_ts_test)*100,2)

# Calculate MAE
mae <- mean(abs(E_ts_forecast.vecm_2 - E_sales_ts_test))
print(paste("MAE:", round(mae, 2)))

# Calculate MAE in percentage
mae_percentage <- (mae / mean(E_sales_ts_test)) * 100
print(paste("MAE as a percentage:", round(mae_percentage, 2), "%"))

# Calculate MPE
mpe <- mean((E_ts_forecast.vecm_2 - E_sales_ts_test) / E_sales_ts_test) * 100
print(round(mpe, 2))

# Calculate RMSE
rmse <- sqrt(mean((E_ts_forecast.vecm_2 - E_sales_ts_test)^2))
print(paste("RMSE:", round(rmse, 2)))

# Calculate R-squared
r_squared_model_2 <- r_squared(E_sales_ts_test, E_ts_forecast.vecm_2)
print(paste("R-squared for Model 2:", round(r_squared_model_2, 4)))

```

```{r}
# Save result
vecm_E_forecast_model_2 <- E_ts_forecast.vecm_2
```

## 4.8. VECM for Northern Ireland series
### Correlation matrix
```{r}
print(colnames(NI_data))

NI_independent_vars <- NI_data[, c("NI_sale_vol", "NI_REA", "NI_RPL", "NI_HF", "NI_HD")]

# Select only numeric columns for correlation analysis
NI_data_cor <- NI_independent_vars %>%
  select_if(is.numeric)

# Compute the correlation matrix
NI_cor_matrix <- cor(NI_data_cor, use = "complete.obs")

# Print the correlation matrix
print("Correlation Matrix:")
print(NI_cor_matrix )

```

```{r}

# Visualize the correlation matrix using ggcorrplot
ggcorrplot(NI_cor_matrix , 
           method = "circle", 
           type = "lower", 
           lab = TRUE, 
           title = "Correlation Matrix")

```


### VIF

```{r}

missing_summary <- sapply(NI_data, function(x) sum(is.na(x)))
print("Summary of Missing Values:")
print(missing_summary)

```


```{r}

# Conduct multiple regression

NI_reg_model <- lm(NI_sale_vol~NI_REA+NI_RPL+ NI_HF +NI_HD , data=NI_data)

# Print the result of multiple regression 
summary(NI_reg_model)

# Calculate VIF for the independent variables
vif(NI_reg_model)

```


### 4.8.1. Data preparation for VECM model

```{r}

# Convert data into Time Series (frequency = 12 for monthly data)
NI_sales_ts <- ts(NI_data$NI_sale_vol, frequency = 12, start = c(2005, 1))

NI_REA_ts <- ts(NI_data$NI_REA, frequency = 12, start = c(2005, 1))

NI_RPL_ts <- ts(NI_data$NI_RPL, frequency = 12, start = c(2005, 1))

NI_HF_ts <- ts(NI_data$NI_HF, frequency = 12, start = c(2005, 1))

NI_HD_ts <- ts(NI_data$NI_HD, frequency = 12, start = c(2005, 1))

```

### Plot all the time series + ADF/KPSS test

### a. NI_sales_ts
```{r}

ggtsdisplay(NI_sales_ts, lag.max = 40, main = "Time Series, ACF and PACF of NI_sales_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(NI_sales_ts) 

adf.test(NI_sales_ts)

# KPSS test

NI_sales_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_NI_sales_ts <- floor(12 * (length(NI_sales_ts) / 100)^(1/4))
print(use_lag_NI_sales_ts)

# Perform KPSS Test with the Chosen Lag
NI_sales_ts%>% ur.kpss(use.lag = use_lag_NI_sales_ts) %>% summary()

```
Conclusion: The NI_sales_ts series exhibits mixed stationarity properties:

- Non-stationary overall according to the ADF test.
- Stationary with drift according to the KPSS test with Type 2.
- Non-stationary in other configurations according to the KPSS test.
--> Non-stationary


### b. NI_REA_ts
```{r}

ggtsdisplay(NI_REA_ts, lag.max = 40, main = "Time Series, ACF and PACF of NI_REA_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(NI_REA_ts) 

adf.test(NI_REA_ts)

# KPSS test

NI_REA_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_NI_REA_ts <- floor(12 * (length(NI_REA_ts) / 100)^(1/4))
print(use_lag_NI_REA_ts)

# Perform KPSS Test with the Chosen Lag
NI_REA_ts%>% ur.kpss(use.lag = use_lag_NI_REA_ts) %>% summary()

```

ADF Test: Indicates that the NI_REA_ts series is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
Type 1: The series is stationary.
Type 2: The series is borderline non-stationary with drift.
Type 3: The series is non-stationary with drift and trend.

KPSS Test (Schwert's Criterion): Indicates that the series is non-stationary.

--> Non-stationary


### c. NI_RPL_ts
```{r}

ggtsdisplay(NI_RPL_ts, lag.max = 40, main = "Time Series, ACF and PACF of NI_RPL_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(NI_RPL_ts) 

adf.test(NI_RPL_ts)

# KPSS test

NI_RPL_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_NI_RPL_ts <- floor(12 * (length(NI_RPL_ts) / 100)^(1/4))
print(use_lag_NI_RPL_ts)

# Perform KPSS Test with the Chosen Lag
NI_RPL_ts%>% ur.kpss(use.lag = use_lag_NI_RPL_ts) %>% summary()

```

ADF Test: Indicates that the NI_RPL_ts series is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
- Type 1: The series is stationary.
- Type 2 and Type 3: The series is non-stationary with drift and trend.

KPSS Test (Schwert's Criterion): Indicates mixed results:

At the 10% and 5% significance levels, the series is non-stationary.

At the 2.5% and 1% significance levels, the series is stationary.

--> Non-stationary

### d. NI_HF_ts
```{r}

ggtsdisplay(NI_HF_ts, lag.max = 40, main = "Time Series, ACF and PACF of NI_HF_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(NI_HF_ts) 

adf.test(NI_HF_ts)

# KPSS test

NI_HF_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_NI_HF_ts <- floor(12 * (length(NI_HF_ts) / 100)^(1/4))
print(use_lag_NI_HF_ts)

# Perform KPSS Test with the Chosen Lag
NI_HF_ts%>% ur.kpss(use.lag = use_lag_NI_HF_ts) %>% summary()

```
The ADF test suggests that the series NI_HF_ts is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
- Type 1: The series is stationary.
- Type 2 and Type 3: The series is non-stationary with drift and trend.
The initial KPSS test suggests stationarity in some configurations but non-stationarity with drift and trend.

KPSS Test (Schwert's Criterion): Indicates that the series is non-stationary.

--> non-stationary.

### e. ts_NI_sii

```{r}

ggtsdisplay(NI_HD_ts, lag.max = 40, main = "Time Series, ACF and PACF of NI_HD_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(NI_HD_ts) 

adf.test(NI_HD_ts)

# KPSS test

NI_HD_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_NI_HD_ts <- floor(12 * (length(NI_HD_ts) / 100)^(1/4))
print(use_lag_NI_HD_ts)

# Perform KPSS Test with the Chosen Lag
NI_HD_ts%>% ur.kpss(use.lag = use_lag_NI_HD_ts) %>% summary()

```


### Split train and test set for VECM model

### Training data from Jan 2005 to Feb 2020

#### a. NI_sales_ts
```{r}

# Split the NI_sales_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
NI_sales_ts_train <- window(NI_sales_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
NI_sales_ts_test <- window(NI_sales_ts, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the training time series
str(NI_sales_ts_train)

# Check the structure of the testing time series
str(NI_sales_ts_test)

# Print the training time series data to verify the split
print(NI_sales_ts_train)

# Print the testing time series data to verify the split
print(NI_sales_ts_test)

```

#### b. NI_REA_ts
```{r}
# Split the NI_REA_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
NI_REA_ts_train <- window(NI_REA_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
NI_REA_ts_test <- window(NI_REA_ts, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the training time series
str(NI_REA_ts_train)

# Check the structure of the testing time series
str(NI_REA_ts_test)

# Print the training time series data to verify the split
print(NI_REA_ts_train)

# Print the testing time series data to verify the split
print(NI_REA_ts_test)
```

#### c. NI_RPL_ts
```{r}
# Split the NI_RPL_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
NI_RPL_ts_train <- window(NI_RPL_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
NI_RPL_ts_test <- window(NI_RPL_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(NI_RPL_ts_train)
str(NI_RPL_ts_test)

# Print the time series data
print(NI_RPL_ts_train)
print(NI_RPL_ts_test)

```

#### d. NI_HF_ts
```{r}

# Split the NI_HF_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019

NI_HF_ts_train <- window(NI_HF_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
NI_HF_ts_test <- window(NI_HF_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(NI_HF_ts_train)
str(NI_HF_ts_test)

# Print the time series data
print(NI_HF_ts_train)
print(NI_HF_ts_test)

```


#### e. ts_NI_sii

```{r}
# Split the ts_NI_sii time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
ts_NI_sii_train <- window(ts_NI_sii, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
ts_NI_sii_test <- window(ts_NI_sii, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(ts_NI_sii_train)
str(ts_NI_sii_test)

# Print the time series data
print(ts_NI_sii_train)
print(ts_NI_sii_test)

```

### Define period

```{r}
NI_frequency <- frequency (NI_sales_ts_train)
NI_start <- start (NI_sales_ts_train)
NI_end <- end (NI_sales_ts_train)
NI_start_forecast <- c(NI_end[1],NI_end[2] + 1)

print (NI_frequency)
print (NI_start)
print (NI_end)
print (NI_start_forecast)
```

### Create VECM input

```{r}
# Model 1: Use search subcategories
NI_vecm_in_1 <- cbind (NI_REA_ts_train, NI_RPL_ts_train, NI_HF_ts_train, NI_sales_ts_train)

# Model 2: Use composite search terms/queries
NI_vecm_in_2 <- cbind (ts_NI_sii_train,NI_sales_ts_train)

```

### 4.8.2. VECM model building

```{r}

# Select lags based in differenced data
(NI_vecm_lagselect_1 <- VARselect (NI_vecm_in_1, lag.max=12, type = "trend" ))
(NI_vecm_lagselect_2 <- VARselect (NI_vecm_in_2, lag.max=12, type = "trend" ))

```

### Choose lags
```{r}

(NI_vecm_max_lag_1 <-NI_vecm_lagselect_1$selection[1])

(NI_vecm_max_lag_2 <-NI_vecm_lagselect_2$selection[1])

```

### Apply Johansen's Cointegration Test

#### 1. Model 1
```{r}
# Co-integration test (K need to be greater than 1)

NI_johansen_test_1 <- ca.jo(NI_vecm_in_1, type = "trace", ecdet = "trend", K = NI_vecm_max_lag_1+1, spec = "transitory", season = 12)

summary(NI_johansen_test_1)
```

From r=0 to r <=6: The test statistic (51.27) is greater than the 5% critical value (42.44), so we reject the null hypothesis of at most six co-integrating vectors (r  6).

Test r <=7:The test statistic (24.29) is less than the 5% critical value (25.32), so we do not reject the null hypothesis of at most seven co-integrating vectors (r  7).

--> Based on the test statistics and critical values, we can conclude that there are 7 co-integrating relationships (since r7 is not rejected) among the variables in the system.

--> there are 1 co-integrating relationships

#### 2. Model 2
```{r}
# Co-integration test

NI_johansen_test_2 <- ca.jo(NI_vecm_in_2, type = "trace", ecdet = "trend", K = NI_vecm_max_lag_2, spec = "transitory", season = 12)

summary(NI_johansen_test_2)
```

--> This suggests there is 1 cointegrating vector.

### Fit VECM

#### Model 1
```{r}

NI_vecm_1 <- VECM (NI_vecm_in_1, r=2, lag= NI_vecm_max_lag_1, estim= "ML", include ="trend")
options(max.print = 10000) # Increase this number as needed

summary (NI_vecm_1)
```

#### Model 2

```{r}

NI_vecm_2 <- VECM (NI_vecm_in_2, r=1, lag= NI_vecm_max_lag_2, estim= "ML", include ="trend")
options(max.print = 10000) # Increase this number as needed
summary (NI_vecm_2)

```

### 4.8.3. Residuals Diagnostics

#### Model 1: Search sub-categories

##### a. NI_REA_ts_train

```{r}
ggtsdisplay(residuals(NI_vecm_1)[,1], main = "Residuals of NI_REA_ts_train")
```
- Time Series Plot: Residuals mostly centered around zero but with some notable spikes, indicating potential anomalies or model inadequacies.

- ACF/PACF Plots: Significant autocorrelation at lag 10 suggests that the model might be missing some structure.

```{r}
checkresiduals(residuals(NI_vecm_1)[,1])
```
- Ljung-Box test: p-value < 0.05: This suggests that we reject the null hypothesis at the 5% significance level. Therefore, there is significant autocorrelation in the residuals up to lag 10. This implies that your model might not have captured all the autocorrelation structure in the data..

- Histogram and Q-Q Plot: The histogram should ideally show a bell curve shape, and the Q-Q plot should have points along the line. Deviations here would suggest non-normality in the residuals.


###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(NI_vecm_1)[,1])
```

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(NI_vecm_1)[,1], main="Q-Q Plot of Residuals")
qqline(residuals(NI_vecm_1)[,1], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(NI_vecm_1)[,1]) 

adf.test(residuals(NI_vecm_1)[,1])

```

###### KPSS test
```{r}
# KPSS test

residuals(NI_vecm_1)[,1]%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(NI_vecm_1)[,1]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(NI_vecm_1)[,1]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(NI_vecm_1)[, 1]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- NI_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(NI_vecm_1)[,1], lags = 12)
print(arch_test)

```

##### b. NI_RPL_ts_train 

```{r}
# Residual of SII
ggtsdisplay(residuals(NI_vecm_1)[,2], main = "Residuals of NI_RPL_ts_train")
```
- Autocorrelation: The ACF and PACF plots indicate significant autocorrelation at lag 10. This suggests that the residuals are not entirely random and there might be some remaining structure that the model did not capture.

- Variance: The time series plot shows some periods of higher variance, which could indicate heteroscedasticity.

```{r}
checkresiduals(residuals(NI_vecm_1)[,2])
```
- The p-value is 0.09731, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.

- Normality: The histogram and Q-Q plot suggest that the residuals are approximately normally distributed, though there are some outliers and deviations in the tails.


###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(NI_vecm_1)[,2])
```

In your case, the p-value is 0.0000000001167, which is less than 0.05. Therefore, you reject the null hypothesis that the residuals of UK_vecm_1[,2] are normally distributed. This result indicates that there is significant evidence to suggest that the residuals do not follow a normal distribution.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(NI_vecm_1)[,2], main="Q-Q Plot of Residuals")
qqline(residuals(NI_vecm_1)[,2], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(NI_vecm_1)[,2]) 

adf.test(residuals(NI_vecm_1)[,2])

```

###### KPSS test
```{r}
# KPSS test

residuals(NI_vecm_1)[,2]%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(NI_vecm_1)[,2]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(NI_vecm_1)[,2]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```
The result of the KPSS test indicates that the test statistic is 0.0505, which is much lower than the critical values for all significance levels. Therefore, you fail to reject the null hypothesis that the residuals of UK_vecm_1[,2] are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis


###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(NI_vecm_1)[, 2]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- NI_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(NI_vecm_1)[,2], lags = 12)
print(arch_test)

```
- Breusch-Pagan Test: Since the p-value is greater than 0.05, we fail to reject the null hypothesis.This means there is not enough evidence to suggest that the residuals exhibit heteroscedasticity.Therefore, the residuals can be considered to have constant variance (homoscedastic).

- ARCH Test: Since the p-value is greater than 0.05, we fail to reject the null hypothesis. This means there is not enough evidence to suggest the presence of ARCH effects in the residuals. Therefore, the residuals do not exhibit time-varying volatility and can be considered homoscedastic.


##### c. NI_HF_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(NI_vecm_1)[,3], main = "Residuals of NI_HF_ts_train")
```

```{r}
checkresiduals(residuals(NI_vecm_1)[,3])
```
- The residuals exhibit some autocorrelation, particularly at lag 10, suggesting that the model may not have fully captured all the patterns in the data.

- There are outliers or periods of large errors in the residuals, indicating that the model's predictions are less accurate at certain points.

- The residuals are not perfectly normally distributed, as indicated by the histogram and Q-Q plot, which may affect the validity of any inferential statistics based on the assumption of normality.

- Ljung-Box test: Since the p-value (0.02893) is less than 0.05, we reject the null hypothesis that the residuals are independently distributed.This indicates that there is evidence of autocorrelation in the residuals of the third component of your VECM model. 

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(NI_vecm_1)[,3])
```

--> Non-Normally distributed (p-value <0.05)

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(NI_vecm_1)[,3], main="Q-Q Plot of Residuals")
qqline(residuals(NI_vecm_1)[,3], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(NI_vecm_1)[,3]) 

adf.test(residuals(NI_vecm_1)[,3])
```
p-value  0.05: The p-value in all cases is 0.01, which is less than the typical significance level of 0.05. This means we reject the null hypothesis that the residuals have a unit root.

Negative ADF statistics: The ADF statistics are significantly negative, which further supports the rejection of the null hypothesis.

The results of the Augmented Dickey-Fuller test indicate that the residuals of the third component of your VECM model are stationary. This is supported across all types of the ADF test (no drift no trend, with drift no trend, and with drift and trend) and various lag orders. The consistent rejection of the null hypothesis with significant p-values ( 0.01) confirms that the residuals do not exhibit a unit root and are therefore stationary.

###### KPSS test
```{r}
# KPSS test
residuals(NI_vecm_1)[,3]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(NI_vecm_1)[,3]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(NI_vecm_1)[,3]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

Test statistic < Critical values: The test statistic (0.1426) is less than the critical values at all commonly used significance levels (10%, 5%, 2.5%, 1%). Therefore, we fail to reject the null hypothesis. This means there is not enough evidence to suggest that the residuals are non-stationary.

The results of the KPSS test indicate that the test statistic is 0.1426, which is much lower than the critical values for all significance levels. Thus, we fail to reject the null hypothesis that the residuals of the third component of your VECM model are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis.

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(NI_vecm_1)[, 3]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- NI_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(NI_vecm_1)[,3], lags = 12)
print(arch_test)


```
Both test show Heteroscedasticity (p-value < 0.05)

##### d. NI_sales_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(NI_vecm_1)[,4], main = "Residuals of NI_sales_ts_train")
```


```{r}
checkresiduals(residuals(NI_vecm_1)[,4])
```
- Ljung-Box test: The p-value is 0.004896, which is less than the typical significance level of 0.05.Therefore, we reject the null hypothesis.This means there is significant autocorrelation in the residuals at the 5% significance level.

- The Q-Q plot indicates that the residuals are not perfectly normally distributed, with significant deviations at the tails.

- The residuals plot shows some patterns, suggesting the residuals are not purely random.

- The ACF and PACF plots both show significant autocorrelations at certain lags, suggesting there are structures in the data that the model has not fully captured.


###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(NI_vecm_1)[,4])
```

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(NI_vecm_1)[,4], main="Q-Q Plot of Residuals")
qqline(residuals(NI_vecm_1)[,4], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(NI_vecm_1)[,4]) 

adf.test(residuals(NI_vecm_1)[,4])

```

###### KPSS test
```{r}
# KPSS test
residuals(NI_vecm_1)[,4]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(NI_vecm_1)[,4]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(NI_vecm_1)[,4]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

###### Test of Heteroscedasticity check

```{r}

### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(NI_vecm_1)[, 4]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- NI_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(NI_vecm_1)[,4], lags = 12)
print(arch_test)

```

#### Model 2: Composite search terms/queries

```{r}
# Plot Residuals vs. Fitted Values for Model 2
residuals_vecm_2 <- residuals(NI_vecm_2)
fitted_values_vecm_2 <- NI_sales_ts_train[1:length(residuals_vecm_2)] - residuals_vecm_2

# Create the Residuals vs. Fitted plot
plot(fitted_values_vecm_2, residuals_vecm_2, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Residuals vs. Fitted Values for NI_VECM Model 2",
     pch = 20, 
     col = "blue")

# Add a horizontal line at 0
abline(h = 0, col = "red", lty = 2)

# Add a grid for better visualization
grid()

```

##### a. ts_NI_sii_train

```{r}
# Residual of SII
ggtsdisplay(residuals(NI_vecm_2)[,1], main = "Residuals of ts_NI_sii_train")
```

```{r}
checkresiduals(residuals(NI_vecm_2)[,1])
```
- Ljung-Box test: The p-value is 0.7277, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis.This means there is no significant autocorrelation in the residuals at the 5% significance level.

- Residuals Time Series Plots: The residuals are centered around zero with no visible patterns, indicating that the model has captured the main features of the data. The presence of significant spikes at certain points indicates occasional higher volatility.

- ACF and PACF Plots: The residuals are mostly uncorrelated, with a few significant lags indicating some remaining structure. The overall randomness suggests that the residuals are largely white noise.

- Histogram with Density Plot (Second Set): The residuals appear approximately normally distributed, with minor deviations suggesting the presence of outliers or heavy tails.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(NI_vecm_2)[,1])
```

In your case, the p-value is 0.06386, which is much greater than 0.05. Therefore, you fail to reject the null hypothesis. This result indicates that there is no significant evidence to suggest that the residuals of UK_vecm_1 are not normally distributed.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(NI_vecm_2)[,1], main="Q-Q Plot of Residuals")
qqline(residuals(NI_vecm_2)[,1], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(NI_vecm_2)[,1]) 

adf.test(residuals(NI_vecm_2)[,1])
```
In all three types (no drift no trend, with drift no trend, and with drift and trend), the p-values for the ADF test are less than or equal to 0.01. This indicates that we reject the null hypothesis of a unit root at the 1% significance level for all lags considered.
The negative values of the ADF statistics (which are all significantly lower than the critical values typically used in ADF tests) also support the rejection of the null hypothesis.

###### KPSS test
```{r}
# KPSS test

residuals(NI_vecm_2)[,1]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(NI_vecm_2)[,1]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(NI_vecm_2)[,1]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

Initial KPSS Test: For all types (no drift no trend, with drift no trend, with drift and trend), the p-values are 0.1, which is greater than the typical significance levels (0.01, 0.05). This means we fail to reject the null hypothesis of stationarity. In other words, the residuals do not show significant evidence of non-stationarity based on these tests.

KPSS Test with Schwert's Criterion:

The test statistic is 0.1121.
The critical value at the 10% significance level is 0.347. Since 0.1121 < 0.347, we fail to reject the null hypothesis of stationarity.

--> The KPSS test results, including the one performed using Schwert's criterion, consistently indicate that the residuals of UK_vecm_1 are stationary. 

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(NI_vecm_2)[, 1]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- NI_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(NI_vecm_2)[,1], lags = 12)
print(arch_test)


```

ARCH test
The result of the ARCH LM test indicates that the p-value is  0.003951, which is much less than 0.05. Therefore, you reject the null hypothesis that there are no ARCH effects in the residuals of UK_vecm_1. This suggests that the residuals are not homoscedastic.

Breusch-Pagan test 
The result of the Breusch-Pagan test indicates that the p-value is 0.2048, which is greater than 0.05. Therefore, you fail to reject the null hypothesis that the variance of the residuals is constant. This suggests that the residuals of your VECM model do not exhibit heteroscedasticity, supporting the assumption of homoscedasticity in your model.

##### b. NI_sales_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(NI_vecm_2)[,2], main = "Residuals of NI_sales_ts_train")
```


```{r}

checkresiduals(residuals(NI_vecm_2)[,2])
```
- The p-value is 0.4301, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(NI_vecm_2)[,2])
```

In your case, the p-value is 0.000000007942, which is less than 0.05. Therefore, you reject the null hypothesis that the residuals of UK_vecm_1[,2] are normally distributed. This result indicates that there is significant evidence to suggest that the residuals do not follow a normal distribution.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(NI_vecm_2)[,2], main="Q-Q Plot of Residuals")
qqline(residuals(NI_vecm_2)[,2], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(NI_vecm_2)[,2]) 

adf.test(residuals(NI_vecm_2)[,2])

```

###### KPSS test
```{r}
# KPSS test
residuals(NI_vecm_2)[,2]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(NI_vecm_2)[,2]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(NI_vecm_2)[,2]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```
The result of the KPSS test indicates that the test statistic is 0.0387, which is much lower than the critical values for all significance levels. Therefore, you fail to reject the null hypothesis that the residuals of UK_vecm_1[,2] are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(NI_vecm_2)[, 2]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- NI_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(NI_vecm_2)[,2], lags = 12)
print(arch_test)

```

### 4.8.4. Forecast with VECM model
#### Model 1 

```{r}

NI_forecast.vecm_1 <- predict(NI_vecm_1, n.ahead = 12) # Forecast 12 months ahead

NI_ts_forecast.vecm_1 <- ts(NI_forecast.vecm_1[,"NI_sales_ts_train"], frequency = E_frequency, start = NI_start_forecast)

print (NI_ts_forecast.vecm_1)

#Plot 

plot(NI_sales_ts_test, main = "VECM", xlab = "Time", ylab = "Values", lwd=2) 
lines(NI_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)

print(NI_sales_ts_test)
```

```{r}

plot(NI_sales_ts_pre, main = "VECM", xlab = "Time", ylab = "Values", lwd=2)
lines(NI_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)
```

#### Evaluation metrics
```{r}

# Calculate MAPE 
round(MLmetrics::MAPE(NI_ts_forecast.vecm_1,NI_sales_ts_test)*100,2)

# Calculate MAE
mae <- mean(abs(NI_ts_forecast.vecm_1 - NI_sales_ts_test))
print(paste("MAE:", round(mae, 2)))

# Calculate MAE in percentage
mae_percentage <- (mae / mean(NI_sales_ts_test)) * 100
print(paste("MAE as a percentage:", round(mae_percentage, 2), "%"))

# Calculate MPE
mpe <- mean((NI_ts_forecast.vecm_1 - NI_sales_ts_test) / NI_sales_ts_test) * 100
print(round(mpe, 2))

# Calculate RMSE
rmse <- sqrt(mean((NI_ts_forecast.vecm_1 - NI_sales_ts_test)^2))
print(paste("RMSE:", round(rmse, 2)))

# Calculate R-squared
r_squared_model_1 <- r_squared(NI_sales_ts_test, NI_ts_forecast.vecm_1)
print(paste("R-squared for Model 1:", round(r_squared_model_1, 4)))
```

```{r}
# Save result 
vecm_NI_forecast_model_1 <- NI_ts_forecast.vecm_1
```

#### Model 2 

```{r}

NI_forecast.vecm_2 <- predict(NI_vecm_2, n.ahead = 12) # Forecast 12 months ahead

NI_ts_forecast.vecm_2 <- ts(NI_forecast.vecm_2[,"NI_sales_ts_train"], frequency = NI_frequency, start = NI_start_forecast)

print (NI_ts_forecast.vecm_2)

#Plot 

plot(NI_sales_ts_test, main = "VECM", xlab = "Time", ylab = "Values", lwd=2) 
lines(NI_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)

print(NI_sales_ts_test)
```

```{r}

plot(NI_sales_ts_pre, main = "VECM", xlab = "Time", ylab = "Values", lwd=2)
lines(NI_ts_forecast.vecm_2, col = "red",lty = "dashed", lwd = 2)
```

#### Evaluation metrics
```{r}

#MAPE 
round(MLmetrics::MAPE(NI_ts_forecast.vecm_2,NI_sales_ts_test)*100,2)

# Calculate MAE
mae <- mean(abs(NI_ts_forecast.vecm_2 - NI_sales_ts_test))
print(paste("MAE:", round(mae, 2)))

# Calculate MAE in percentage
mae_percentage <- (mae / mean(NI_sales_ts_test)) * 100
print(paste("MAE as a percentage:", round(mae_percentage, 2), "%"))

# Calculate MPE
mpe <- mean((NI_ts_forecast.vecm_2 - NI_sales_ts_test) / NI_sales_ts_test) * 100
print(round(mpe, 2))

# Calculate RMSE
rmse <- sqrt(mean((NI_ts_forecast.vecm_2 - NI_sales_ts_test)^2))
print(paste("RMSE:", round(rmse, 2)))

```

```{r}
# Save result 
vecm_NI_forecast_model_2 <- NI_ts_forecast.vecm_2
```


## 4.9. VECM for Scotland series
### Correlation matrix
```{r}
print(colnames(S_data))

S_independent_vars <- S_data[, c("S_sale_vol", "S_REA", "S_RPL", "S_HF", "S_HD")]

# Select only numeric columns for correlation analysis
S_data_cor <- S_independent_vars %>%
  select_if(is.numeric)

# Compute the correlation matrix
S_cor_matrix <- cor(S_data_cor, use = "complete.obs")

# Print the correlation matrix
print("Correlation Matrix:")
print(S_cor_matrix )

```

```{r}

# Visualize the correlation matrix using ggcorrplot
ggcorrplot(S_cor_matrix , 
           method = "circle", 
           type = "lower", 
           lab = TRUE, 
           title = "Correlation Matrix")

```

### VIF

```{r}
missing_summary <- sapply(S_data, function(x) sum(is.na(x)))
print("Summary of Missing Values:")
print(missing_summary)

```

```{r}
# Conduct multiple regression
S_reg_model <- lm(S_sale_vol~S_REA+S_RPL+ S_HF +S_HD , data=S_data)

# Print the result of multiple regression 
summary(S_reg_model)

# Calculate VIF for the independent variables
vif(S_reg_model)

```


### 4.9.1. Data preparation for VECM model

```{r}
# Convert data into Time Series (frequency = 12 for monthly data)
S_sales_ts <- ts(S_data$S_sale_vol, frequency = 12, start = c(2005, 1))

S_REA_ts <- ts(S_data$S_REA, frequency = 12, start = c(2005, 1))

S_RPL_ts <- ts(S_data$S_RPL, frequency = 12, start = c(2005, 1))

S_HF_ts <- ts(S_data$S_HF, frequency = 12, start = c(2005, 1))

S_HD_ts <- ts(S_data$S_HD, frequency = 12, start = c(2005, 1))

```

### Plot all the time series + ADF/KPSS test

### a. S_sales_ts
```{r}
ggtsdisplay(S_sales_ts, lag.max = 40, main = "Time Series, ACF and PACF of S_sales_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(S_sales_ts) 

adf.test(S_sales_ts)

# KPSS test

S_sales_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_S_sales_ts <- floor(12 * (length(S_sales_ts) / 100)^(1/4))
print(use_lag_S_sales_ts)

# Perform KPSS Test with the Chosen Lag
S_sales_ts%>% ur.kpss(use.lag = use_lag_S_sales_ts) %>% summary()

```
Conclusion: The S_sales_ts series exhibits mixed stationarity properties:

- Non-stationary overall according to the ADF test.
- Stationary with drift according to the KPSS test with Type 2.
- Non-stationary in other configurations according to the KPSS test.
--> Non-stationary


### b. S_REA_ts
```{r}

ggtsdisplay(S_REA_ts, lag.max = 40, main = "Time Series, ACF and PACF of S_REA_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(S_REA_ts) 

adf.test(S_REA_ts)

# KPSS test

S_REA_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_S_REA_ts <- floor(12 * (length(S_REA_ts) / 100)^(1/4))
print(use_lag_S_REA_ts)

# Perform KPSS Test with the Chosen Lag
S_REA_ts%>% ur.kpss(use.lag = use_lag_S_REA_ts) %>% summary()

```

ADF Test: Indicates that the S_REA_ts series is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
Type 1: The series is stationary.
Type 2: The series is borderline non-stationary with drift.
Type 3: The series is non-stationary with drift and trend.

KPSS Test (Schwert's Criterion): Indicates that the series is non-stationary.

--> Non-stationary


### c. S_RPL_ts
```{r}

ggtsdisplay(S_RPL_ts, lag.max = 40, main = "Time Series, ACF and PACF of S_RPL_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(S_RPL_ts) 

adf.test(S_RPL_ts)

# KPSS test

S_RPL_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_S_RPL_ts <- floor(12 * (length(S_RPL_ts) / 100)^(1/4))
print(use_lag_S_RPL_ts)

# Perform KPSS Test with the Chosen Lag
S_RPL_ts%>% ur.kpss(use.lag = use_lag_S_RPL_ts) %>% summary()

```

ADF Test: Indicates that the S_RPL_ts series is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
- Type 1: The series is stationary.
- Type 2 and Type 3: The series is non-stationary with drift and trend.

KPSS Test (Schwert's Criterion): Indicates mixed results:

At the 10% and 5% significance levels, the series is non-stationary.

At the 2.5% and 1% significance levels, the series is stationary.

--> Non-stationary

### d. S_HF_ts
```{r}

ggtsdisplay(S_HF_ts, lag.max = 40, main = "Time Series, ACF and PACF of S_HF_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(S_HF_ts) 

adf.test(S_HF_ts)

# KPSS test

S_HF_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_S_HF_ts <- floor(12 * (length(S_HF_ts) / 100)^(1/4))
print(use_lag_S_HF_ts)

# Perform KPSS Test with the Chosen Lag
S_HF_ts%>% ur.kpss(use.lag = use_lag_S_HF_ts) %>% summary()

```
The ADF test suggests that the series S_HF_ts is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
- Type 1: The series is stationary.
- Type 2 and Type 3: The series is non-stationary with drift and trend.
The initial KPSS test suggests stationarity in some configurations but non-stationarity with drift and trend.

KPSS Test (Schwert's Criterion): Indicates that the series is non-stationary.

--> non-stationary.

### e. ts_S_sii

```{r}

ggtsdisplay(S_HD_ts, lag.max = 40, main = "Time Series, ACF and PACF of ts_S_sii")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(S_HD_ts) 

adf.test(S_HD_ts)

# KPSS test

S_HD_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_S_HD_ts <- floor(12 * (length(S_HD_ts) / 100)^(1/4))
print(use_lag_S_HD_ts)

# Perform KPSS Test with the Chosen Lag
S_HD_ts%>% ur.kpss(use.lag = use_lag_S_HD_ts) %>% summary()

```


### Split train and test set for VECM model

### Training data from Jan 2005 to Feb 2020

#### a. S_sales_ts
```{r}

# Split the S_sales_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
S_sales_ts_train <- window(S_sales_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
S_sales_ts_test <- window(S_sales_ts, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the training time series
str(S_sales_ts_train)

# Check the structure of the testing time series
str(S_sales_ts_test)

# Print the training time series data to verify the split
print(S_sales_ts_train)

# Print the testing time series data to verify the split
print(S_sales_ts_test)

```

#### b. S_REA_ts
```{r}
# Split the S_REA_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
S_REA_ts_train <- window(S_REA_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
S_REA_ts_test <- window(S_REA_ts, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the training time series
str(S_REA_ts_train)

# Check the structure of the testing time series
str(S_REA_ts_test)

# Print the training time series data to verify the split
print(S_REA_ts_train)

# Print the testing time series data to verify the split
print(S_REA_ts_test)
```

#### c. S_RPL_ts
```{r}
# Split the S_RPL_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
S_RPL_ts_train <- window(S_RPL_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
S_RPL_ts_test <- window(S_RPL_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(S_RPL_ts_train)
str(S_RPL_ts_test)

# Print the time series data
print(S_RPL_ts_train)
print(S_RPL_ts_test)

```

#### d. S_HF_ts
```{r}

# Split the S_HF_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019

S_HF_ts_train <- window(S_HF_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
S_HF_ts_test <- window(S_HF_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(S_HF_ts_train)
str(S_HF_ts_test)

# Print the time series data
print(S_HF_ts_train)
print(S_HF_ts_test)

```


#### e. ts_S_sii

```{r}
# Split the ts_S_sii time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
ts_S_sii_train <- window(ts_S_sii, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
ts_S_sii_test <- window(ts_S_sii, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(ts_S_sii_train)
str(ts_S_sii_test)

# Print the time series data
print(ts_S_sii_train)
print(ts_S_sii_test)

```


### Define period

```{r}
S_frequency <- frequency (S_sales_ts_train)
S_start <- start (S_sales_ts_train)
S_end <- end (S_sales_ts_train)
S_start_forecast <- c(S_end[1],S_end[2] + 1)

print (S_frequency)
print (S_start)
print (S_end)
print (S_start_forecast)
```

### Create VECM input

```{r}
# Model 1: Use search subcategories
S_vecm_in_1 <- cbind (S_REA_ts_train, S_RPL_ts_train, S_HF_ts_train, S_sales_ts_train)

# Model 2: Use composite search terms/queries
S_vecm_in_2 <- cbind (ts_S_sii_train,S_sales_ts_train)

```

### 4.9.2. VECM Model Building

```{r}
# Select lags based in differenced data
(S_vecm_lagselect_1 <- VARselect (S_vecm_in_1, lag.max=12, type = "trend" ))
(S_vecm_lagselect_2 <- VARselect (S_vecm_in_2, lag.max=12, type = "trend" ))

```

### Choose lags
```{r}

(S_vecm_max_lag_1 <-S_vecm_lagselect_1$selection[1])

(S_vecm_max_lag_2 <-S_vecm_lagselect_2$selection[1])

```

### Apply Johansen's Cointegration Test

#### Model 1
```{r}
# Co-integration test

S_johansen_test_1 <- ca.jo(S_vecm_in_1, type = "trace", ecdet = "trend", K = S_vecm_max_lag_1, spec = "transitory", season = 12)

summary(S_johansen_test_1)
```

From r=0 to r <=6: The test statistic (51.27) is greater than the 5% critical value (42.44), so we reject the null hypothesis of at most six co-integrating vectors (r  6).

Test r <=7:The test statistic (24.29) is less than the 5% critical value (25.32), so we do not reject the null hypothesis of at most seven co-integrating vectors (r  7).

--> Based on the test statistics and critical values, we can conclude that there are 7 co-integrating relationships (since r7 is not rejected) among the variables in the system.

--> there are 2 co-integrating relationships

#### Model 2
```{r}
# Co-integration test

S_johansen_test_2 <- ca.jo(S_vecm_in_2, type = "trace", ecdet = "trend", K = S_vecm_max_lag_2, spec = "transitory", season = 12)

summary(S_johansen_test_2)
```

--> This suggests there is 1 cointegrating vector.

### Fit VECM

#### Model 1
```{r}

S_vecm_1 <- VECM (S_vecm_in_1, r=1, lag= S_vecm_max_lag_1-1, estim= "ML", include ="trend")
options(max.print = 10000) # Increase this number as needed

summary (S_vecm_1)
```

#### Model 2

```{r}

S_vecm_2 <- VECM (S_vecm_in_2, r=1, lag= S_vecm_max_lag_2, estim= "ML", include ="trend")
options(max.print = 10000) # Increase this number as needed
summary (S_vecm_2)

```

### 4.9.3. Residuals Diagnostics

#### Model 1: Search sub-categories

##### a. S_REA_ts_train

```{r}
ggtsdisplay(residuals(S_vecm_1)[,1], main = "Residuals of S_REA_ts_train")
```

```{r}
checkresiduals(residuals(S_vecm_1)[,1])
```
- Ljung-Box test: The p-value is 0.9796, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.


###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(S_vecm_1)[,1])
```

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(S_vecm_1)[,1], main="Q-Q Plot of Residuals")
qqline(residuals(S_vecm_1)[,1], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(S_vecm_1)[,1]) 

adf.test(residuals(S_vecm_1)[,1])

```

###### KPSS test
```{r}
# KPSS test

residuals(S_vecm_1)[,1]%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(S_vecm_1)[,1]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(S_vecm_1)[,1]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

###### Test of Heteroscedasticity check

```{r}

### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(S_vecm_1)[, 1]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- S_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(S_vecm_1)[,1], lags = 12)
print(arch_test)
```

##### b. S_RPL_ts_train 

```{r}
# Residual of SII
ggtsdisplay(residuals(S_vecm_1)[,2], main = "Residuals of S_RPL_ts_train")
```
- The residuals of the time series model are generally well-behaved, with most residuals oscillating around zero and minimal autocorrelation indicated by the ACF and PACF plots.

- The significant spike around the 50th time point suggests an outlier or an unusual observation that might need further investigation.

```{r}

checkresiduals(residuals(S_vecm_1)[,2])
```
- The p-value is 0.1997, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.

- The histogram of residuals shows a roughly normal distribution, which is desirable for residuals in a time series model.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(S_vecm_1)[,2])
```

In your case, the p-value is 0.0000000000256, which is less than 0.05. Therefore, you reject the null hypothesis that the residuals of UK_vecm_1[,2] are normally distributed. This result indicates that there is significant evidence to suggest that the residuals do not follow a normal distribution.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(S_vecm_1)[,2], main="Q-Q Plot of Residuals")
qqline(residuals(S_vecm_1)[,2], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(S_vecm_1)[,2]) 

adf.test(residuals(S_vecm_1)[,2])

```

###### KPSS test
```{r}
# KPSS test
residuals(S_vecm_1)[,2]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(S_vecm_1)[,2]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(S_vecm_1)[,2]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```
The result of the KPSS test indicates that the test statistic is 0.0705, which is much lower than the critical values for all significance levels. Therefore, you fail to reject the null hypothesis that the residuals of UK_vecm_1[,2] are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis


###### Test of Heteroscedasticity check

```{r}

### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(S_vecm_1)[, 2]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- S_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(S_vecm_1)[,2], lags = 12)
print(arch_test)

```
- Breusch-Pagan Test: Since the p-value is greater than 0.05, we fail to reject the null hypothesis.This means there is not enough evidence to suggest that the residuals exhibit heteroscedasticity.Therefore, the residuals can be considered to have constant variance (homoscedastic).

- ARCH Test: Since the p-value is greater than 0.05, we fail to reject the null hypothesis. This means there is not enough evidence to suggest the presence of ARCH effects in the residuals. Therefore, the residuals do not exhibit time-varying volatility and can be considered homoscedastic.


##### c. S_HF_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(S_vecm_1)[,3], main = "Residuals of S_HF_ts_train")
```

- The residuals of the time series model generally behave as expected, with most residuals oscillating around zero and minimal autocorrelation indicated by the ACF and PACF plots.

- The significant spikes around the 50th and 100th time points suggest outliers or unusual observations that might need further investigation.

```{r}

checkresiduals(residuals(S_vecm_1)[,3])
```
- The histogram of residuals shows a roughly normal distribution, with a few outliers that might need to be addressed.

- Ljung-Box test: Since the p-value (0.9726) is greater than 0.05, we fail to reject the null hypothesis that the residuals are independently distributed.This indicates that there is no significant evidence of autocorrelation in the residuals of the third component of your VECM model, suggesting that the residuals are adequately modeled as white noise.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(S_vecm_1)[,3])
```

--> Normally distributed (p-value >0.05)

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(S_vecm_1)[,3], main="Q-Q Plot of Residuals")
qqline(residuals(S_vecm_1)[,3], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(S_vecm_1)[,3]) 

adf.test(residuals(S_vecm_1)[,3])
```
p-value  0.05: The p-value in all cases is 0.01, which is less than the typical significance level of 0.05. This means we reject the null hypothesis that the residuals have a unit root.

Negative ADF statistics: The ADF statistics are significantly negative, which further supports the rejection of the null hypothesis.

The results of the Augmented Dickey-Fuller test indicate that the residuals of the third component of your VECM model are stationary. This is supported across all types of the ADF test (no drift no trend, with drift no trend, and with drift and trend) and various lag orders. The consistent rejection of the null hypothesis with significant p-values ( 0.01) confirms that the residuals do not exhibit a unit root and are therefore stationary.

###### KPSS test
```{r}
# KPSS test
residuals(S_vecm_1)[,3]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(S_vecm_1)[,3]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(S_vecm_1)[,3]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

Test statistic < Critical values: The test statistic (0.1426) is less than the critical values at all commonly used significance levels (10%, 5%, 2.5%, 1%). Therefore, we fail to reject the null hypothesis. This means there is not enough evidence to suggest that the residuals are non-stationary.

The results of the KPSS test indicate that the test statistic is 0.1426, which is much lower than the critical values for all significance levels. Thus, we fail to reject the null hypothesis that the residuals of the third component of your VECM model are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis.

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(S_vecm_1)[, 3]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- S_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(S_vecm_1)[,3], lags = 12)
print(arch_test)


```
Breusch-Pagan Test: p-value > 0.05: Since the p-value is greater than 0.05, we fail to reject the null hypothesis. This means there is not enough evidence to suggest that the residuals exhibit heteroscedasticity. Therefore, the residuals can be considered to have constant variance (homoscedastic).

ARCH Test: p-value > 0.05: Since the p-value is greater than 0.05, we fail to reject the null hypothesis.This means there is not enough evidence to suggest the presence of ARCH effects in the residuals. Therefore, the residuals do not exhibit time-varying volatility and can be considered homoscedastic.

##### d. S_sales_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(S_vecm_1)[,4], main = "Residuals of S_sales_ts_train")
```
- The residuals of the time series model generally behave as expected, with most residuals oscillating around zero and minimal autocorrelation indicated by the ACF and PACF plots.

- The significant spike around the 50th time point suggests an outlier or an unusual observation that might need further investigation.

```{r}
checkresiduals(residuals(S_vecm_1)[,4])
```
- Ljung-Box test: The p-value is 0.931, which is greater than the typical significance level of 0.05.Therefore, you do not reject the null hypothesis.This means there is no significant autocorrelation in the residuals at the 5% significance level.

- The histogram of residuals shows a roughly normal distribution, with a few outliers that might need to be addressed.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(S_vecm_1)[,4])
```

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(S_vecm_1)[,4], main="Q-Q Plot of Residuals")
qqline(residuals(S_vecm_1)[,4], col = "red")
grid()
```
The residuals are mostly normally distributed, but the presence of outliers suggests potential issues that might require further examination or model refinement.

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(S_vecm_1)[,4]) 

adf.test(residuals(S_vecm_1)[,4])
```

###### KPSS test
```{r}
# KPSS test
residuals(S_vecm_1)[,4]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(S_vecm_1)[,4]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(S_vecm_1)[,4]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(S_vecm_1)[, 4]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- S_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(S_vecm_1)[,4], lags = 12)
print(arch_test)
```

#### Model 2: Composite search terms/queries

##### a. ts_S_sii_train

```{r}
# Residual of SII
ggtsdisplay(residuals(S_vecm_2)[,1], main = "Residuals of ts_S_sii_train")
```

- The residuals of the time series model show significant fluctuations at the beginning but generally stabilize around zero.

- The ACF and PACF plots indicate that most of the autocorrelation has been captured by the model, though there are some spikes suggesting potential periodicity or seasonality not fully addressed.

```{r}
checkresiduals(residuals(S_vecm_2)[,1])
```
- Ljung-Box test: The p-value is 0.918, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis.This means there is no significant autocorrelation in the residuals at the 5% significance level.

- The histogram shows that the residuals follow a roughly normal distribution, but with some outliers.

- These diagnostic plots indicate that while the model fits the data reasonably well, there might be some room for improvement, particularly in handling the initial fluctuations and any periodic components suggested by the ACF plot.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(S_vecm_2)[,1])
```

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(S_vecm_2)[,1], main="Q-Q Plot of Residuals")
qqline(residuals(S_vecm_2)[,1], col = "red")
grid()
```

The residuals are mostly normally distributed in the central range, but the presence of outliers at both ends suggests potential issues that might require further examination or model refinement to handle these extreme values better.

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(S_vecm_2)[,1]) 

adf.test(residuals(S_vecm_2)[,1])
```
In all three types (no drift no trend, with drift no trend, and with drift and trend), the p-values for the ADF test are less than or equal to 0.01. This indicates that we reject the null hypothesis of a unit root at the 1% significance level for all lags considered.

The negative values of the ADF statistics (which are all significantly lower than the critical values typically used in ADF tests) also support the rejection of the null hypothesis.

###### KPSS test
```{r}
# KPSS test

residuals(S_vecm_2)[,1]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(S_vecm_2)[,1]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(S_vecm_2)[,1]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

Initial KPSS Test: For all types (no drift no trend, with drift no trend, with drift and trend), the p-values are 0.1, which is greater than the typical significance levels (0.01, 0.05). This means we fail to reject the null hypothesis of stationarity. In other words, the residuals do not show significant evidence of non-stationarity based on these tests.

KPSS Test with Schwert's Criterion:

The test statistic is 0.1121.
The critical value at the 10% significance level is 0.0713. Since 0.0713 < 0.347, we fail to reject the null hypothesis of stationarity.

--> The KPSS test results, including the one performed using Schwert's criterion, consistently indicate that the residuals of S_vecm_1 are stationary. 

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(S_vecm_2)[, 1]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- S_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(S_vecm_2)[,1], lags = 12)
print(arch_test)
```

##### b. S_sales_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(S_vecm_2)[,2], main = "Residuals of S_sales_ts_train")
```

- The residuals of the time series model show significant fluctuations and spikes at certain points, suggesting potential outliers or unusual observations.

- The ACF and PACF plots indicate that there is some autocorrelation present in the residuals, suggesting that the model has not fully captured all the autocorrelation in the data.


```{r}

checkresiduals(residuals(S_vecm_2)[,2])
```
- The p-value is 0.6151, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.

- The histogram shows that the residuals follow a roughly normal distribution, but with some outliers.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(S_vecm_2)[,2])
```

In your case, the p-value is 0.002069, which is less than 0.05. Therefore, you reject the null hypothesis that the residuals of UK_vecm_1[,2] are normally distributed. This result indicates that there is significant evidence to suggest that the residuals do not follow a normal distribution.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(S_vecm_2)[,2], main="Q-Q Plot of Residuals")
qqline(residuals(S_vecm_2)[,2], col = "red")
grid()
```
The residuals are mostly normally distributed in the central range, but the presence of outliers at both ends suggests potential issues that might require further examination or model refinement to handle these extreme values better. The significant deviations at the tails indicate that the residuals do not completely follow a normal distribution, which might impact the performance of the model.

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(S_vecm_2)[,2]) 

adf.test(residuals(S_vecm_2)[,2])

```

###### KPSS test
```{r}
# KPSS test
residuals(S_vecm_2)[,2]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(S_vecm_2)[,2]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(S_vecm_2)[,2]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```
The result of the KPSS test indicates that the test statistic is 0.0616, which is much lower than the critical values for all significance levels. Therefore, you fail to reject the null hypothesis that the residuals of UK_vecm_1[,2] are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis


###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(S_vecm_2)[, 2]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- S_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(S_vecm_2)[,2], lags = 12)
print(arch_test)

```


### 4.9.4. Forecast with VECM model

#### Model 1 

```{r}

S_forecast.vecm_1 <- predict(S_vecm_1, n.ahead = 12) # Forecast 12 months ahead

S_ts_forecast.vecm_1 <- ts(S_forecast.vecm_1[,"S_sales_ts_train"], frequency = S_frequency, start = S_start_forecast)

print (S_ts_forecast.vecm_1)

#Plot 

plot(S_sales_ts_test, main = "VECM", xlab = "Time", ylab = "Values", lwd=2) 
lines(S_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)

print(S_sales_ts_test)
```

```{r}

plot(S_sales_ts_pre, main = "VECM", xlab = "Time", ylab = "Values", lwd=2)
lines(S_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)
```

#### Evaluation metrics
```{r}

# Calculate MAPE 
round(MLmetrics::MAPE(S_ts_forecast.vecm_1,S_sales_ts_test)*100,2)

# Calculate MAE
mae <- mean(abs(S_ts_forecast.vecm_1 - S_sales_ts_test))
print(paste("MAE:", round(mae, 2)))

# Calculate MAE in percentage
mae_percentage <- (mae / mean(S_sales_ts_test)) * 100
print(paste("MAE as a percentage:", round(mae_percentage, 2), "%"))

# Calculate MPE
mpe <- mean((S_ts_forecast.vecm_1 - S_sales_ts_test) / S_sales_ts_test) * 100
print(round(mpe, 2))

# Calculate RMSE
rmse <- sqrt(mean((S_ts_forecast.vecm_1 - S_sales_ts_test)^2))
print(paste("RMSE:", round(rmse, 2)))

# Calculate R-squared
r_squared_model_1 <- r_squared(S_sales_ts_test, S_ts_forecast.vecm_1)
print(paste("R-squared for Model 1:", round(r_squared_model_1, 4)))

```

```{r}
# Save result 
vecm_S_forecast_model_1 <- S_ts_forecast.vecm_1
```

#### Model 2 

```{r}

S_forecast.vecm_2 <- predict(S_vecm_2, n.ahead = 12) # Forecast 12 months ahead

S_ts_forecast.vecm_2 <- ts(S_forecast.vecm_2[,"S_sales_ts_train"], frequency = S_frequency, start = S_start_forecast)

print (S_ts_forecast.vecm_2)

#Plot 

plot(S_sales_ts_test, main = "VECM", xlab = "Time", ylab = "Values", lwd=2) 
lines(S_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)

print(S_sales_ts_test)
```

```{r}

plot(S_sales_ts, main = "VECM", xlab = "Time", ylab = "Values", lwd=2)
lines(S_ts_forecast.vecm_2, col = "red",lty = "dashed", lwd = 2)
```

#### Evaluation metrics
```{r}

# Calculate MAPE 
round(MLmetrics::MAPE(S_ts_forecast.vecm_2,S_sales_ts_test)*100,2)

# Calculate MAE
mae <- mean(abs(S_ts_forecast.vecm_2 - S_sales_ts_test))
print(paste("MAE:", round(mae, 2)))

# Calculate MAE in percentage
mae_percentage <- (mae / mean(S_sales_ts_test)) * 100
print(paste("MAE as a percentage:", round(mae_percentage, 2), "%"))

# Calculate MPE
mpe <- mean((S_ts_forecast.vecm_2 - S_sales_ts_test) / S_sales_ts_test) * 100
print(round(mpe, 2))

# Calculate RMSE
rmse <- sqrt(mean((S_ts_forecast.vecm_2 - S_sales_ts_test)^2))
print(paste("RMSE:", round(rmse, 2)))

# Calculate R-squared
r_squared_model_2 <- r_squared(S_sales_ts_test, S_ts_forecast.vecm_2)
print(paste("R-squared for Model 1:", round(r_squared_model_1, 4)))

```

```{r}
# Save result 
vecm_S_forecast_model_2 <- S_ts_forecast.vecm_2
```

## 4.10. VECM for Wales series
### Correlation matrix
```{r}
print(colnames(W_data))

W_independent_vars <- W_data[, c("W_sale_vol", "W_REA", "W_RPL", "W_HF", "W_HD")]

# Select only numeric columns for correlation analysis
W_data_cor <- W_independent_vars %>%
  select_if(is.numeric)

# Compute the correlation matrix
W_cor_matrix <- cor(W_data_cor, use = "complete.obs")

# Print the correlation matrix
print("Correlation Matrix:")
print(W_cor_matrix )

```

```{r}

# Visualize the correlation matrix using ggcorrplot
ggcorrplot(W_cor_matrix , 
           method = "circle", 
           type = "lower", 
           lab = TRUE, 
           title = "Correlation Matrix")

```


### VIF

```{r}

missing_summary <- sapply(W_data, function(x) sum(is.na(x)))
print("Summary of Missing Values:")
print(missing_summary)

```


```{r}

# Conduct multiple regression

W_reg_model <- lm(W_sale_vol~W_REA+W_RPL+ W_HF +W_HD , data=W_data)

# Print the result of multiple regression 
summary(W_reg_model)

# Calculate VIF for the independent variables
vif(W_reg_model)

```


### 4.10.1. Data preparation for VECM model

```{r}
# Convert data into Time Series (frequency = 12 for monthly data)
W_sales_ts <- ts(W_data$W_sale_vol, frequency = 12, start = c(2005, 1))

W_REA_ts <- ts(W_data$W_REA, frequency = 12, start = c(2005, 1))

W_RPL_ts <- ts(W_data$W_RPL, frequency = 12, start = c(2005, 1))

W_HF_ts <- ts(W_data$W_HF, frequency = 12, start = c(2005, 1))

W_HD_ts <- ts(W_data$W_HD, frequency = 12, start = c(2005, 1))

```

### Plot all the time series + ADF/KPSS test

### a. W_sales_ts
```{r}

ggtsdisplay(W_sales_ts, lag.max = 40, main = "Time Series, ACF and PACF of W_sales_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(W_sales_ts) 

adf.test(W_sales_ts)

# KPSS test

W_sales_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_W_sales_ts <- floor(12 * (length(W_sales_ts) / 100)^(1/4))
print(use_lag_W_sales_ts)

# Perform KPSS Test with the Chosen Lag
W_sales_ts%>% ur.kpss(use.lag = use_lag_W_sales_ts) %>% summary()

```
Conclusion: The W_sales_ts series exhibits mixed stationarity properties:

- Non-stationary overall according to the ADF test.
- Stationary with drift according to the KPSS test with Type 2.
- Non-stationary in other configurations according to the KPSS test.
--> Non-stationary


### b. W_REA_ts
```{r}

ggtsdisplay(W_REA_ts, lag.max = 40, main = "Time Series, ACF and PACF of W_REA_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(W_REA_ts) 

adf.test(W_REA_ts)

# KPSS test

W_REA_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_W_REA_ts <- floor(12 * (length(W_REA_ts) / 100)^(1/4))
print(use_lag_W_REA_ts)

# Perform KPSS Test with the Chosen Lag
W_REA_ts%>% ur.kpss(use.lag = use_lag_W_REA_ts) %>% summary()

```

ADF Test: Indicates that the W_REA_ts series is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
Type 1: The series is stationary.
Type 2: The series is borderline non-stationary with drift.
Type 3: The series is non-stationary with drift and trend.

KPSS Test (Schwert's Criterion): Indicates that the series is non-stationary.

--> Non-stationary


### c. W_RPL_ts
```{r}

ggtsdisplay(W_RPL_ts, lag.max = 40, main = "Time Series, ACF and PACF of W_RPL_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(W_RPL_ts) 

adf.test(W_RPL_ts)

# KPSS test

W_RPL_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_W_RPL_ts <- floor(12 * (length(W_RPL_ts) / 100)^(1/4))
print(use_lag_W_RPL_ts)

# Perform KPSS Test with the Chosen Lag
W_RPL_ts%>% ur.kpss(use.lag = use_lag_W_RPL_ts) %>% summary()

```

ADF Test: Indicates that the S_RPL_ts series is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
- Type 1: The series is stationary.
- Type 2 and Type 3: The series is non-stationary with drift and trend.

KPSS Test (Schwert's Criterion): Indicates mixed results:

At the 10% and 5% significance levels, the series is non-stationary.

At the 2.5% and 1% significance levels, the series is stationary.

--> Non-stationary

### d. W_HF_ts
```{r}

ggtsdisplay(W_HF_ts, lag.max = 40, main = "Time Series, ACF and PACF of W_HF_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(W_HF_ts) 

adf.test(W_HF_ts)

# KPSS test

W_HF_ts%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_W_HF_ts <- floor(12 * (length(W_HF_ts) / 100)^(1/4))
print(use_lag_W_HF_ts)

# Perform KPSS Test with the Chosen Lag
W_HF_ts%>% ur.kpss(use.lag = use_lag_W_HF_ts) %>% summary()

```
The ADF test suggests that the series W_HF_ts is non-stationary overall.

KPSS Test (Initial): Indicates mixed results:
- Type 1: The series is stationary.
- Type 2 and Type 3: The series is non-stationary with drift and trend.
The initial KPSS test suggests stationarity in some configurations but non-stationarity with drift and trend.

KPSS Test (Schwert's Criterion): Indicates that the series is non-stationary.

--> non-stationary.

### e. ts_W_sii

```{r}

ggtsdisplay(ts_W_sii, lag.max = 40, main = "Time Series, ACF and PACF of W_HD_ts")

# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(ts_W_sii) 

adf.test(ts_W_sii)

# KPSS test

ts_W_sii%>% kpss.test()


# Apply Schwert's criterion to determine the optimal lag length.
use_lag_ts_W_sii <- floor(12 * (length(ts_W_sii) / 100)^(1/4))
print(use_lag_ts_W_sii)

# Perform KPSS Test with the Chosen Lag
ts_W_sii%>% ur.kpss(use.lag = use_lag_ts_W_sii) %>% summary()

```


### Split train and test set for VECM model

### Training data from Jan 2005 to Feb 2020

#### a. W_sales_ts
```{r}

# Split the W_sales_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
W_sales_ts_train <- window(W_sales_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
W_sales_ts_test <- window(W_sales_ts, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the training time series
str(W_sales_ts_train)

# Check the structure of the testing time series
str(W_sales_ts_test)

# Print the training time series data to verify the split
print(W_sales_ts_train)

# Print the testing time series data to verify the split
print(W_sales_ts_test)

```

#### b. W_REA_ts
```{r}
# Split the W_REA_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
W_REA_ts_train <- window(W_REA_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
W_REA_ts_test <- window(W_REA_ts, start = c(2019, 3), end = c(2020, 2))

# Check the structure of the training time series
str(W_REA_ts_train)

# Check the structure of the testing time series
str(W_REA_ts_test)

# Print the training time series data to verify the split
print(W_REA_ts_train)

# Print the testing time series data to verify the split
print(W_REA_ts_test)
```

#### c. W_RPL_ts
```{r}
# Split the W_RPL_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
W_RPL_ts_train <- window(W_RPL_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
W_RPL_ts_test <- window(W_RPL_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(W_RPL_ts_train)
str(W_RPL_ts_test)

# Print the time series data
print(W_RPL_ts_train)
print(W_RPL_ts_test)

```

#### d. W_HF_ts
```{r}

# Split the W_HF_ts time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019

W_HF_ts_train <- window(W_HF_ts, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
W_HF_ts_test <- window(W_HF_ts, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(W_HF_ts_train)
str(W_HF_ts_test)

# Print the time series data
print(W_HF_ts_train)
print(W_HF_ts_test)

```

#### e. ts_W_sii

```{r}
# Split the ts_W_sii time series into training and testing datasets

# Training data from Jan 2005 to Feb 2019
ts_W_sii_train <- window(ts_W_sii, start = c(2005, 1), end = c(2019, 2))

# Test data from Mar 2019 to Feb 2020
ts_W_sii_test <- window(ts_W_sii, start = c(2019, 3), end = c(2020,2))

# Check the structure of the time series
str(ts_W_sii_train)
str(ts_W_sii_test)

# Print the time series data
print(ts_W_sii_train)
print(ts_W_sii_test)

```

### Define period

```{r}
W_frequency <- frequency (W_sales_ts_train)
W_start <- start (W_sales_ts_train)
W_end <- end (W_sales_ts_train)
W_start_forecast <- c(W_end[1],W_end[2] + 1)

print (W_frequency)
print (W_start)
print (W_end)
print (W_start_forecast)
```

### Create VECM input

```{r}
# Model 1: Use search subcategories
W_vecm_in_1 <- cbind (W_REA_ts_train, W_RPL_ts_train, W_HF_ts_train, W_sales_ts_train)

# Model 2: Use composite search terms/queries
W_vecm_in_2 <- cbind (ts_W_sii_train,W_sales_ts_train)

```

### 4.10.2. VECM Model Building

```{r}
# Select lags based in differenced data
(W_vecm_lagselect_1 <- VARselect (W_vecm_in_1, lag.max=12, type = "trend" ))
(W_vecm_lagselect_2 <- VARselect (W_vecm_in_2, lag.max=12, type = "trend" ))

```

### Choose lags
```{r}
(W_vecm_max_lag_1 <-W_vecm_lagselect_1$selection[1])

(W_vecm_max_lag_2 <-W_vecm_lagselect_2$selection[1])
```

### Apply Johansen's Cointegration Test

#### Model 1
```{r}
# Co-integration test

W_johansen_test_1 <- ca.jo(W_vecm_in_1, type = "trace", ecdet = "trend", K = W_vecm_max_lag_1, spec = "transitory", season = 12)

summary(W_johansen_test_1)
```

From r=0 to r <=6: The test statistic (51.27) is greater than the 5% critical value (42.44), so we reject the null hypothesis of at most six co-integrating vectors (r  6).

Test r <=7:The test statistic (24.29) is less than the 5% critical value (25.32), so we do not reject the null hypothesis of at most seven co-integrating vectors (r  7).

--> Based on the test statistics and critical values, we can conclude that there are 7 co-integrating relationships (since r7 is not rejected) among the variables in the system.

--> there are 1 co-integrating relationships

#### Model 2
```{r}
# Co-integration test

W_johansen_test_2 <- ca.jo(W_vecm_in_2, type = "trace", ecdet = "trend", K = W_vecm_max_lag_2, spec = "transitory", season = 12)

summary(W_johansen_test_2)
```

--> This suggests there is 1 cointegrating vector.

### Fit VECM

#### Model 1
```{r}

W_vecm_1 <- VECM (W_vecm_in_1, r=1, lag= W_vecm_max_lag_1-1, estim= "ML", include ="trend")
options(max.print = 10000) # Increase this number as needed

summary (W_vecm_1)
```

#### Model 2

```{r}

W_vecm_2 <- VECM (W_vecm_in_2, r=1, lag= W_vecm_max_lag_2, estim= "ML", include ="trend")
options(max.print = 10000) # Increase this number as needed
summary (W_vecm_2)

```

### 4.10.3. Residuals Diagnostics
#### Model 1: Search sub-categories

##### a. W_REA_ts_train

```{r}
ggtsdisplay(residuals(W_vecm_1)[,1], main = "Residuals of W_REA_ts_train")
```

- The residuals of the time series model show significant fluctuations and spikes at certain points, suggesting potential outliers or unusual observations.

- The ACF and PACF plots indicate that there is some autocorrelation present in the residuals, suggesting that the model has not fully captured all the autocorrelation in the data.

```{r}

checkresiduals(residuals(W_vecm_1)[,1])
```
- Ljung-Box test: The p-value is 0.8577, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.

- The histogram shows that the residuals follow a roughly normal distribution, but with some outliers.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(W_vecm_1)[,1])
```

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(W_vecm_1)[,1], main="Q-Q Plot of Residuals")
qqline(residuals(W_vecm_1)[,1], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(W_vecm_1)[,1]) 

adf.test(residuals(W_vecm_1)[,1])

```

###### KPSS test
```{r}
# KPSS test
residuals(W_vecm_1)[,1]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(W_vecm_1)[,1]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(W_vecm_1)[,1]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(W_vecm_1)[, 1]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- W_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(W_vecm_1)[,1], lags = 12)
print(arch_test)
```

##### b. W_RPL_ts_train 

```{r}
# Residual of SII
ggtsdisplay(residuals(W_vecm_1)[,2], main = "Residuals of W_RPL_ts_train")
```
- The residuals of the time series model show significant fluctuations and spikes at certain points, suggesting potential outliers or unusual observations.

- The ACF and PACF plots indicate that there is some autocorrelation present in the residuals, suggesting that the model has not fully captured all the autocorrelation in the data.

```{r}
checkresiduals(residuals(W_vecm_1)[,2])
```
- The p-value is 0.3452, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.

- The histogram shows that the residuals follow a roughly normal distribution, but with some outliers.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(W_vecm_1)[,2])
```

In your case, the p-value is 0.009069, which is less than 0.05. Therefore, you reject the null hypothesis that the residuals of UK_vecm_1[,2] are normally distributed. This result indicates that there is significant evidence to suggest that the residuals do not follow a normal distribution.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(W_vecm_1)[,2], main="Q-Q Plot of Residuals")
qqline(residuals(W_vecm_1)[,2], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(W_vecm_1)[,2]) 

adf.test(residuals(W_vecm_1)[,2])

```

###### KPSS test
```{r}
# KPSS test
residuals(W_vecm_1)[,2]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(W_vecm_1)[,2]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(W_vecm_1)[,2]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```
The result of the KPSS test indicates that the test statistic is 0.0719, which is much lower than the critical values for all significance levels. Therefore, you fail to reject the null hypothesis that the residuals of UK_vecm_1[,2] are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis

###### Test of Heteroscedasticity check

```{r}

### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(W_vecm_1)[, 2]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- W_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(W_vecm_1)[,2], lags = 12)
print(arch_test)

```
- Breusch-Pagan Test: Since the p-value is less than 0.05, we reject the null hypothesis.This means there is enough evidence to suggest that the residuals exhibit heteroscedasticity.Therefore, the residuals can be considered to not have constant variance.

- ARCH Test: Since the p-value is greater than 0.05, we fail to reject the null hypothesis. This means there is not enough evidence to suggest the presence of ARCH effects in the residuals. Therefore, the residuals do not exhibit time-varying volatility and can be considered homoscedastic.


##### c. W_HF_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(W_vecm_1)[,3], main = "Residuals of W_HF_ts_train")
```
- The residuals of the time series model show significant fluctuations and spikes at certain points, suggesting potential outliers or unusual observations.

- The ACF and PACF plots indicate that there is some autocorrelation present in the residuals, suggesting that the model has not fully captured all the autocorrelation in the data.n

```{r}

checkresiduals(residuals(W_vecm_1)[,3])
```
- The histogram shows that the residuals follow a roughly normal distribution, but with some outliers.

- Ljung-Box test: Since the p-value (0.4963) is greater than 0.05, we fail to reject the null hypothesis that the residuals are independently distributed.This indicates that there is no significant evidence of autocorrelation in the residuals of the third component of your VECM model, suggesting that the residuals are adequately modeled as white noise.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(W_vecm_1)[,3])
```

--> Not Normally distributed (p-value < 0.05)

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(W_vecm_1)[,3], main="Q-Q Plot of Residuals")
qqline(residuals(W_vecm_1)[,3], col = "red")
grid()
```
The residuals are mostly normally distributed in the central range, but the presence of outliers at the upper end suggests potential issues that might require further examination or model refinement to handle these extreme values better. The significant deviation at the upper tail indicates that the residuals do not completely follow a normal distribution, which might impact the performance of the model.

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(W_vecm_1)[,3]) 

adf.test(residuals(W_vecm_1)[,3])
```
p-value  0.05: The p-value in all cases is 0.01, which is less than the typical significance level of 0.05. This means we reject the null hypothesis that the residuals have a unit root.

Negative ADF statistics: The ADF statistics are significantly negative, which further supports the rejection of the null hypothesis.

The results of the Augmented Dickey-Fuller test indicate that the residuals of the third component of your VECM model are stationary. This is supported across all types of the ADF test (no drift no trend, with drift no trend, and with drift and trend) and various lag orders. The consistent rejection of the null hypothesis with significant p-values ( 0.01) confirms that the residuals do not exhibit a unit root and are therefore stationary.

###### KPSS test
```{r}
# KPSS test
residuals(W_vecm_1)[,3]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(W_vecm_1)[,3]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(W_vecm_1)[,3]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

Test statistic < Critical values: The test statistic (0.1061) is less than the critical values at all commonly used significance levels (10%, 5%, 2.5%, 1%). Therefore, we fail to reject the null hypothesis. This means there is not enough evidence to suggest that the residuals are non-stationary.

The results of the KPSS test indicate that the test statistic is 0.1061, which is much lower than the critical values for all significance levels. Thus, we fail to reject the null hypothesis that the residuals of the third component of your VECM model are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis.

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(W_vecm_1)[, 3]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- W_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(W_vecm_1)[,3], lags = 12)
print(arch_test)


```
Breusch-Pagan Test: p-value > 0.05: Since the p-value is greater than 0.05, we fail to reject the null hypothesis. This means there is not enough evidence to suggest that the residuals exhibit heteroscedasticity. Therefore, the residuals can be considered to have constant variance (homoscedastic).

ARCH Test: p-value > 0.05: Since the p-value is greater than 0.05, we fail to reject the null hypothesis.This means there is not enough evidence to suggest the presence of ARCH effects in the residuals. Therefore, the residuals do not exhibit time-varying volatility and can be considered homoscedastic.

##### d. W_sales_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(W_vecm_1)[,4], main = "Residuals of W_sales_ts_train")
```
- The residuals of the time series model show significant fluctuations and spikes at certain points, suggesting potential outliers or unusual observations.

- The ACF and PACF plots indicate that there is some autocorrelation present in the residuals, suggesting that the model has not fully captured all the autocorrelation in the data.

```{r}
checkresiduals(residuals(W_vecm_1)[,4])
```
- Ljung-Box test: The p-value is 0.7082, which is greater than the typical significance level of 0.05.Therefore, you do not reject the null hypothesis.This means there is no significant autocorrelation in the residuals at the 5% significance level.

- The histogram shows that the residuals follow a roughly normal distribution, but with some outliers.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(W_vecm_1)[,4])
```

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(W_vecm_1)[,4], main="Q-Q Plot of Residuals")
qqline(residuals(W_vecm_1)[,4], col = "red")
grid()
```
The residuals are mostly normally distributed in the central range, but the presence of outliers at both ends suggests potential issues that might require further examination or model refinement to handle these extreme values better. The significant deviation at the tails indicates that the residuals do not completely follow a normal distribution, which might impact the performance of the model.


###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(W_vecm_1)[,4]) 

adf.test(residuals(W_vecm_1)[,4])

```

###### KPSS test
```{r}
# KPSS test
residuals(W_vecm_1)[,4]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(W_vecm_1)[,4]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(W_vecm_1)[,4]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(W_vecm_1)[, 4]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- W_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(W_vecm_1)[,4], lags = 12)
print(arch_test)

```

#### Model 2: Composite search terms/queries


```{r}
# Plot Residuals vs. Fitted Values for Model 2
residuals_vecm_2 <- residuals(W_vecm_2)
fitted_values_vecm_2 <- W_sales_ts_train[1:length(residuals_vecm_2)] - residuals_vecm_2

# Create the Residuals vs. Fitted plot
plot(fitted_values_vecm_2, residuals_vecm_2, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Residuals vs. Fitted Values for W_VECM Model 2",
     pch = 20, 
     col = "blue")

# Add a horizontal line at 0
abline(h = 0, col = "red", lty = 2)

# Add a grid for better visualization
grid()

```

##### a. ts_W_sii_train

```{r}
# Residual of SII
ggtsdisplay(residuals(W_vecm_2)[,1], main = "Residuals of ts_W_sii_train")
```
- The residuals of the time series model show significant fluctuations and spikes at certain points, suggesting potential outliers or unusual observations.

- The ACF and PACF plots indicate that there is some autocorrelation present in the residuals, suggesting that the model has not fully captured all the autocorrelation in the data.

```{r}
checkresiduals(residuals(UK_vecm_2)[,1])
```
- Ljung-Box test: The p-value is 0.7277, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis.This means there is no significant autocorrelation in the residuals at the 5% significance level.

- The histogram shows that the residuals follow a roughly normal distribution, but with some outliers.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(W_vecm_2)[,1])
```

In your case, the p-value is 0.8523, which is much greater than 0.05. Therefore, you fail to reject the null hypothesis. This result indicates that there is no significant evidence to suggest that the residuals of UK_vecm_1 are not normally distributed.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(W_vecm_2)[,1], main="Q-Q Plot of Residuals")
qqline(residuals(W_vecm_2)[,1], col = "red")
grid()
```
The residuals are mostly normally distributed in the central range, but the presence of outliers at both ends suggests potential issues that might require further examination or model refinement to handle these extreme values better. The significant deviation at the tails indicates that the residuals do not completely follow a normal distribution, which might impact the performance of the model.

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(W_vecm_2)[,1]) 

adf.test(residuals(W_vecm_2)[,1])
```
In all three types (no drift no trend, with drift no trend, and with drift and trend), the p-values for the ADF test are less than or equal to 0.01. This indicates that we reject the null hypothesis of a unit root at the 1% significance level for all lags considered.
The negative values of the ADF statistics (which are all significantly lower than the critical values typically used in ADF tests) also support the rejection of the null hypothesis.

###### KPSS test
```{r}
# KPSS test

residuals(W_vecm_2)[,1]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(W_vecm_2)[,1]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(W_vecm_2)[,1]%>% ur.kpss(use.lag = use_lag_r) %>% summary()
```

Initial KPSS Test: For all types (no drift no trend, with drift no trend, with drift and trend), the p-values are 0.1, which is greater than the typical significance levels (0.01, 0.05). This means we fail to reject the null hypothesis of stationarity. In other words, the residuals do not show significant evidence of non-stationarity based on these tests.

KPSS Test with Schwert's Criterion:

The test statistic is 0.1121.
The critical value at the 10% significance level is 0.347. Since 0.1121 < 0.347, we fail to reject the null hypothesis of stationarity.

--> The KPSS test results, including the one performed using Schwert's criterion, consistently indicate that the residuals of UK_vecm_1 are stationary. 

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(W_vecm_2)[, 1]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- W_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(W_vecm_2)[,1], lags = 12)
print(arch_test)

```

ARCH test
The result of the ARCH LM test indicates that the p-value is 0.00001224, which is much less than 0.05. Therefore, you reject the null hypothes is that there are no ARCH effects in the residuals of UK_vecm_1. This suggests that the residuals exhibit time-varying volatility, and they are heteroscedastic

Breusch-Pagan test 
The result of the Breusch-Pagan test indicates that the p-value is 0.8947, which is greater than 0.05. Therefore, you fail to reject the null hypothesis that the variance of the residuals is constant. This suggests that the residuals of your VECM model do not exhibit heteroscedasticity, supporting the assumption of homoscedasticity in your model.

##### b. W_sales_ts_train

```{r}
# Residual of SII
ggtsdisplay(residuals(W_vecm_2)[,2], main = "Residuals of W_sales_ts_train")
```
- The residuals of the time series model show significant fluctuations and spikes at certain points, suggesting potential outliers or unusual observations.

- The ACF and PACF plots indicate that there is some autocorrelation present in the residuals, suggesting that the model has not fully captured all the autocorrelation in the data.

```{r}
checkresiduals(residuals(W_vecm_2)[,2])
```
- Ljung-Box test: The p-value is 0.9719, which is greater than the typical significance level of 0.05. Therefore, you do not reject the null hypothesis. This means there is no significant autocorrelation in the residuals at the 5% significance level.

- The histogram shows that the residuals follow a roughly normal distribution, but with some outliers.

###### Normality

```{r}
# Shapiro-Wilk test for normality
shapiro.test(residuals(W_vecm_2)[,2])
```

In your case, the p-value is 0.000000007942, which is less than 0.05. Therefore, you reject the null hypothesis that the residuals of UK_vecm_1[,2] are normally distributed. This result indicates that there is significant evidence to suggest that the residuals do not follow a normal distribution.

```{r}
# Plotting QQ plot for normality check
par(mfrow=c(1,1))
qqnorm(residuals(W_vecm_2)[,2], main="Q-Q Plot of Residuals")
qqline(residuals(W_vecm_2)[,2], col = "red")
grid()
```

###### ADF test
```{r}
# Perform Augmented Dickey-Fuller (ADF) test
tseries::adf.test(residuals(W_vecm_2)[,2]) 

adf.test(residuals(W_vecm_2)[,2])
```

###### KPSS test
```{r}
# KPSS test
residuals(W_vecm_2)[,2]%>% kpss.test()

# Apply Schwert's criterion to determine the optimal lag length.
use_lag_r<- floor(12 * (length(residuals(W_vecm_2)[,2]) / 100)^(1/4))
print(use_lag_r)

# Perform KPSS Test with the Chosen Lag
residuals(W_vecm_2)[,2]%>% ur.kpss(use.lag = use_lag_r) %>% summary()

```
The result of the KPSS test indicates that the test statistic is 0.0387, which is much lower than the critical values for all significance levels. Therefore, you fail to reject the null hypothesis that the residuals of UK_vecm_1[,2] are stationary. This suggests that the residuals do not have a unit root and are stationary, which is a desirable property in time series analysis

###### Test of Heteroscedasticity check

```{r}
### Breusch-Pagan test

# Extract the residuals from the VECM model
residuals_vecm <- residuals(W_vecm_2)[, 2]

# Calculate the fitted values manually (original values minus residuals)
fitted_values_vecm <- W_sales_ts_train[1:length(residuals_vecm)] - residuals_vecm

# Perform Breusch-Pagan test
bptest_result <- bptest(residuals_vecm ~ fitted_values_vecm)

# Print the result of the Breusch-Pagan test
print(bptest_result)

# Perform ARCH test for heteroscedasticity
arch_test <- ArchTest(residuals(W_vecm_2)[,2], lags = 12)
print(arch_test)

```

### 4.10.4. Forecast with VECM model

#### Model 1 

```{r}

W_forecast.vecm_1 <- predict(W_vecm_1, n.ahead = 12) # Forecast 12 months ahead

W_ts_forecast.vecm_1 <- ts(W_forecast.vecm_1[,"W_sales_ts_train"], frequency = W_frequency, start = W_start_forecast)

print (W_ts_forecast.vecm_1)

#Plot 

plot(W_sales_ts_test, main = "VECM", xlab = "Time", ylab = "Values", lwd=2) 
lines(W_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)

print(W_sales_ts_test)
```

```{r}

plot(W_sales_ts_pre, main = "VECM", xlab = "Time", ylab = "Values", lwd=2)
lines(W_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)
```

#### Evaluation metrics
```{r}
#MAPE 
round(MLmetrics::MAPE(W_ts_forecast.vecm_1, W_sales_ts_test)*100,2)

# Calculate MAE
mae <- mean(abs(W_ts_forecast.vecm_1 - W_sales_ts_test))
print(paste("MAE:", round(mae, 2)))

# Calculate MAE in percentage
mae_percentage <- (mae / mean(W_sales_ts_test)) * 100
print(paste("MAE as a percentage:", round(mae_percentage, 2), "%"))

# Calculate MPE
mpe <- mean((W_ts_forecast.vecm_1 - W_sales_ts_test) / W_sales_ts_test) * 100
print(round(mpe, 2))

# Calculate RMSE
rmse <- sqrt(mean((W_ts_forecast.vecm_1 - W_sales_ts_test)^2))
print(paste("RMSE:", round(rmse, 2)))

# Calculate R-squared
r_squared_model_1 <- r_squared(W_sales_ts_test, W_ts_forecast.vecm_1)
print(paste("R-squared for Model 1:", round(r_squared_model_1, 4)))

```

```{r}
# Save result 
vecm_W_forecast_model_1 <- W_ts_forecast.vecm_1
```

#### Model 2 

```{r}

W_forecast.vecm_2 <- predict(W_vecm_2, n.ahead = 12) # Forecast 12 months ahead

W_ts_forecast.vecm_2 <- ts(W_forecast.vecm_2[,"W_sales_ts_train"], frequency = W_frequency, start = W_start_forecast)

print (W_ts_forecast.vecm_2)

#Plot 

plot(W_sales_ts_test, main = "VECM", xlab = "Time", ylab = "Values", lwd=2) 
lines(W_ts_forecast.vecm_1, col = "red",lty = "dashed", lwd = 2)

print(W_sales_ts_test)
```

```{r}

plot(W_sales_ts_pre, main = "VECM", xlab = "Time", ylab = "Values", lwd=2)
lines(W_ts_forecast.vecm_2, col = "red",lty = "dashed", lwd = 2)
```

#### Evaluation metrics
```{r}

# Calculate MAPE 
round(MLmetrics::MAPE(W_ts_forecast.vecm_2,W_sales_ts_test)*100,2)

# Calculate MAE
mae <- mean(abs(W_ts_forecast.vecm_2 - W_sales_ts_test))
print(paste("MAE:", round(mae, 2)))

# Calculate MAE in percentage
mae_percentage <- (mae / mean(W_sales_ts_test)) * 100
print(paste("MAE as a percentage:", round(mae_percentage, 2), "%"))

# Calculate MPE
mpe <- mean((W_ts_forecast.vecm_2 - W_sales_ts_test) / W_sales_ts_test) * 100
print(round(mpe, 2))

# Calculate RMSE
rmse <- sqrt(mean((W_ts_forecast.vecm_2 - W_sales_ts_test)^2))
print(paste("RMSE:", round(rmse, 2)))

# Calculate R-squared
r_squared_model_2 <- r_squared(W_sales_ts_test, W_ts_forecast.vecm_2)
print(paste("R-squared for Model 1:", round(r_squared_model_2, 4)))

```

```{r}
# Save result 
vecm_W_forecast_model_2 <- W_ts_forecast.vecm_2
```

# 5. Combined Results

```{r}
# Test set
all_test <- UK_sales_ts_test
all_test
```

## 5.1. Regional Forecast comparison

### 5.1.1. UK series
```{r}
# Rename SARIMA aggregate
# UK series
sarima_UK_forecast

```

```{r}
# SARIMA model
df_sarima_UK_forecast <- as.data.frame(sarima_UK_forecast)%>% 
  mutate(month_year = time(sarima_UK_forecast))

names(df_sarima_UK_forecast)[1] <- "forecast" 
names(df_sarima_UK_forecast)[2] <- "upper 95%CI" 
names(df_sarima_UK_forecast)[3] <- "lower 95%CI" 

sarima_UK_forecast_ts <- ts(df_sarima_UK_forecast, start = start(sarima_UK_forecast), frequency = frequency(sarima_UK_forecast))

```

```{r}
# Adjust the ylim to ensure all lines are visible
plot(UK_sales_ts_test, main = "UK univariate & multivariate models", xlab = "Time", ylab = "Sales Volume", ylim = range(c(all_test, sarima_UK_forecast[,1], vecm_UK_forecast_model_1, vecm_UK_forecast_model_2)),lwd=2)

# Make lines thicker using lwd parameter
lines(sarima_UK_forecast[,1], col = "blue", lty = 2, lwd = 1.7) 
lines(vecm_UK_forecast_model_1, col = "gold", lty = 2, lwd = 1.7)
lines(vecm_UK_forecast_model_2, col = "deeppink", lty = 2, lwd = 1.7)

# Adjust legend size and make it clearer
legend("topleft", legend = c("UK Actual", "(1) UK SARIMA", "(6) UK VECM-SSC", "(7) UK VECM-SII"), 
       col = c("black", "blue", "gold", "deeppink"), lty = 1,lwd = 2, cex = 0.7)
```

### 5.1.2. England series
```{r}
# Rename SARIMA aggregate
# UK series
sarima_E_forecast

```

```{r}
# SARIMA model
df_sarima_E_forecast <- as.data.frame(sarima_E_forecast)%>% 
  mutate(month_year = time(sarima_E_forecast))

names(df_sarima_E_forecast)[1] <- "forecast" 
names(df_sarima_E_forecast)[2] <- "upper 95%CI" 
names(df_sarima_E_forecast)[3] <- "lower 95%CI" 

sarima_E_forecast_ts <- ts(df_sarima_E_forecast, start = start(sarima_E_forecast), frequency = frequency(sarima_E_forecast))

```

```{r}
# Adjust the ylim to ensure all lines are visible
plot(E_sales_ts_test, main = "E univariate & multivariate models", xlab = "Time", ylab = "Sales Volume", ylim = range(c(E_sales_ts_test, sarima_E_forecast[,1], vecm_E_forecast_model_1, vecm_E_forecast_model_2)),lwd=2)

# Make lines thicker using lwd parameter
lines(sarima_E_forecast[,1], col = "blue", lty = 2, lwd = 1.7) 
lines(vecm_E_forecast_model_1, col = "gold", lty = 2, lwd = 1.7)
lines(vecm_E_forecast_model_2, col = "deeppink", lty = 2, lwd = 1.7)

# Adjust legend size and make it clearer
legend("topleft", legend = c("E Actual", "(2) E SARIMA", "(8) E VECM-SSC", "(12) E VECM-SII"), 
       col = c("black", "blue", "gold", "deeppink"), lty = 1,lwd = 2, cex = 0.7)
```


### 5.1.3. Northern Ireland series
```{r}
# Rename SARIMA aggregate
# NI series
sarima_NI_forecast

```

```{r}
# SARIMA model
df_sarima_NI_forecast <- as.data.frame(sarima_NI_forecast)%>% 
  mutate(month_year = time(sarima_NI_forecast))

names(df_sarima_NI_forecast)[1] <- "forecast" 
names(df_sarima_NI_forecast)[2] <- "upper 95%CI" 
names(df_sarima_NI_forecast)[3] <- "lower 95%CI" 

sarima_NI_forecast_ts <- ts(df_sarima_NI_forecast, start = start(sarima_NI_forecast), frequency = frequency(sarima_NI_forecast))

```

```{r}
# Adjust the ylim to ensure all lines are visible
plot(NI_sales_ts_test, main = "NI univariate & multivariate models", xlab = "Time", ylab = "Sales Volume", ylim = range(c(NI_sales_ts_test, sarima_NI_forecast[,1], vecm_NI_forecast_model_1, vecm_NI_forecast_model_2)),lwd=2)

# Make lines thicker using lwd parameter
lines(sarima_NI_forecast[,1], col = "blue", lty = 2, lwd = 1.7) 
lines(vecm_NI_forecast_model_1, col = "gold", lty = 2, lwd = 1.7)
lines(vecm_NI_forecast_model_2, col = "deeppink", lty = 2, lwd = 1.7)

# Adjust legend size and make it clearer
legend("topleft", legend = c("NI Actual", "(3) NI SARIMA", "(9) NI VECM-SSC", "(13) NI VECM-SII"), 
       col = c("black", "blue", "gold", "deeppink"), lty = 1,lwd = 2, cex = 0.6)
```


### 5.1.4. Scotland series
```{r}
# Rename SARIMA aggregate
# S series
sarima_S_forecast

```

```{r}
# SARIMA model
df_sarima_S_forecast <- as.data.frame(sarima_S_forecast)%>% 
  mutate(month_year = time(sarima_S_forecast))

names(df_sarima_S_forecast)[1] <- "forecast" 
names(df_sarima_S_forecast)[2] <- "upper 95%CI" 
names(df_sarima_S_forecast)[3] <- "lower 95%CI" 

sarima_S_forecast_ts <- ts(df_sarima_S_forecast, start = start(sarima_S_forecast), frequency = frequency(sarima_S_forecast))

```

```{r}
# Adjust the ylim to ensure all lines are visible
plot(S_sales_ts_test, main = "S univariate & multivariate models", xlab = "Time", ylab = "Sales Volume", ylim = range(c(S_sales_ts_test, sarima_S_forecast[,1], vecm_S_forecast_model_1, vecm_S_forecast_model_2)),lwd=2)

# Make lines thicker using lwd parameter
lines(sarima_S_forecast[,1], col = "blue", lty = 2, lwd = 1.7) 
lines(vecm_S_forecast_model_1, col = "gold", lty = 2, lwd = 1.7)
lines(vecm_S_forecast_model_2, col = "deeppink", lty = 2, lwd = 1.7)

# Adjust legend size and make it clearer
legend("bottomleft", legend = c("S Actual", "(4) S SARIMA", "(10) S VECM-SSC", "(14) S VECM-SII"), 
       col = c("black", "blue", "gold", "deeppink"), lty = 1,lwd = 2, cex = 0.7)
```

### 5.1.5. Wales series
```{r}
# Rename SARIMA aggregate
# W series
sarima_W_forecast

```

```{r}
# SARIMA model
df_sarima_W_forecast <- as.data.frame(sarima_W_forecast)%>% 
  mutate(month_year = time(sarima_W_forecast))

names(df_sarima_W_forecast)[1] <- "forecast" 
names(df_sarima_W_forecast)[2] <- "upper 95%CI" 
names(df_sarima_W_forecast)[3] <- "lower 95%CI" 

sarima_W_forecast_ts <- ts(df_sarima_W_forecast, start = start(sarima_W_forecast), frequency = frequency(sarima_W_forecast))

```

```{r}
# Adjust the ylim to ensure all lines are visible
plot(W_sales_ts_test, main = "W univariate & multivariate models", xlab = "Time", ylab = "Sales Volume", ylim = range(c(W_sales_ts_test, sarima_W_forecast[,1], vecm_W_forecast_model_1, vecm_W_forecast_model_2)),lwd=2)

# Make lines thicker using lwd parameter
lines(sarima_W_forecast[,1], col = "blue", lty = 2, lwd = 1.7) 
lines(vecm_W_forecast_model_1, col = "gold", lty = 2, lwd = 1.7)
lines(vecm_W_forecast_model_2, col = "deeppink", lty = 2, lwd = 1.7)

# Adjust legend size and make it clearer
legend("topleft", legend = c("W Actual", "(5) W SARIMA", "(11) W VECM-SSC", "(15) W VECM-SII"), 
       col = c("black", "blue", "gold", "deeppink"), lty = 1,lwd = 2, cex = 0.72)
```


## 5.2. Hierarchy model
```{r}
# Combined hierarchy

# England series
sarima_E_forecast
#sarima_E_forecast_2

# Northern Ireland series
sarima_NI_forecast
#sarima_NI_forecast_2

# Scotland series
sarima_S_forecast
#sarima_S_forecast_2

# Wales series
sarima_W_forecast
#sarima_W_forecast_2

sarima_all_forecast = sarima_E_forecast+sarima_NI_forecast+sarima_S_forecast+ sarima_W_forecast

df_sarima_all_forecast <- as.data.frame(sarima_all_forecast)%>% 
  mutate(month_year = time(sarima_all_forecast))

names(df_sarima_all_forecast)[1] <- "forecast" 
names(df_sarima_all_forecast)[2] <- "upper 95%CI" 
names(df_sarima_all_forecast)[3] <- "lower 95%CI" 

sarima_all_forecast<- ts(df_sarima_all_forecast, start = start(sarima_all_forecast), frequency = frequency(sarima_all_forecast))


```

```{r}
# Combined VECM - hierarchy 

# Model 1

vecm_all_forecast_1 <- (vecm_E_forecast_model_1+vecm_NI_forecast_model_1+ vecm_S_forecast_model_1+ vecm_W_forecast_model_1) 

df_vecm_all_forecast_1 <- as.data.frame(vecm_all_forecast_1)%>% 
  mutate(month_year = time(vecm_all_forecast_1)) 

names(df_vecm_all_forecast_1)[1] <- "forecast" 

vecm_all_forecast_1<- ts(df_vecm_all_forecast_1, start = start(vecm_all_forecast_1), frequency = frequency(vecm_all_forecast_1))

# Model 2

vecm_all_forecast_2 <- (vecm_E_forecast_model_2+vecm_NI_forecast_model_2+ vecm_S_forecast_model_2+ vecm_W_forecast_model_2) 

df_vecm_all_forecast_2 <- as.data.frame(vecm_all_forecast_2)%>% 
  mutate(month_year = time(vecm_all_forecast_2)) 

names(df_vecm_all_forecast_2)[1] <- "forecast" 

vecm_all_forecast_2 <- ts(df_vecm_all_forecast_2, start = start(vecm_all_forecast_2), frequency = frequency(vecm_all_forecast_2))

```

## SARIMA models
```{r}
# Plot result UK Forecast - Aggregate

plot(all_test, main = "Forecast - Aggregate", xlab = "Time", ylab = "Sales Volume")
lines(sarima_UK_forecast[,1],col = "red",lty = 2) 
lines(sarima_UK_forecast[,2],col = "grey",lty = 3) 
lines(sarima_UK_forecast[,3],col = "grey",lty = 3)

```

```{r}
# Plot result UK Forecast - Hierarchy

plot(all_test, main = "Forecast - Hierarchy", xlab = "Time", ylab = "Sales Volume") 
lines(sarima_all_forecast[,1],col = "blue",lty = 2) 
lines(sarima_all_forecast[,2],col = "grey",lty = 3) 
lines(sarima_all_forecast[,3],col = "grey",lty = 3)

```

# Plot for all models

```{r}
# Determine the range for y-axis to ensure all lines are visible
y_range <- range(c(all_test, sarima_UK_forecast[,1], sarima_all_forecast[,1], 
                   vecm_UK_forecast_model_1, vecm_UK_forecast_model_2, 
                   vecm_all_forecast_1[,1], vecm_all_forecast_2[,1]))

# Plot with adjusted y-axis limits and thicker lines
plot(all_test, main = "All models", xlab = "Time", ylab = "Sales Volume", ylim = y_range, lwd = 2)
lines(sarima_UK_forecast[,1], col = "blue", lty = 2, lwd = 2) 
lines(sarima_all_forecast[,1], col = "coral", lty = 2, lwd = 2) 
lines(vecm_UK_forecast_model_1, col = "gold", lty = 2, lwd = 2)
lines(vecm_UK_forecast_model_2, col = "deeppink", lty = 2, lwd = 2)
lines(vecm_all_forecast_1[,1], col = "turquoise", lty = 2, lwd = 2)
lines(vecm_all_forecast_2[,1], col = "darkolivegreen3", lty = 2, lwd = 2)

# Adjust the legend to match the line thickness and size
legend("topleft", legend = c("Actual", "SARIMA (A)", "SARIMA (H)", "VECM-SCC (A)", "VECM-SII (A)", "VECM-SCC (H)", "VECM-SII (H)"), 
       col = c("black", "blue", "darkolivegreen3", "gold", "deeppink", "turquoise", "coral"), 
       lty = 1, lwd = 2, cex = 0.7)

```


```{r}
# MAPE
mape_sarima_UK <- round(MLmetrics::MAPE(sarima_UK_forecast[,1], all_test) * 100, 2)
mape_sarima_all <- round(MLmetrics::MAPE(sarima_all_forecast[,1], all_test) * 100, 2)
mape_vecm_UK_model_1 <- round(MLmetrics::MAPE(vecm_UK_forecast_model_1, all_test) * 100, 2)
mape_vecm_UK_model_2 <- round(MLmetrics::MAPE(vecm_UK_forecast_model_2, all_test) * 100, 2)
mape_vecm_all_1 <- round(MLmetrics::MAPE(vecm_all_forecast_1[,1], all_test) * 100, 2)
mape_vecm_all_2 <- round(MLmetrics::MAPE(vecm_all_forecast_2[,1], all_test) * 100, 2)


# MAE
mae_sarima_UK <- round(MLmetrics::MAE(sarima_UK_forecast[,1], all_test), 2)
mae_sarima_all <- round(MLmetrics::MAE(sarima_all_forecast[,1], all_test), 2)
mae_vecm_UK_model_1 <- round(MLmetrics::MAE(vecm_UK_forecast_model_1, all_test), 2)
mae_vecm_UK_model_2 <- round(MLmetrics::MAE(vecm_UK_forecast_model_2, all_test), 2)
mae_vecm_all_1 <- round(MLmetrics::MAE(vecm_all_forecast_1[,1], all_test), 2)
mae_vecm_all_2 <- round(MLmetrics::MAE(vecm_all_forecast_2[,1], all_test), 2)

# MAE (%)
mae_percentage_sarima_UK <- round((mae_sarima_UK / mean(all_test)) * 100, 2)
mae_percentage_sarima_all <- round((mae_sarima_all / mean(all_test)) * 100, 2)
mae_percentage_vecm_UK_model_1 <- round((mae_vecm_UK_model_1 / mean(all_test)) * 100, 2)
mae_percentage_vecm_UK_model_2 <- round((mae_vecm_UK_model_2 / mean(all_test)) * 100, 2)
mae_percentage_vecm_all_1 <- round((mae_vecm_all_1 / mean(all_test)) * 100, 2)
mae_percentage_vecm_all_2 <- round((mae_vecm_all_2 / mean(all_test)) * 100, 2)

# MPE (Mean Percentage Error)
mpe_sarima_UK <- round(mean((sarima_UK_forecast[,1] - all_test) / all_test) * 100, 2)
mpe_sarima_all <- round(mean((sarima_all_forecast[,1] - all_test) / all_test) * 100, 2)
mpe_vecm_UK_model_1 <- round(mean((vecm_UK_forecast_model_1 - all_test) / all_test) * 100, 2)
mpe_vecm_UK_model_2 <- round(mean((vecm_UK_forecast_model_2 - all_test) / all_test) * 100, 2)
mpe_vecm_all_1 <- round(mean((vecm_all_forecast_1[,1] - all_test) / all_test) * 100, 2)
mpe_vecm_all_2 <- round(mean((vecm_all_forecast_2[,1] - all_test) / all_test) * 100, 2)

# RMSE
rmse_sarima_UK <- round(MLmetrics::RMSE(sarima_UK_forecast[,1], all_test), 2)
rmse_sarima_all <- round(MLmetrics::RMSE(sarima_all_forecast[,1], all_test), 2)
rmse_vecm_UK_model_1 <- round(MLmetrics::RMSE(vecm_UK_forecast_model_1, all_test), 2)
rmse_vecm_UK_model_2 <- round(MLmetrics::RMSE(vecm_UK_forecast_model_2, all_test), 2)
rmse_vecm_all_1 <- round(MLmetrics::RMSE(vecm_all_forecast_1[,1], all_test), 2)
rmse_vecm_all_2 <- round(MLmetrics::RMSE(vecm_all_forecast_2[,1], all_test), 2)

# Print all the calculated metrics
list(
  MAPE = list(sarima_UK = mape_sarima_UK, sarima_all = mape_sarima_all, vecm_UK_model_1 = mape_vecm_UK_model_1, vecm_UK_model_2 = mape_vecm_UK_model_2, vecm_all_1 = mape_vecm_all_1, vecm_all_2 = mape_vecm_all_2),
  MAE = list(sarima_UK = mae_sarima_UK, sarima_all = mae_sarima_all, vecm_UK_model_1 = mae_vecm_UK_model_1, vecm_UK_model_2 = mae_vecm_UK_model_2, vecm_all_1 = mae_vecm_all_1, vecm_all_2 = mae_vecm_all_2),
  MAE_Percentage = list(sarima_UK = mae_percentage_sarima_UK, sarima_all = mae_percentage_sarima_all, vecm_UK_model_1 = mae_percentage_vecm_UK_model_1, vecm_UK_model_2 = mae_percentage_vecm_UK_model_2, vecm_all_1 = mae_percentage_vecm_all_1, vecm_all_2 = mae_percentage_vecm_all_2),
  MPE = list(sarima_UK = mpe_sarima_UK, sarima_all = mpe_sarima_all, vecm_UK_model_1 = mpe_vecm_UK_model_1, vecm_UK_model_2 = mpe_vecm_UK_model_2, vecm_all_1 = mpe_vecm_all_1, vecm_all_2 = mpe_vecm_all_2),
  RMSE = list(sarima_UK = rmse_sarima_UK, sarima_all = rmse_sarima_all, vecm_UK_model_1 = rmse_vecm_UK_model_1, vecm_UK_model_2 = rmse_vecm_UK_model_2, vecm_all_1 = rmse_vecm_all_1, vecm_all_2 = rmse_vecm_all_2)
)

```

```{r}
combined_result<-cbind(sarima_UK_forecast[,1],sarima_all_forecast[,1],vecm_UK_forecast_model_1,vecm_UK_forecast_model_2,vecm_all_forecast_1[,1],vecm_all_forecast_2[,1] ) 

view(combined_result)

```

```{r}
# Assuming the forecasts and actual values are already computed and stored in appropriate variables

# Create a list of models and their forecasts
models <- list(
  sarima_UK_forecast = sarima_UK_forecast[,1],
  sarima_all_forecast = sarima_all_forecast[,1],
  vecm_UK_forecast_model_1 = vecm_UK_forecast_model_1,
  vecm_UK_forecast_model_2 = vecm_UK_forecast_model_2,
  vecm_all_forecast_1 = vecm_all_forecast_1[,1],
  vecm_all_forecast_2 = vecm_all_forecast_2[,1]
)

# Function to calculate metrics
calculate_metrics <- function(forecast, actual) {
  # Mean Absolute Percentage Error (MAPE)
  mape <- round(mean(abs((forecast - actual) / actual)) * 100, 2)
  
  # Mean Absolute Error (MAE)
  mae <- round(MLmetrics::MAE(forecast, actual), 2)
  
  # MAE Percentage (relative to the mean of actual values)
  mae_percentage <- round((mae / mean(actual)) * 100, 2)
  
  # Mean Percentage Error (MPE)
  mpe <- round(mean((forecast - actual) / actual) * 100, 2)
  
  # Root Mean Square Error (RMSE)
  rmse <- round(sqrt(mean((forecast - actual)^2)), 2)
  
  return(c(MAPE = mape, MAE = mae, MAE_Percentage = mae_percentage, MPE = mpe, RMSE = rmse))
}

# Initialize a data frame to store results
results <- data.frame(Model = character(), Month = integer(), MAPE = double(), MAE = double(), MAE_Percentage = double(), MPE = double(), RMSE = double(), stringsAsFactors = FALSE)

# Loop through each model and calculate metrics for each month
for (model_name in names(models)) {
  forecasts <- models[[model_name]]
  for (month in 1:length(all_test)) {
    metrics <- calculate_metrics(forecasts[month], all_test[month])
    results <- rbind(results, data.frame(Model = model_name, Month = month, t(metrics)))
  }
}

# View results
View(results)
print(results)
```


# View all result

```{r}
view(UK_ts_forecast.vecm_1)
```

